defaults:
  - _self_
  - problem: tsp_constructive
  - llm_client: gemini
  - override hydra/output: local

hydra:
  job:
    chdir: True
  run:
    dir: outputs/${problem.problem_name}-${problem.problem_type}/${algorithm}/${now:%Y-%m-%d_%H-%M-%S}


model: mistral/codestral-latest # LLM model
temperature: 1  # temperature for chat completion

# The chosen algorithm
algorithm: mcts-ahd

# Main GA loop parameters
max_fe: 1000 # maximum number of function evaluations
pop_size: 10 # population size for GA
init_pop_size: 4 # initial population size for GA
timeout: 60 # timeout for evaluation of a single heuristic