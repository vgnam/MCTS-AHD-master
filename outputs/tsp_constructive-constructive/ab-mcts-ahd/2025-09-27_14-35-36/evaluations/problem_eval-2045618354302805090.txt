def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    next_node = None
    best_score = float('-inf')
    remaining_nodes = len(unvisited_nodes)
    alpha = 0.7  # Learning rate for historical performance
    beta = 0.3   # Weight for historical performance in scoring

    # Initialize or update historical performance (simplified for demonstration)
    if 'historical_performance' not in select_next_node.__dict__:
        select_next_node.historical_performance = {}

    for node in unvisited_nodes:
        distance_to_node = distance_matrix[current_node][node]
        distance_to_dest = distance_matrix[node][destination_node]

        # Base score components
        proximity_score = 1 / (1 + distance_to_node)
        destination_bias = (remaining_nodes / (remaining_nodes + 2)) * (distance_to_dest / distance_to_node)

        # Historical performance component (reinforcement learning inspired)
        historical_factor = select_next_node.historical_performance.get(node, 0.5)
        historical_factor = alpha * historical_factor + (1 - alpha) * (1 / (1 + distance_to_node))

        # Combined score with adaptive weighting
        score = (beta * historical_factor + (1 - beta) * proximity_score) * destination_bias

        if score > best_score:
            best_score = score
            next_node = node

    # Update historical performance for the selected node
    if next_node is not None:
        select_next_node.historical_performance[next_node] = select_next_node.historical_performance.get(next_node, 0.5) + 0.1

    # Early return to destination if significantly closer
    if destination_node in unvisited_nodes:
        dest_distance = distance_matrix[current_node][destination_node]
        if dest_distance < distance_matrix[current_node][next_node] * 0.7:
            next_node = destination_node

    return next_node
