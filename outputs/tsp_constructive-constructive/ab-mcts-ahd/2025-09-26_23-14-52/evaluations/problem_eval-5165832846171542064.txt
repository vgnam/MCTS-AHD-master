import random
import numpy as np

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    total_unvisited = len(unvisited_nodes)
    exploration_factor = 0.7 * (1.0 - (total_unvisited / (total_unvisited + 2)))
    centrality_scores = []

    # Calculate centrality using harmonic mean of distances
    for node in unvisited_nodes:
        distances = distance_matrix[node]
        harmonic_mean = len(distances) / np.sum(1.0 / (distances + 1e-6))
        centrality_scores.append(harmonic_mean)

    # Normalize and apply non-linear transformation
    if centrality_scores:
        centrality_scores = np.array(centrality_scores)
        centrality_scores = np.tanh(centrality_scores / np.max(centrality_scores))

    best_score = float('inf')
    next_node = None

    for idx, node in enumerate(unvisited_nodes):
        current_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]
        centrality = centrality_scores[idx]

        # Dynamic weighting with adaptive factors
        centrality_weight = 0.3 + 0.7 * (1 - exploration_factor)
        distance_weight = 0.5 + 0.5 * exploration_factor

        # Novel scoring equation combining multiple factors
        weighted_score = (distance_weight * (0.7 * current_distance + 0.3 * future_distance) +
                         centrality_weight * centrality)

        # Probabilistic selection with adaptive threshold
        selection_prob = 0.5 * (centrality ** 1.5) + 0.5 * (1 - exploration_factor)
        if random.random() < selection_prob:
            weighted_score *= 0.9  # Higher centrality nodes get slight preference

        if weighted_score < best_score:
            best_score = weighted_score
            next_node = node
        elif weighted_score == best_score:
            if future_distance < distance_matrix[next_node][destination_node]:
                next_node = node

    return next_node
