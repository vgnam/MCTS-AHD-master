import random
import numpy as np

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    total_unvisited = len(unvisited_nodes)
    exploration_factor = 0.5 * (1.0 - (total_unvisited / (total_unvisited + 1)))
    centrality_weights = []

    # Calculate adaptive centrality with distance scaling
    for node in unvisited_nodes:
        avg_distance = np.mean(distance_matrix[node])
        distance_to_current = distance_matrix[current_node][node]
        centrality_weights.append(avg_distance * (1 / (1 + distance_to_current)))

    # Normalize and scale centrality weights
    if centrality_weights:
        max_centrality = max(centrality_weights)
        centrality_weights = [w / max_centrality for w in centrality_weights]
        centrality_weights = [w ** (1 + exploration_factor) for w in centrality_weights]

    best_score = float('inf')
    next_node = None

    for idx, node in enumerate(unvisited_nodes):
        current_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]
        centrality = centrality_weights[idx]

        # Dynamic weighting with reinforcement adjustment
        weight_factor = 0.3 + 0.7 * (1 - exploration_factor)
        weighted_score = (0.5 * current_distance +
                          0.4 * future_distance +
                          weight_factor * centrality)

        # Probabilistic selection with reinforcement
        if random.random() < (centrality ** 3) * (1 - exploration_factor):
            weighted_score *= 0.7  # Stronger preference for high centrality nodes

        if weighted_score < best_score:
            best_score = weighted_score
            next_node = node
        elif weighted_score == best_score:
            if future_distance < distance_matrix[next_node][destination_node]:
                next_node = node

    return next_node
