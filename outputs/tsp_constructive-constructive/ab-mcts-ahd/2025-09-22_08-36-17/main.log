[2025-09-22 08:36:17,454][root][INFO] - Workspace: D:\MCTS-AHD-master\outputs\tsp_constructive-constructive\ab-mcts-ahd\2025-09-22_08-36-17
[2025-09-22 08:36:17,454][root][INFO] - Project Root: D:\MCTS-AHD-master
[2025-09-22 08:36:17,454][root][INFO] - Using LLM: mistral/codestral-latest
[2025-09-22 08:36:17,454][root][INFO] - Using Algorithm: ab-mcts-ahd
[2025-09-22 08:36:17,958][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:19,331][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:19,368][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:19,371][root][INFO] - LLM usage: prompt_tokens = 163, completion_tokens = 138
[2025-09-22 08:36:19,373][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:20,277][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:20,282][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:20,287][root][INFO] - LLM usage: prompt_tokens = 488, completion_tokens = 203
[2025-09-22 08:36:20,289][root][INFO] - Iteration 0: Running Code -4675772565231704753
[2025-09-22 08:36:20,786][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-22 08:36:20,851][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-22 08:36:20,852][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:21,971][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:21,976][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:21,982][root][INFO] - LLM usage: prompt_tokens = 893, completion_tokens = 373
[2025-09-22 08:36:21,984][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:22,784][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:22,788][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:22,789][root][INFO] - LLM usage: prompt_tokens = 1255, completion_tokens = 455
[2025-09-22 08:36:22,790][root][INFO] - Iteration 0: Running Code -1842571284834531433
[2025-09-22 08:36:23,274][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-22 08:36:23,310][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-22 08:36:23,310][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:24,611][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:24,615][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:24,617][root][INFO] - LLM usage: prompt_tokens = 1660, completion_tokens = 657
[2025-09-22 08:36:24,617][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:25,620][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:25,624][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:25,630][root][INFO] - LLM usage: prompt_tokens = 2054, completion_tokens = 763
[2025-09-22 08:36:25,634][root][INFO] - Iteration 0: Running Code 2842369583715965845
[2025-09-22 08:36:26,141][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-22 08:36:26,833][root][INFO] - Iteration 0, response_id 0: Objective value: 21.834803658638442
[2025-09-22 08:36:26,833][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:28,096][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:28,100][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:28,107][root][INFO] - LLM usage: prompt_tokens = 2811, completion_tokens = 972
[2025-09-22 08:36:28,109][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-22 08:36:30,073][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-22 08:36:30,074][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-22 08:36:30,076][root][INFO] - LLM usage: prompt_tokens = 3212, completion_tokens = 1082
[2025-09-22 08:36:30,076][root][INFO] - Iteration 0: Running Code 8062924256556096098
