def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    scores = []
    total_score = 0.0
    remaining_nodes = len(unvisited_nodes)

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_savings = distance_matrix[node][destination_node] - distance_matrix[current_node][destination_node]

        # Dynamic weight for future savings and exploration bonus
        weight = 0.6 * (1 - remaining_nodes / (remaining_nodes + 1))
        exploration_bonus = 0.3 * (1 / (1 + immediate_distance))  # Encourages exploration of distant nodes

        # Penalty for revisiting nodes
        penalty = 0.2 if current_node == node else 0.0

        # Normalize scores
        normalized_immediate = immediate_distance / max(1, max(distance_matrix[current_node]))
        normalized_future = future_savings / max(1, max(distance_matrix[node]))

        score = normalized_immediate - weight * normalized_future + penalty - exploration_bonus
        scores.append(score)
        total_score += score

    # Probabilistic selection based on normalized scores
    if total_score <= 0:
        probabilities = [1.0 / len(unvisited_nodes)] * len(unvisited_nodes)
    else:
        probabilities = [max(0, 1 - (score / total_score)) for score in scores]
        sum_prob = sum(probabilities)
        probabilities = [p / sum_prob for p in probabilities]

    next_node = np.random.choice(unvisited_nodes, p=probabilities)
    return next_node
