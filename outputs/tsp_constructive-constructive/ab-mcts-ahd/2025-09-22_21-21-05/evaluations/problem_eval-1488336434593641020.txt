def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    visit_frequencies = {node: 0 for node in unvisited_nodes}
    best_score = -float('inf')
    next_node = None
    num_unvisited = len(unvisited_nodes)
    exploration_factor = 0.2 * (1 / (1 + num_unvisited))  # Decreases as nodes are visited
    centrality_threshold = 0.3 * sum(distance_matrix[0]) / len(distance_matrix)

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]
        distance_to_destination = distance_matrix[node][destination_node]
        avg_distance_to_remaining = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / num_unvisited if num_unvisited else 0

        # Centrality-based weight
        centrality_weight = 1.0 if sum(distance_matrix[node]) < centrality_threshold else 0.7

        # Exploration bonus term
        exploration_bonus = exploration_factor * (1 / (1 + visit_frequencies.get(node, 0)))

        # Probabilistic score with reinforcement learning elements
        score = (0.5 * (1 / (1 + distance_to_current)) + 0.3 * (1 / (1 + distance_to_destination)) + 0.2 * (1 / (1 + avg_distance_to_remaining))) * centrality_weight + exploration_bonus

        if score > best_score:
            best_score = score
            next_node = node

    # Update visit frequency for the selected node
    if next_node in visit_frequencies:
        visit_frequencies[next_node] += 1

    return next_node
