def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    total_unvisited = len(unvisited_nodes)
    best_score = float('-inf')
    next_node = None
    node_priority = {}
    memory_window = max(3, int(total_unvisited * 0.2))

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]
        distance_to_destination = distance_matrix[node][destination_node]

        # Dynamic weight for destination influence based on progress
        progress_ratio = 1 - (total_unvisited / len(distance_matrix))
        weight = 0.3 + 0.7 * (1 - progress_ratio ** 2)

        # Reinforcement learning inspired novelty factor
        novelty = 1 / (1 + node_priority.get(node, 0) ** 0.7)

        # Memory-based penalty for recently visited nodes
        memory_penalty = 1.0
        if node in unvisited_nodes[-memory_window:]:
            memory_penalty = 1.5

        # Adaptive scoring with combined factors
        combined_score = (1/distance_to_current) * (1 + weight * (1/distance_to_destination)) * novelty / memory_penalty

        if combined_score > best_score:
            best_score = combined_score
            next_node = node

    # Update priority for the selected node
    if next_node in node_priority:
        node_priority[next_node] += 1
    else:
        node_priority[next_node] = 1

    return next_node
