def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    best_score = float('-inf')
    next_node = None
    total_nodes = len(distance_matrix)
    remaining_count = len(unvisited_nodes)
    progress_ratio = (total_nodes - remaining_count) / total_nodes

    # Phase 1: Probabilistic shortcut scoring for early exploration
    if progress_ratio < 0.3:
        for node in unvisited_nodes:
            distance_to_current = distance_matrix[current_node][node]
            distance_to_destination = distance_matrix[node][destination_node]

            # Probability of being a shortcut based on distance ratio
            shortcut_prob = (distance_to_current + distance_to_destination) / sum(distance_matrix[current_node][n] + distance_matrix[n][destination_node] for n in unvisited_nodes)

            # Centrality as fallback metric
            centrality = sum(distance_matrix[node][n] for n in range(total_nodes)) / (total_nodes - 1)

            # Combined score with dynamic weight
            combined_score = (0.7 * shortcut_prob) + (0.3 * (1 - centrality / sum(sum(distance_matrix))))

            if combined_score > best_score:
                best_score = combined_score
                next_node = node

    # Phase 2: Balanced optimization with memory penalty
    else:
        memory_penalty = {}
        for node in unvisited_nodes:
            # Calculate base metrics
            distance_to_current = distance_matrix[current_node][node]
            distance_to_destination = distance_matrix[node][destination_node]
            centrality = sum(distance_matrix[node][n] for n in range(total_nodes)) / (total_nodes - 1)
            density = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / remaining_count if remaining_count > 1 else 0

            # Memory penalty calculation
            memory_penalty[node] = 0
            for visited in range(total_nodes):
                if visited not in unvisited_nodes and visited != current_node:
                    memory_penalty[node] += 0.2 * (1 - distance_matrix[node][visited] / sum(distance_matrix[node]))

            # Dynamic weight based on progress
            exploration_weight = 0.2 + 0.6 * (1 - progress_ratio)

            # Combined score with memory penalty
            combined_score = (exploration_weight * (distance_to_current + distance_to_destination) +
                           (1 - exploration_weight) * (centrality + density) -
                           memory_penalty[node])

            if combined_score > best_score:
                best_score = combined_score
                next_node = node

    return next_node
