def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Calculate dynamic entropy threshold
    if remaining_nodes > 1:
        distances = [distance_matrix[current_node][n] for n in unvisited_nodes]
        entropy_threshold = np.percentile(distances, 75)  # Q3 as dynamic threshold
    else:
        entropy_threshold = 0

    # Path momentum and node density
    if len(distance_matrix) > 1:
        prev_node = current_node - 1 if current_node > 0 else len(distance_matrix) - 1
        momentum_factor = -distance_matrix[prev_node][current_node] / max(sum(row) for row in distance_matrix)
    else:
        momentum_factor = 0

    density_factor = remaining_nodes / total_nodes

    # Adaptive neighborhood exploration
    neighborhood_size = max(1, int(remaining_nodes * 0.3 + 1))  # Dynamic neighborhood size
    candidate_nodes = sorted(unvisited_nodes, key=lambda n: distance_matrix[current_node][n])[:neighborhood_size]

    # Probabilistic selection with reinforcement scoring
    def calculate_probability(node):
        local_dist = distance_matrix[current_node][node]
        connectivity = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < entropy_threshold) / (remaining_nodes - 1)

        # Reinforcement scoring with momentum awareness
        base_score = (local_dist / (1 + connectivity)) * (1 - 0.4 * momentum_factor)
        density_score = (1 - density_factor) * connectivity
        momentum_score = momentum_factor * (1 - local_dist / max(sum(row) for row in distance_matrix))

        return base_score + density_score + momentum_score

    probabilities = [calculate_probability(node) for node in candidate_nodes]
    probabilities = [p / sum(probabilities) for p in probabilities]  # Normalize

    next_node = np.random.choice(candidate_nodes, p=probabilities)
    return next_node
