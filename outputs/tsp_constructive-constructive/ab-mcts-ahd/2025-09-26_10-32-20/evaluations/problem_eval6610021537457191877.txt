def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    progress = 1.0 - (remaining_nodes / len(distance_matrix))  # Normalized progress (0 to 1)
    exploration_weight = 1.0 - progress  # Decaying exploration bias

    # Historical selection frequency (simulated reinforcement)
    selection_history = {node: 1.0 / len(unvisited_nodes) for node in unvisited_nodes}  # Placeholder for actual tracking

    def path_potential(node):
        local_dist = distance_matrix[current_node][node]
        global_dist = distance_matrix[node][destination_node]

        # Neighborhood influence: average distance to unvisited nodes
        neighborhood_influence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)

        # Dynamic weighting: balance local/global with progress and history
        weight_local = 0.5 * (1 - progress) + 0.2 * selection_history[node]
        weight_global = 0.5 * progress + 0.3 * selection_history[node]

        # Stochastic component with decaying exploration
        stochastic_factor = (local_dist + global_dist) * (0.3 + 0.7 * exploration_weight)

        return (weight_local * local_dist + weight_global * global_dist + 0.4 * neighborhood_influence + stochastic_factor)

    next_node = min(unvisited_nodes, key=path_potential)
    return next_node
