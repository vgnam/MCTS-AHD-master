def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Calculate adaptive weights based on path progress
    progress_ratio = (total_nodes - remaining_nodes) / total_nodes
    weight_local = 0.5 - 0.4 * progress_ratio
    weight_connectivity = 0.3 + 0.2 * progress_ratio
    weight_diversity = 0.2 + 0.3 * progress_ratio

    # Memory mechanism to avoid recent selections
    recent_memory = set()
    if len(unvisited_nodes) < total_nodes:
        recent_memory.add(current_node)

    def calculate_score(node):
        local_distance = distance_matrix[current_node][node]
        connectivity = sum(distance_matrix[node][n] for n in range(total_nodes)) / total_nodes
        diversity = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)

        # Reinforcement learning inspired scoring
        local_term = weight_local * (1 / (1 + local_distance))
        connectivity_term = weight_connectivity * connectivity
        diversity_term = weight_diversity * (1 / (1 + diversity))

        # Penalize recent selections
        if node in recent_memory:
            return float('inf')

        return -(local_term + connectivity_term + diversity_term)

    # Probabilistic selection based on scores
    scores = [calculate_score(node) for node in unvisited_nodes]
    min_score = min(scores)
    max_score = max(scores)

    if min_score == max_score:
        probabilities = [1.0 / remaining_nodes for _ in range(remaining_nodes)]
    else:
        normalized_scores = [(score - min_score) / (max_score - min_score) for score in scores]
        probabilities = [1 - (s / sum(normalized_scores)) for s in normalized_scores]
        probabilities = [p / sum(probabilities) for p in probabilities]

    next_node = np.random.choice(unvisited_nodes, p=probabilities)
    return next_node
