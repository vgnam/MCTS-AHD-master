def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Enhanced entropy and momentum calculation
    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes if unvisited_nodes else 0
    max_total_distance = max(sum(row) for row in distance_matrix) if distance_matrix else 0
    entropy_factor = 1 - (avg_distance / max_total_distance) if max_total_distance != 0 else 1

    # Adaptive neighborhood exploration
    neighborhood_radius = int(0.3 * total_nodes * entropy_factor) + 1
    neighborhood = [n for n in unvisited_nodes if distance_matrix[current_node][n] <= neighborhood_radius]

    if not neighborhood:
        neighborhood = unvisited_nodes

    # Dynamic momentum with neighborhood influence
    if len(distance_matrix) > 1:
        prev_node = current_node - 1 if current_node > 0 else len(distance_matrix) - 1
        path_momentum = -distance_matrix[prev_node][current_node] / max_total_distance
        momentum_factor = 0.5 * (1 + path_momentum) * (1 - entropy_factor)
    else:
        momentum_factor = 0.5

    # Adaptive weight adjustment with entropy and momentum
    weight_local = 0.4 * (1 - entropy_factor) + 0.3 * momentum_factor
    weight_coherence = 0.3 * entropy_factor + 0.2 * momentum_factor
    weight_centrality = 0.3 * (1 - entropy_factor) + 0.1 * momentum_factor

    def calculate_score(node):
        local_distance = distance_matrix[current_node][node]
        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)
        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)

        # Novel scoring with probabilistic and momentum components
        local_term = weight_local * (local_distance / (1 + 0.5 * entropy_factor)) * (1 - 0.3 * momentum_factor)
        centrality_term = weight_centrality * (centrality * (1 + 0.5 * entropy_factor)) * (1 + 0.2 * momentum_factor)
        coherence_term = weight_coherence * (coherence / (1 + entropy_factor)) * (1 + 0.5 * momentum_factor)

        # Add probabilistic element for exploration
        exploration_prob = 0.2 * entropy_factor * (1 - momentum_factor)
        if random.random() < exploration_prob:
            return random.uniform(0, 1)

        return local_term + centrality_term - coherence_term * (1 + 0.3 * entropy_factor)

    next_node = min(neighborhood, key=calculate_score)
    return next_node
