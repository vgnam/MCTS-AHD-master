def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Calculate entropy and path momentum
    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes
    max_total_distance = max(sum(row) for row in distance_matrix)
    entropy_factor = 1 - (avg_distance / max_total_distance) if max_total_distance != 0 else 1

    # Path momentum calculation (reward for consistent path direction)
    if len(distance_matrix) > 1:
        prev_node = current_node - 1 if current_node > 0 else len(distance_matrix) - 1
        path_momentum = -distance_matrix[prev_node][current_node] / max_total_distance
    else:
        path_momentum = 0

    # Dynamic temperature cooling (controls exploration-exploitation balance)
    progress_ratio = (total_nodes - remaining_nodes) / total_nodes
    temperature = 1 - progress_ratio * (0.5 + 0.5 * entropy_factor)

    # Dynamic weight adjustment with momentum influence
    weight_coherence = 0.4 * (1 - entropy_factor) + 0.3 * (remaining_nodes / total_nodes) + 0.2 * path_momentum
    weight_local = 0.4 * entropy_factor + 0.3 * (remaining_nodes / total_nodes) + 0.2 * path_momentum
    weight_centrality = 0.4 * (1 - entropy_factor) + 0.1 * (remaining_nodes / total_nodes)

    # Neighborhood analysis (local vs global)
    neighborhood_size = min(3, remaining_nodes)
    if neighborhood_size > 0:
        local_neighborhood = sorted(unvisited_nodes, key=lambda n: distance_matrix[current_node][n])[:neighborhood_size]
        global_neighborhood = sorted(unvisited_nodes, key=lambda n: sum(distance_matrix[n][m] for m in range(total_nodes)))[:neighborhood_size]
        neighborhood_factor = len(set(local_neighborhood) & set(global_neighborhood)) / neighborhood_size
    else:
        neighborhood_factor = 0

    # Probabilistic selection with temperature cooling
    scores = []
    for node in unvisited_nodes:
        local_distance = distance_matrix[current_node][node]
        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)
        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)

        local_term = weight_local * (local_distance / (1 + entropy_factor)) * (1 - 0.5 * path_momentum)
        centrality_term = weight_centrality * (centrality * (1 + entropy_factor)) * (1 + 0.3 * path_momentum)
        coherence_term = weight_coherence * (coherence / (1 + entropy_factor)) * (1 + 0.7 * path_momentum)

        # Adaptive neighborhood influence
        neighborhood_influence = 0.5 if node in local_neighborhood or node in global_neighborhood else 0.1
        total_score = (local_term + centrality_term - coherence_term * (1 + 0.5 * entropy_factor)) * (1 + neighborhood_influence)
        scores.append((node, total_score))

    # Temperature-based probabilistic selection
    if scores:
        max_score = max(score for _, score in scores)
        min_score = min(score for _, score in scores)

        if max_score != min_score:
            normalized_scores = [(node, (score - min_score) / (max_score - min_score)) for node, score in scores]
        else:
            normalized_scores = [(node, 0.5) for node, _ in scores]

        probabilities = [score ** (1 / temperature) for _, score in normalized_scores]
        total_prob = sum(probabilities)
        probabilities = [p / total_prob for p in probabilities]

        next_node = random.choices([node for node, _ in normalized_scores], weights=probabilities, k=1)[0]
        return next_node
    else:
        return next_node
