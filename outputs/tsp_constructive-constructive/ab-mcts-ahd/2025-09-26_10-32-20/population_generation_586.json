[
     {
          "algorithm": "The algorithm dynamically balances three factors\u2014local distance, centrality, and coherence\u2014where local distance is prioritized early (higher `weight_local`), centrality gains importance later (increasing `weight_centrality`), and coherence follows a bell curve (peaking midway). The `calculate_score` function combines these weighted factors to select the next node, favoring nearby nodes initially but shifting toward more central and coherent choices as progress increases. The weights adjust linearly or via a bell curve based on the remaining unvisited nodes.",
          "thought": "The new algorithm emphasizes early focus on local distances and later prioritizes centrality and coherence, using inverse-progress-weighted factors where weight_local starts high and decreases, weight_centrality starts low and increases, and weight_coherence follows a bell curve centered in the middle of the path construction.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - (remaining_nodes / total_nodes)\n\n    weight_local = 0.7 - 0.4 * progress\n    weight_centrality = 0.1 + 0.4 * progress\n    weight_coherence = 0.2 + 0.4 * (0.5 - abs(progress - 0.5))\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.37203,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines nearest-neighbor (prioritizing local distance) with dynamic weights that balance centrality (favoring well-connected nodes) and coherence (avoiding isolated nodes) as the tour progresses. Higher weights are given to local distance and coherence early in the tour, while centrality gains importance later. The weights adjust based on progress (total nodes visited), creating a dynamic trade-off between local and global considerations.",
          "thought": "The new algorithm combines the nearest-neighbor approach of No.2 with a dynamic weighting scheme inspired by No.1, balancing local distance (increasing weight) with node centrality (decreasing weight) and coherence (increasing weight) to avoid local optima and improve global structure.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - (remaining_nodes / total_nodes)\n\n    weight_local = 0.4 + 0.6 * progress\n    weight_centrality = 0.5 * (0.5 ** progress)\n    weight_coherence = 0.2 + 0.8 * progress\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.37567,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local distance, centrality, and coherence priorities, starting with high local distance weight (0.7) and gradually shifting focus to centrality (0.2\u21920.6) and coherence (0.1\u21920.5) as the search progresses, optimizing the path by prioritizing global metrics early and refining local choices later. The `calculate_score` function combines these weighted factors to select the next node, where local distance dominates early, while centrality and coherence gain importance as unvisited nodes decrease. The weights adjust dynamically based on remaining nodes, ensuring a balance between immediate proximity and global structure.",
          "thought": "The new algorithm dynamically shifts focus from local distance to centrality and coherence, starting with high local distance weight (0.7\u21920.3) and gradually increasing centrality (0.2\u21920.6) and coherence (0.1\u21920.5) weights, prioritizing global metrics early and refining local choices later for better path optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    remaining_ratio = remaining_nodes / total_nodes\n    weight_local = 0.7 - 0.4 * (1 - remaining_ratio)\n    weight_centrality = 0.2 + 0.4 * (1 - remaining_ratio)\n    weight_coherence = 0.1 + 0.4 * (1 - remaining_ratio)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.42324,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local optimization (prioritized early) with global structure (emphasized later) by adjusting weights: `weight_local` increases linearly, `weight_centrality` decreases exponentially, and `weight_coherence` increases linearly. It selects the next node by minimizing a weighted score combining local distance, node centrality (inverse of total distance to all nodes), and coherence (average distance to unvisited nodes). Early in the path, local distance dominates, while centrality and coherence gain importance as progress increases.",
          "thought": "The new algorithm prioritizes local distance early in the path construction, with centrality and coherence becoming more influential later. It uses linearly increasing weight_local, exponentially decreasing weight_centrality, and linearly increasing weight_coherence, dynamically adjusting these weights based on progress to balance local optimization and global structure.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - (remaining_nodes / total_nodes)\n\n    weight_local = 0.3 + 0.7 * progress\n    weight_centrality = 0.6 * (0.5 ** progress)\n    weight_coherence = 0.2 + 0.8 * progress\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.43208,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weight scaling with exponential decay to balance local distance, centrality, and coherence, prioritizing local distance (weight 0.7-1.0) and centrality (weight 0.2-0.6) over coherence (weight 0.1-0.8), while dynamically adjusting weights based on remaining nodes. It uses a multiplicative local-global balance metric and subtractive coherence term to avoid over-prioritization, with weights decaying exponentially as the tour progresses. The score is minimized to select the next node.",
          "thought": "This algorithm modifies the original by introducing adaptive weight scaling with exponential decay and incorporating a novel 'local-global balance' metric that combines distance and centrality in a multiplicative fashion, while preserving coherence as a subtractive term to avoid over-prioritization.",
          "code": "import math\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    remaining_ratio = remaining_nodes / total_nodes\n    decay_factor = math.exp(-remaining_ratio)\n\n    weight_local = 0.7 * decay_factor + 0.3\n    weight_centrality = 0.4 * decay_factor + 0.2\n    weight_coherence = 0.1 * decay_factor + 0.4\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        local_global_balance = (local_distance * centrality) ** 0.5\n        return (weight_local * local_distance) + (weight_centrality * local_global_balance) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.43243,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances three priorities\u2014**local distance (highest weight initially)**, **centrality (moderate weight initially)**, and **coherence (lowest weight initially)**\u2014by adjusting weights based on the remaining unvisited nodes. It prioritizes immediate proximity early on while increasingly considering node centrality and coherence as the tour progresses, ensuring a trade-off between short-term and long-term optimization. The weights are computed using a ratio of remaining nodes, with local distance dominating early (weight_local = 0.6), centrality and coherence increasing over time. The next node is selected by minimizing a weighted score combining direct distance, centrality, and average remaining distance.",
          "thought": "The new algorithm combines the dynamic weight balancing of No.1 (adjusting local distance, centrality, and coherence priorities) with the modified farthest insertion approach of No.2 (balancing direct distance and average remaining distance), resulting in a heuristic that prioritizes immediate proximity while adaptively considering centrality and coherence as the search progresses.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    remaining_ratio = remaining_nodes / total_nodes\n    weight_local = 0.6 - 0.3 * (1 - remaining_ratio)\n    weight_centrality = 0.2 + 0.3 * (1 - remaining_ratio)\n    weight_coherence = 0.2 + 0.5 * (1 - remaining_ratio)\n\n    def calculate_score(node):\n        direct_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        avg_remaining_distance = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / max(1, len(unvisited_nodes) - 1)\n        return (weight_local * direct_distance) + (weight_centrality * centrality) - (weight_coherence * avg_remaining_distance)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.44109,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local distance, centrality, and coherence by adjusting weights (60% local/centrality, 40% coherence) based on remaining nodes, prioritizing immediate proximity and long-term optimization. It selects the next node by minimizing a weighted score combining local distance, node centrality (inverse of total distances), and average coherence (distances to unvisited nodes). The weights are adaptive, favoring local/centrality early and coherence later, ensuring a trade-off between short-term and long-term optimization.",
          "thought": "The new algorithm combines the adaptive weighting of local distance, centrality, and coherence from No.1 with the hybrid nearest-neighbor and farthest-insertion approach of No.2, using dynamic weights (60% local/centrality, 40% coherence) that adjust based on remaining nodes, ensuring a balance between immediate and long-term optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    weight_local = 0.6 - 0.2 * (remaining_nodes / len(distance_matrix))\n    weight_centrality = 0.3 + 0.1 * (remaining_nodes / len(distance_matrix))\n    weight_coherence = 0.4 - 0.2 * (remaining_nodes / len(distance_matrix))\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.44406,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global considerations by adjusting weights based on remaining nodes, prioritizing local distance early (higher weight) and gradually incorporating global centrality and inverse global distance (lower weight) for long-term optimization. It selects the next node by minimizing a weighted score combining these factors, with local distance dominating initially and global metrics gaining importance as the tour progresses. The code structure clearly separates weight calculation, score computation, and node selection, ensuring a smooth transition between exploration and exploitation.",
          "thought": "The new algorithm combines dynamic weighting with local distance, global centrality, and inverse global distance inspired by No.1, while maintaining the dynamic weight adjustment of No.2 to balance exploration and exploitation. The algorithm calculates dynamic weights based on remaining nodes, prioritizes local distance early, and gradually incorporates global centrality and inverse global distance for better long-term optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    total_nodes = len(distance_matrix)\n    remaining_ratio = len(unvisited_nodes) / total_nodes\n    local_weight = 0.6 + 0.4 * (1 - remaining_ratio)\n    global_weight = 1 - local_weight\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        global_distance = sum(distance_matrix[node][n] for n in unvisited_nodes) / len(unvisited_nodes)\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        inverse_global = 1 / (global_distance + 1e-10)\n        return local_weight * local_distance + global_weight * (0.5 * centrality + 0.5 * inverse_global)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.48396,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines entropy-based dynamic weighting with reinforcement learning-inspired scoring, prioritizing coherence in high-entropy scenarios while maintaining local efficiency through path momentum. It balances immediate distance (local_term), long-term centrality (centrality_term), and consistency (coherence_term) with adaptive weights, where coherence dominates in uncertain situations (high entropy) and local distance is emphasized in low-entropy phases. The path momentum factor reinforces consistent path direction, with weights dynamically adjusted to favor either local efficiency or global coherence based on remaining nodes and entropy levels.",
          "thought": "The new algorithm extends the entropy-based dynamic weighting approach by incorporating adaptive path memory through a reinforcement learning-inspired scoring mechanism, where node selection is influenced by both immediate factors and long-term path quality estimates, with coherence prioritized in high-entropy scenarios while maintaining local efficiency through a novel \"path momentum\" factor.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n\n    # Calculate entropy and path momentum\n    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes\n    max_total_distance = max(sum(row) for row in distance_matrix)\n    entropy_factor = 1 - (avg_distance / max_total_distance) if max_total_distance != 0 else 1\n\n    # Path momentum calculation (reward for consistent path direction)\n    if len(distance_matrix) > 1:\n        prev_node = current_node - 1 if current_node > 0 else len(distance_matrix) - 1\n        path_momentum = -distance_matrix[prev_node][current_node] / max_total_distance\n    else:\n        path_momentum = 0\n\n    # Dynamic weight adjustment with momentum influence\n    weight_coherence = 0.5 * (1 - entropy_factor) + 0.3 * (remaining_nodes / total_nodes) + 0.2 * path_momentum\n    weight_local = 0.3 * entropy_factor + 0.2 * (remaining_nodes / total_nodes) + 0.3 * path_momentum\n    weight_centrality = 0.4 * (1 - entropy_factor) + 0.1 * (remaining_nodes / total_nodes)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)\n\n        # Novel scoring with momentum and adaptive scaling\n        local_term = weight_local * (local_distance / (1 + entropy_factor)) * (1 - 0.5 * path_momentum)\n        centrality_term = weight_centrality * (centrality * (1 + entropy_factor)) * (1 + 0.3 * path_momentum)\n        coherence_term = weight_coherence * (coherence / (1 + entropy_factor)) * (1 + 0.7 * path_momentum)\n\n        return local_term + centrality_term - coherence_term * (1 + 0.5 * entropy_factor)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.49114,
          "other_inf": null
     },
     {
          "algorithm": "This heuristic algorithm for TSP dynamically balances local efficiency, centrality, and path coherence by adjusting weights based on entropy (uncertainty) and path momentum. It prioritizes local distance minimization (weighted 0.3) and centrality (weighted 0.4) in low-entropy phases, while emphasizing coherence (weighted 0.6) and momentum reinforcement in high-entropy phases. The algorithm adapts scoring through inverse proportional weighting, with momentum reinforcing consistent path direction.",
          "thought": "This new algorithm integrates dynamic weight adjustment based on entropy and path momentum, while incorporating adaptive local/centrality/coherence scoring with inverse proportional weighting to remaining nodes, emphasizing coherence in uncertain phases and local efficiency in stable ones, and reinforcing path consistency through momentum.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n\n    # Entropy calculation\n    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes\n    max_total_distance = max(sum(row) for row in distance_matrix)\n    entropy_factor = 1 - (avg_distance / max_total_distance) if max_total_distance != 0 else 1\n\n    # Path momentum calculation\n    if len(distance_matrix) > 1:\n        prev_node = current_node - 1 if current_node > 0 else len(distance_matrix) - 1\n        path_momentum = -distance_matrix[prev_node][current_node] / max_total_distance\n    else:\n        path_momentum = 0\n\n    # Dynamic weight adjustment\n    weight_coherence = 0.6 * (1 - entropy_factor) + 0.3 * (remaining_nodes / total_nodes) + 0.2 * path_momentum\n    weight_local = 0.3 * entropy_factor + 0.2 * (remaining_nodes / total_nodes) + 0.3 * path_momentum\n    weight_centrality = 0.4 * (1 - entropy_factor) + 0.1 * (remaining_nodes / total_nodes)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)\n\n        # Adaptive scoring with momentum and entropy\n        local_term = weight_local * (local_distance / (1 + entropy_factor)) * (1 - 0.4 * path_momentum)\n        centrality_term = weight_centrality * (centrality * (1 + entropy_factor)) * (1 + 0.2 * path_momentum)\n        coherence_term = weight_coherence * (coherence / (1 + entropy_factor)) * (1 + 0.6 * path_momentum)\n\n        return local_term + centrality_term - coherence_term * (1 + 0.4 * entropy_factor)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.49139,
          "other_inf": null
     }
]