[
     {
          "algorithm": "The algorithm dynamically balances local distance, centrality, and coherence priorities, starting with high local distance weight (0.7) and gradually shifting focus to centrality (0.2\u21920.6) and coherence (0.1\u21920.5) as the search progresses, optimizing the path by prioritizing global metrics early and refining local choices later. The `calculate_score` function combines these weighted factors to select the next node, where local distance dominates early, while centrality and coherence gain importance as unvisited nodes decrease. The weights adjust dynamically based on remaining nodes, ensuring a balance between immediate proximity and global structure.",
          "thought": "The new algorithm dynamically shifts focus from local distance to centrality and coherence, starting with high local distance weight (0.7\u21920.3) and gradually increasing centrality (0.2\u21920.6) and coherence (0.1\u21920.5) weights, prioritizing global metrics early and refining local choices later for better path optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    remaining_ratio = remaining_nodes / total_nodes\n    weight_local = 0.7 - 0.4 * (1 - remaining_ratio)\n    weight_centrality = 0.2 + 0.4 * (1 - remaining_ratio)\n    weight_coherence = 0.1 + 0.4 * (1 - remaining_ratio)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.42324,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weight scaling with exponential decay to balance local distance, centrality, and coherence, prioritizing local distance (weight 0.7-1.0) and centrality (weight 0.2-0.6) over coherence (weight 0.1-0.8), while dynamically adjusting weights based on remaining nodes. It uses a multiplicative local-global balance metric and subtractive coherence term to avoid over-prioritization, with weights decaying exponentially as the tour progresses. The score is minimized to select the next node.",
          "thought": "This algorithm modifies the original by introducing adaptive weight scaling with exponential decay and incorporating a novel 'local-global balance' metric that combines distance and centrality in a multiplicative fashion, while preserving coherence as a subtractive term to avoid over-prioritization.",
          "code": "import math\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    remaining_ratio = remaining_nodes / total_nodes\n    decay_factor = math.exp(-remaining_ratio)\n\n    weight_local = 0.7 * decay_factor + 0.3\n    weight_centrality = 0.4 * decay_factor + 0.2\n    weight_coherence = 0.1 * decay_factor + 0.4\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        local_global_balance = (local_distance * centrality) ** 0.5\n        return (weight_local * local_distance) + (weight_centrality * local_global_balance) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.43243,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local distance, centrality, and coherence by adjusting weights (60% local/centrality, 40% coherence) based on remaining nodes, prioritizing immediate proximity and long-term optimization. It selects the next node by minimizing a weighted score combining local distance, node centrality (inverse of total distances), and average coherence (distances to unvisited nodes). The weights are adaptive, favoring local/centrality early and coherence later, ensuring a trade-off between short-term and long-term optimization.",
          "thought": "The new algorithm combines the adaptive weighting of local distance, centrality, and coherence from No.1 with the hybrid nearest-neighbor and farthest-insertion approach of No.2, using dynamic weights (60% local/centrality, 40% coherence) that adjust based on remaining nodes, ensuring a balance between immediate and long-term optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    weight_local = 0.6 - 0.2 * (remaining_nodes / len(distance_matrix))\n    weight_centrality = 0.3 + 0.1 * (remaining_nodes / len(distance_matrix))\n    weight_coherence = 0.4 - 0.2 * (remaining_nodes / len(distance_matrix))\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.44406,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global considerations by adjusting weights based on remaining nodes, prioritizing local distance early (higher weight) and gradually incorporating global centrality and inverse global distance (lower weight) for long-term optimization. It selects the next node by minimizing a weighted score combining these factors, with local distance dominating initially and global metrics gaining importance as the tour progresses. The code structure clearly separates weight calculation, score computation, and node selection, ensuring a smooth transition between exploration and exploitation.",
          "thought": "The new algorithm combines dynamic weighting with local distance, global centrality, and inverse global distance inspired by No.1, while maintaining the dynamic weight adjustment of No.2 to balance exploration and exploitation. The algorithm calculates dynamic weights based on remaining nodes, prioritizes local distance early, and gradually incorporates global centrality and inverse global distance for better long-term optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    total_nodes = len(distance_matrix)\n    remaining_ratio = len(unvisited_nodes) / total_nodes\n    local_weight = 0.6 + 0.4 * (1 - remaining_ratio)\n    global_weight = 1 - local_weight\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        global_distance = sum(distance_matrix[node][n] for n in unvisited_nodes) / len(unvisited_nodes)\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        inverse_global = 1 / (global_distance + 1e-10)\n        return local_weight * local_distance + global_weight * (0.5 * centrality + 0.5 * inverse_global)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.48396,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances global optimization (coherence) and local constraints (distance/centrality) by adjusting weights inversely proportional to remaining nodes. Early in the search, it heavily favors coherence (70% weight) to ensure long-term path coherence, gradually shifting to local distance (30%) and centrality (20%) as nodes are visited. The `calculate_score` function computes a weighted sum of local distance, centrality (node importance), and coherence (average distance to unvisited nodes), prioritizing coherence initially before adapting to local factors.",
          "thought": "The new algorithm prioritizes global optimization by emphasizing coherence (70% weight) early and gradually shifting to local distance (30%) and centrality (20%) as nodes are visited, ensuring long-term path coherence while maintaining adaptability to local constraints.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    weight_coherence = 0.7 - 0.4 * (remaining_nodes / len(distance_matrix))\n    weight_local = 0.3 + 0.2 * (remaining_nodes / len(distance_matrix))\n    weight_centrality = 0.2 + 0.1 * (remaining_nodes / len(distance_matrix))\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.49596,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by balancing local distance (highest priority), global centrality (medium priority), and coherence (lowest priority), with weights adjusted based on remaining nodes. It uses historical selection patterns to reinforce frequently chosen nodes, optimizing long-term path efficiency. The code structures these factors into a weighted score, selecting the node with the minimal value to guide the path.",
          "thought": "The new algorithm introduces a dynamic prioritization mechanism that combines local distance, global centrality, and coherence with adaptive weights, but also incorporates a reinforcement learning-inspired component that adjusts weights based on historical node selection patterns to improve long-term path optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_weight_local = 0.5\n    base_weight_centrality = 0.3\n    base_weight_coherence = 0.2\n\n    # Dynamic weight adjustment based on remaining nodes\n    weight_local = base_weight_local * (1 - 0.3 * (remaining_nodes / len(distance_matrix)))\n    weight_centrality = base_weight_centrality * (1 + 0.2 * (remaining_nodes / len(distance_matrix)))\n    weight_coherence = base_weight_coherence * (1 - 0.1 * (remaining_nodes / len(distance_matrix)))\n\n    # Historical selection pattern reinforcement\n    selection_history = {}\n    for node in unvisited_nodes:\n        selection_history[node] = 1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = selection_history[node]\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.51569,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically adjusts selection priorities by weighting local distance (higher early on), global centrality (moderate), and path coherence (lower initially) based on remaining nodes, using a scoring function that balances these factors. Local distance dominates early, while coherence gains importance later. The weights are inversely proportional to the remaining path length, ensuring adaptability.",
          "thought": "The new algorithm modifies the selection criteria by incorporating a dynamic weight adjustment mechanism based on the remaining path length, combining local distance, global centrality, and a novel \"path coherence\" factor that measures alignment with the overall path direction, while preserving the original structure with a different scoring function and adaptive weights.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    weight_local = 0.5 + 0.4 * (remaining_nodes / len(distance_matrix))\n    weight_centrality = 0.3 + 0.2 * (remaining_nodes / len(distance_matrix))\n    weight_coherence = 0.2 + 0.3 * (remaining_nodes / len(distance_matrix))\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence)\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.52042,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically adapts weights for local distance, centrality, and coherence based on node density, prioritizing exploration early (higher local distance and centrality weights) and exploitation later (higher coherence weight). It avoids local optima by penalizing frequently visited nodes and selects the next node by minimizing a score combining these weighted components. The weights are adjusted using a density factor, with local distance and centrality given higher initial priority, while coherence becomes more influential as the search progresses.",
          "thought": "The new algorithm introduces dynamic weight adaptation based on node density and historical visits, using a novel score function that combines local distance, centrality, and coherence with adaptive weights that prioritize exploration early and exploitation later, while incorporating a memory-based penalty for frequently visited nodes to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    density = remaining_nodes / total_nodes\n\n    # Dynamic weight adaptation\n    weight_local = 0.5 * (1 - density) + 0.3\n    weight_centrality = 0.4 * (1 - density) + 0.2\n    weight_coherence = 0.3 * density + 0.1\n\n    # Memory-based penalty\n    visit_counts = {node: 0 for node in range(total_nodes)}\n    for node in unvisited_nodes:\n        visit_counts[node] = sum(1 for n in unvisited_nodes if n == node)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)\n        penalty = 0.1 * visit_counts[node] / (remaining_nodes + 1e-10)\n        return (weight_local * local_distance) + (weight_centrality * centrality) - (weight_coherence * coherence) + penalty\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.52544,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines a nearest-neighbor heuristic (70% weight) with a global measure (30% weight) that balances centrality (inverse sum of all distances) and inverse average distance to unvisited nodes. It prioritizes local proximity (via nearest neighbor) while incorporating limited global considerations to avoid myopia, with the hybrid score ensuring a trade-off between immediate and long-term optimization.",
          "thought": "The new algorithm combines the nearest neighbor heuristic from No.2 with a refined global measure that considers both centrality and inverse global distance, inspired by No.1, to balance local and global optimization with a hybrid score (70% local, 30% global).",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    nearest_neighbor = min(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])\n    global_measure = lambda node: 0.7 * (1 / (sum(distance_matrix[node][n] for n in range(len(distance_matrix))) + 1e-10)) + 0.3 * (1 / (sum(distance_matrix[node][n] for n in unvisited_nodes) / len(unvisited_nodes) + 1e-10))\n    hybrid_score = lambda node: 0.7 * distance_matrix[current_node][node] + 0.3 * global_measure(node)\n    next_node = min(unvisited_nodes, key=hybrid_score)\n    return next_node",
          "objective": 6.52706,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically adjusts selection priorities based on entropy and remaining path flexibility, favoring local distance for low-entropy paths and coherence for high-entropy ones. It balances three weighted factors (local distance, centrality, and coherence) using entropy-based scaling, with coherence given higher emphasis in uncertain scenarios. The weights are recalculated at each step, emphasizing local factors early and coherence later, while centrality plays a moderate role throughout.",
          "thought": "The new algorithm introduces a dynamic weight adjustment mechanism based on node entropy and remaining path flexibility, where weights for local distance, centrality, and coherence are recalculated at each step using a non-linear entropy-based scaling factor that prioritizes coherence for high-entropy (unpredictable) paths and local factors for low-entropy paths.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n\n    # Calculate entropy-based scaling factor\n    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes\n    entropy_factor = 1 - (avg_distance / max(sum(row) for row in distance_matrix) if max(sum(row) for row in distance_matrix) != 0 else 1)\n\n    # Dynamic weight adjustment\n    weight_coherence = 0.6 * (1 - entropy_factor) + 0.3 * (remaining_nodes / total_nodes)\n    weight_local = 0.3 * entropy_factor + 0.2 * (remaining_nodes / total_nodes)\n    weight_centrality = 0.4 * (1 - entropy_factor) + 0.1 * (remaining_nodes / total_nodes)\n\n    def calculate_score(node):\n        local_distance = distance_matrix[current_node][node]\n        centrality = 1 / (sum(distance_matrix[node][n] for n in range(total_nodes)) + 1e-10)\n        coherence = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1 if remaining_nodes > 1 else 1)\n\n        # Novel scoring mechanism with entropy-based adjustments\n        local_term = weight_local * (local_distance / (1 + entropy_factor))\n        centrality_term = weight_centrality * (centrality * (1 + entropy_factor))\n        coherence_term = weight_coherence * (coherence / (1 + entropy_factor))\n\n        return local_term + centrality_term - coherence_term\n\n    next_node = min(unvisited_nodes, key=calculate_score)\n    return next_node",
          "objective": 6.53031,
          "other_inf": null
     }
]