def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    next_node = None
    best_score = float('inf')
    num_unvisited = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Adaptive weights based on exploration stage
    exploration_stage = num_unvisited / total_nodes
    weight_proximity = 0.5 * (0.7 + 0.3 * exploration_stage)
    weight_future = 0.3 * (0.3 * (1 - exploration_stage))
    weight_detour = 0.2 * (0.8 + 0.2 * exploration_stage)

    # Dynamic detour penalty
    detour_threshold = 1.2 * distance_matrix[current_node][destination_node]
    detour_penalty_factor = 1.5 if num_unvisited < total_nodes * 0.3 else 1.0

    for node in unvisited_nodes:
        distance_to_node = distance_matrix[current_node][node]
        avg_future_distance = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / max(1, num_unvisited - 1)
        detour_cost = distance_matrix[node][destination_node] - distance_matrix[current_node][destination_node]
        normalized_detour = detour_cost / detour_threshold if detour_threshold > 0 else 0

        # Dynamic penalty based on detour and exploration stage
        penalty = 0.1 * (1 - exploration_stage) + detour_penalty_factor * max(0, normalized_detour)

        # Score calculation with probabilistic element
        score = (weight_proximity * distance_to_node +
                 weight_future * avg_future_distance +
                 weight_detour * detour_cost +
                 penalty)

        if score < best_score:
            best_score = score
            next_node = node

    # Probabilistic selection for late stages to explore alternatives
    if exploration_stage < 0.5 and num_unvisited > 1:
        candidates = [node for node in unvisited_nodes if distance_matrix[current_node][node] <= 1.2 * distance_matrix[current_node][next_node]]
        if candidates and len(candidates) > 1:
            next_node = random.choice(candidates)

    return next_node
