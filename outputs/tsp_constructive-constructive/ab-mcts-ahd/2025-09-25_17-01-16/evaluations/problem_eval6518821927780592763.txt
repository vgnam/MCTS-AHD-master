import math
import random

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    next_node = None
    best_score = float('inf')
    total_unvisited = len(unvisited_nodes)

    # Historical preference tracking (simplified for demonstration)
    historical_preferences = {node: 1.0 for node in unvisited_nodes}

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]
        distance_to_destination = distance_matrix[node][destination_node]

        # Adaptive exploration-exploitation trade-off
        exploration_factor = 1.0 / (1.0 + math.exp(-(total_unvisited - len(unvisited_nodes) + 1)))
        exploitation_factor = 1.0 - exploration_factor

        # Probabilistic weighting based on historical preferences
        preference_weight = historical_preferences[node]
        normalized_preference = preference_weight / sum(historical_preferences.values())

        # Combined score with adaptive factors
        if distance_to_destination == 0:
            score = distance_to_current * (1 + exploitation_factor)
        else:
            ratio = distance_to_current / distance_to_destination
            score = (exploitation_factor * distance_to_current +
                     exploration_factor * ratio) * (1 + normalized_preference)

        if score < best_score:
            best_score = score
            next_node = node

    # Update historical preferences (simplified)
    if next_node is not None:
        historical_preferences[next_node] *= 1.1  # Increase preference for selected node

    return next_node
