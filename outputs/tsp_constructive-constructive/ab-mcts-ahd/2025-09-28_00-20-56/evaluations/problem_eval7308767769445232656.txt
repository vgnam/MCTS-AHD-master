def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    total_remaining_distance = sum(distance_matrix[node][destination_node] for node in unvisited_nodes)
    avg_remaining_distance = total_remaining_distance / len(unvisited_nodes)

    def evaluate_node(node):
        current_dist = distance_matrix[current_node][node]

        if len(unvisited_nodes) > 1:
            remaining_nodes = [n for n in unvisited_nodes if n != node]

            # Calculate centrality: average distance from node to all unvisited nodes
            centrality = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)

            # Dynamic weight based on centrality and efficiency
            efficiency_factor = (avg_remaining_distance / centrality) ** 0.5

            # Probabilistic component with memory-based adjustment
            memory_factor = 1.0 - (0.3 * (1 - (current_dist / sum(distance_matrix[current_node][n] for n in unvisited_nodes))))

            # Centrality-adjusted lookahead score
            best_lookahead = min(remaining_nodes, key=lambda n: distance_matrix[node][n] + distance_matrix[n][destination_node])
            lookahead_dist = distance_matrix[node][best_lookahead] + distance_matrix[best_lookahead][destination_node]
            adjusted_lookahead_dist = lookahead_dist * efficiency_factor * memory_factor
        else:
            adjusted_lookahead_dist = distance_matrix[node][destination_node]
            memory_factor = 1.0

        # Novel score combining immediate distance, lookahead, and memory
        return (current_dist + 0.6 * adjusted_lookahead_dist) * memory_factor

    next_node = min(unvisited_nodes, key=evaluate_node)
    return next_node
