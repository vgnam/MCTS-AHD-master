def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    next_node = None
    best_score = -float('inf')
    remaining_nodes = len(unvisited_nodes)

    # Initialize penalty dictionary if not exists (simulated here)
    penalty = {node: 0 for node in unvisited_nodes}

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        lookahead_distance = distance_matrix[node][destination_node]

        # Dynamic penalty based on historical selection and proximity to destination
        penalty_factor = (1.0 + penalty[node]) * (1.0 + lookahead_distance / max(distance_matrix[node]))
        normalized_penalty = penalty_factor / (1.0 + remaining_nodes)

        # Probabilistic bias favoring immediate distance but considering lookahead
        selection_probability = (1.0 / (1.0 + immediate_distance)) * (1.0 + 0.5 * (1.0 / (1.0 + lookahead_distance)))

        # Combined score with adaptive penalty
        score = selection_probability - normalized_penalty

        if score > best_score:
            best_score = score
            next_node = node

    # Update penalty for the selected node (simulated here)
    if next_node is not None:
        penalty[next_node] += 1

    return next_node
