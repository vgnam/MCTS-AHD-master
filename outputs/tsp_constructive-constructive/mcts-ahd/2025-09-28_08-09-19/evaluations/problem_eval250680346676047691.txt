def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    next_node = None
    min_score = float('inf')
    remaining_nodes = len(unvisited_nodes)
    base_weight = 0.7  # Increased from 0.6 to prioritize immediate distance more initially
    dynamic_weight = 1.0 / (1.0 + remaining_nodes ** 1.5)  # Sharper decay with exponent
    exploration_factor = 0.3 * (1 - remaining_nodes / len(distance_matrix))  # Probabilistic exploration

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]

        if len(unvisited_nodes) == 1:
            avg_distance = 0
        else:
            avg_distance = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (len(unvisited_nodes) - 1)

        # Reinforcement learning-inspired adjustment
        performance_bias = 0.5 if node == destination_node else 1.0  # Prefer destination
        score = (base_weight * distance_to_current + (1 - base_weight) * dynamic_weight * avg_distance) * performance_bias

        # Add probabilistic element
        if exploration_factor > 0 and random.random() < exploration_factor:
            score *= 0.8  # Slightly favor randomness

        if score < min_score:
            min_score = score
            next_node = node

    return next_node
