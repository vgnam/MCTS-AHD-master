def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    next_node = None
    min_score = float('inf')
    base_decay = 0.5
    exploration_factor = 0.3
    remaining_ratio = len(unvisited_nodes) / (len(distance_matrix) - 1)

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]
        distance_to_destination = distance_matrix[node][destination_node]

        # Dynamic weighting with exploration bonus
        alignment_score = (1 - distance_to_destination / max(distance_matrix[node])) * (1 + exploration_factor * remaining_ratio)
        penalty = max(0, distance_to_current - 1.5 * distance_matrix[current_node][destination_node])

        # Reinforcement learning-inspired score update
        score = distance_to_current * (alignment_score ** base_decay) + penalty * (1 + 0.5 * (1 - remaining_ratio))

        if score < min_score:
            min_score = score
            next_node = node

    return next_node
