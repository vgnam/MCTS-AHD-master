importance, and global path optimization by incorporating a reinforcement learning-inspired scoring system with decaying weights for past selections and a probabilistic selection based on normalized scores, while preserving the original penalty for nodes near the destination.}

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    next_node = None
    scores = []
    remaining_nodes = len(unvisited_nodes)

    for node in unvisited_nodes:
        distance_to_current = distance_matrix[current_node][node]
        distance_to_destination = distance_matrix[node][destination_node]

        if remaining_nodes == 1:
            score = distance_to_current + distance_to_destination
        else:
            # Node importance: combination of centrality and connectivity
            centrality = 1.0 / (sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / (remaining_nodes - 1)) if remaining_nodes > 1 else 0
            connectivity = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.2 * distance_to_current) / remaining_nodes
            importance = 0.6 * centrality + 0.4 * connectivity

            # Dynamic weight adjustment based on exploration/exploitation trade-off
            exploration_weight = 0.3 * (remaining_nodes / (remaining_nodes + 1))
            exploitation_weight = 0.7 * (1 - exploration_weight)

            # Reinforcement learning-inspired decay factor
            decay_factor = 0.9 ** (remaining_nodes / len(unvisited_nodes))
            weighted_distance = distance_to_current * decay_factor

            # Penalty for nodes near destination (modified)
            proximity_penalty = 0.5 * (distance_to_destination / (1.0 + weighted_distance)) if weighted_distance > 0 else 0

            # Combined score with probabilistic element
            score = (exploitation_weight * weighted_distance +
                     exploration_weight * importance) - proximity_penalty

        scores.append((node, score))

    # Probabilistic selection based on normalized scores
    if scores:
        min_score = min(score for _, score in scores)
        max_score = max(score for _, score in scores)
        normalized_scores = [(node, (score - min_score) / (max_score - min_score + 1e-6)) for node, score in scores]
        next_node = min(normalized_scores, key=lambda x: x[1])[0]

    return next_node
