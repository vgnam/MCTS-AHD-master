def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    next_node = None
    best_score = float('-inf')
    remaining_nodes = len(unvisited_nodes)
    base_weight = 0.5
    centrality_weight = 0.3 + 0.4 * (1.0 - remaining_nodes / (remaining_nodes + 1))
    continuity_weight = 0.2 + 0.3 * (remaining_nodes / (remaining_nodes + 1))

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_potential = sum(distance_matrix[node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes) if unvisited_nodes else 0
        destination_distance = distance_matrix[node][destination_node]

        # Dynamic centrality measure: average distance to all unvisited nodes
        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / len(unvisited_nodes) if unvisited_nodes else 0

        # Continuity penalty: discourages large jumps when path is long
        continuity_penalty = immediate_distance * (1.0 - 1.0 / (1.0 + remaining_nodes))

        # Reinforcement learning-inspired scoring
        score = (base_weight * (1.0 / (1.0 + immediate_distance)) +
                 centrality_weight * (1.0 / (1.0 + centrality)) -
                 continuity_weight * continuity_penalty +
                 0.3 * (1.0 / (1.0 + destination_distance)))

        if score > best_score:
            best_score = score
            next_node = node

    return next_node
