[
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with dynamic weight adjustment, prioritizing local costs early in the search and shifting to global potential as progress advances, while incorporating regret terms to avoid costly alternatives and diversity bonuses to prevent clustering. The weight shifts from local (1.0) to global (1.6) as progress increases, and temperature balances exploration (0.8) and exploitation (0.1) similarly. The regret term prioritizes high-cost alternatives, and the diversity bonus discourages clustering, with the destination being prioritized if it is nearby relative to average distances.",
          "thought": "The new algorithm combines nearest-neighbor selection with dynamic weight adjustment, global potential estimation, regret consideration, diversity encouragement, and temperature scaling, where the weight shifts from local to global focus, the regret term prioritizes high-cost alternatives, diversity bonus prevents clustering, and temperature balances exploration and exploitation, all while prioritizing the destination if it is nearby relative to the average distance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.1:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.6 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.4 * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.34249,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential, with adaptive thresholding for destination proximity, while incorporating regret minimization and diversity encouragement. It dynamically adjusts weights based on remaining nodes and prioritizes the destination when it's nearby relative to average distances. The heuristic combines distance to current node, potential to destination, predictive factors, regret terms, and diversity bonuses, with weights shifting toward local proximity as progress advances.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by a progress factor) and global potential, incorporating predictive factors, regret minimization, diversity encouragement, and adaptive thresholding based on remaining nodes, while prioritizing the destination node when it's nearby relative to the average distance to unvisited nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.3722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines **progress-dependent weighting** of immediate cost, regret, and hub connectivity, with **dynamic temperature modulation** and **diversity bonuses** to balance early exploration and late exploitation. It prioritizes **nearby nodes with low regret** early on but shifts to **hub nodes with high connectivity** later, while maintaining path diversity through a **diversity penalty**. The weights (`weight`, `temperature`) decrease with progress, favoring **immediate cost and hubs** in the later stages, while the **diversity bonus** discourages repetitive paths.",
          "thought": "The new algorithm combines progress-dependent weighting of immediate cost, regret, and hub connectivity with dynamic temperature modulation and diversity bonuses, balancing early exploration and late exploitation while prioritizing strategic hubs and maintaining path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.6 - 0.3 * progress\n    temperature = 0.8 - 0.5 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.15 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.3 * hub_score) * temperature - 0.35 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.38553,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights between immediate proximity (higher priority) and regret minimization (lower priority) based on progress, while using temperature modulation to refine selection. It also incorporates hub centrality and diversity bonuses to prioritize nodes with high connectivity and diversity, with the hub score and diversity bonus given moderate and lower priorities, respectively. The weight and temperature parameters adapt to progress, making early decisions more exploratory and later ones more exploitative.",
          "thought": "The new algorithm combines dynamic progress-based weighting between immediate proximity and regret minimization, with adaptive temperature modulation to balance exploration and exploitation, while incorporating hub centrality and diversity bonuses to refine selection.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39252,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances local and global optimization by dynamically adjusting weights between immediate distance (to the current node) and long-term potential (to the destination and unvisited nodes), while incorporating regret penalties to avoid suboptimal choices and diversity bonuses to explore alternative paths. The weight parameter shifts from prioritizing local decisions early to favoring global potential as the tour progresses, with regret penalties and diversity bonuses fine-tuning selections to balance exploration and exploitation. The heuristic function combines these factors with modified coefficients (e.g., 1.8, 0.5, 0.3) to refine node selection.",
          "thought": "The new algorithm focuses on balancing immediate distance reduction with long-term path optimization by dynamically adjusting weights between local and global factors, while incorporating regret penalties and diversity bonuses with modified parameters to encourage exploration and avoid premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.2 + (0.8 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.8 - 0.8 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.5 * regret_term) - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40068,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines a weighted balance of immediate cost, regret, and hub connectivity while dynamically adjusting priorities through progress-dependent weighting, temperature modulation, and diversity bonuses. Early stages favor exploration (higher weight on regret and diversity), while later stages emphasize efficiency (higher weight on immediate cost and hub scores). The adaptive regret factor scales with progress, and the hub threshold tightens as nodes are visited, balancing exploration and exploitation.",
          "thought": "This new algorithm combines progress-dependent weighting of immediate cost, regret, and hub connectivity with dynamic temperature modulation and diversity bonuses, while incorporating a novel adaptive regret factor that scales with progress and a hub score threshold that tightens with remaining nodes, balancing early exploration with late exploitation for improved path optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n    hub_threshold = 1.1 + 0.05 * (1 - progress)\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < hub_threshold * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        adaptive_regret = regret * (1 + 0.5 * progress)\n        weighted_score = (weight * immediate_cost + (1 - weight) * adaptive_regret + 0.3 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40485,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weighting, regret minimization, and hub centrality to select the next node in TSP, dynamically balancing local (immediate cost) and global (predictive factors, regret, and hub scores) considerations with temperature modulation and progress-based adjustments. Higher priority is given to immediate cost and regret, while predictive factors and hub scores are weighted lower, with diversity bonuses applied as a penalty. The algorithm adjusts weights and temperature based on progress (1 - remaining nodes/total nodes) to shift focus from exploration to exploitation.",
          "thought": "The new algorithm will combine the adaptive weighting and progress-based adjustments from No.2 with the predictive factors, regret minimization, and diversity encouragement from No.1, while dynamically balancing local and global considerations with temperature modulation and hub centrality.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * (0.7 * regret + 0.3 * predictive_factor) + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42215,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weights for local cost, regret minimization, and diversity bonuses, with selection pressure shifting from exploration (early) to exploitation (late). It prioritizes local cost and regret early (high selection pressure) but balances global potential and diversity late (lower pressure), using a weighted heuristic to select the next node. The progress factor dynamically adjusts weights based on remaining nodes, ensuring a balance between short-term and long-term considerations.",
          "thought": "The new algorithm combines adaptive weights for local cost, global potential, regret minimization, and diversity bonuses, with selection pressure adjusting from exploration to exploitation. It prioritizes local cost early, balances regret and global potential midway, and emphasizes diversity late to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = selection_pressure * (0.6 * local_cost + 0.4 * regret_term) + (1 - selection_pressure) * (0.5 * global_potential) - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42572,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines local proximity (weighted by dynamic `weight`) with global potential (distance to destination and average distances to unvisited nodes) and regret (difference between best and current local cost), while balancing exploration and exploitation via `temperature` and `progress_factor`. The `diversity_bonus` (average distance to unvisited nodes) is subtracted to encourage diversity, and the destination is prioritized early if it is close relative to the average distance. The `weight` and `temperature` adjust dynamically with progress, favoring local costs early and global potential later.",
          "thought": "The new algorithm combines local proximity (prioritized via dynamic weight adjustment) with global potential and regret consideration, incorporating diversity bonuses and dynamic temperature to balance exploration and exploitation as progress advances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.3:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.4 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.2 * regret_term) * temperature - 0.15 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42589,
          "other_inf": null
     }
]