[
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weights for local cost, regret minimization, and diversity bonuses, with selection pressure shifting from exploration (early) to exploitation (late). It prioritizes local cost and regret early (high selection pressure) but balances global potential and diversity late (lower pressure), using a weighted heuristic to select the next node. The progress factor dynamically adjusts weights based on remaining nodes, ensuring a balance between short-term and long-term considerations.",
          "thought": "The new algorithm combines adaptive weights for local cost, global potential, regret minimization, and diversity bonuses, with selection pressure adjusting from exploration to exploitation. It prioritizes local cost early, balances regret and global potential midway, and emphasizes diversity late to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = selection_pressure * (0.6 * local_cost + 0.4 * regret_term) + (1 - selection_pressure) * (0.5 * global_potential) - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42572,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines local proximity (weighted by dynamic `weight`) with global potential (distance to destination and average distances to unvisited nodes) and regret (difference between best and current local cost), while balancing exploration and exploitation via `temperature` and `progress_factor`. The `diversity_bonus` (average distance to unvisited nodes) is subtracted to encourage diversity, and the destination is prioritized early if it is close relative to the average distance. The `weight` and `temperature` adjust dynamically with progress, favoring local costs early and global potential later.",
          "thought": "The new algorithm combines local proximity (prioritized via dynamic weight adjustment) with global potential and regret consideration, incorporating diversity bonuses and dynamic temperature to balance exploration and exploitation as progress advances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.3:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.4 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.2 * regret_term) * temperature - 0.15 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42589,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure (higher early on) and temperature (starting high for exploration), while incorporating regret terms (lower weight) and diversity bonuses (negative weight) to guide node selection toward promising but diverse paths. Local cost has higher priority in early stages, while global potential and regret terms gain importance as progress advances, with diversity bonuses slightly discouraging redundant choices.",
          "thought": "The new algorithm emphasizes early global optimization with high initial temperature (0.9) and gradually shifts to local refinement, using a more aggressive selection pressure (0.7) and reduced regret weighting (0.05), while increasing diversity penalty (-0.4) to encourage exploration.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.7 + 0.3 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.05 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44991,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure adjustment with progressive focus shift, prioritizing local cost early in the search (high selection pressure) and shifting to global potential later (lower pressure). It incorporates weighted regret and diversity-aware global potential assessment, with temperature and selection pressure adapting based on progress. The heuristic balances local cost (high initial weight), global potential (lower weight), regret, and diversity, with decreasing temperature and increasing selection pressure as the search progresses.",
          "thought": "The new algorithm combines No.1's dynamic selection pressure adjustment with No.2's progressive focus shift, incorporating weighted regret consideration and diversity-aware global potential assessment while adapting temperature and selection pressure based on progress.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.2:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 0.9 - 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.25 * regret_term) * temperature - 0.35 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.50806,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure with regret-based optimization, prioritizing local cost minimization (30%) and hub avoidance (20%) early, while increasing global potential evaluation (50%) and diversity rewards (25%) as progress advances. It balances immediate cost savings with long-term efficiency by adjusting weights based on progress and node density, avoiding bottlenecks through centrality-based hub avoidance.",
          "thought": "The new algorithm combines dynamic selection pressure with regret-based optimization, local cost minimization, and global potential evaluation, while incorporating hub avoidance and diversity rewards to balance immediate cost savings with long-term efficiency, avoiding bottlenecks and local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    base_pressure = 0.3 + 0.7 * progress_factor\n    node_density = total_nodes / (sum(sum(row) for row in distance_matrix) + 1e-6)\n    selection_pressure = base_pressure * (1 + 0.2 * node_density)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        min_cost = min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        max_cost = max(distance_matrix[current_node][n] for n in unvisited_nodes)\n        regret = (local_cost - min_cost) / (max_cost - min_cost + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        hub_avoidance = 1 / (centrality + 1e-6)\n        weighted_score = selection_pressure * (0.5 * regret + 0.3 * local_cost + 0.2 * hub_avoidance) + (1 - selection_pressure) * (0.5 * global_potential - 0.25 * diversity_bonus)\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.52355,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure adjustment (prioritizing local cost early) with adaptive temperature scaling (balancing exploration/exploitation) and weighted regret consideration (minimizing suboptimal choices), while incorporating diversity-aware global potential assessment. It progressively shifts focus from local cost to global optimization, regret minimization, and path diversity, with selection pressure and temperature adjusting based on progress. The weighted score formula (selection_pressure * local_cost + (1-selection_pressure) * global_potential + regret_term) dynamically balances these factors, while diversity_bonus is subtracted to encourage path diversity.",
          "thought": "This new algorithm combines dynamic selection pressure adjustment, adaptive temperature scaling, weighted regret consideration, and diversity-aware global potential assessment to create a hybrid heuristic that prioritizes local cost early while progressively balancing global optimization, regret minimization, and path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n    temperature = 1.0 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.2 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.54141,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm enhances traditional TSP heuristics by dynamically balancing local and global decisions through adaptive selection pressure, regret-based node evaluation, and hub avoidance. It prioritizes regret-adjusted costs (60%) and hub avoidance (20%) under high selection pressure, while emphasizing global potential (40%) and proximity bias (30%) as nodes are visited. The heuristic combines node density, centrality, and progress factors to refine node selection, ensuring a mix of exploration and exploitation.",
          "thought": "The new algorithm enhances the provided heuristic by incorporating adaptive selection pressure based on both progress and remaining nodes, introducing a dynamic regret adjustment that considers node connectivity, and adding a hub avoidance mechanism through inverse centrality weighting while preserving the original's global-local balance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    base_pressure = 0.3 + 0.7 * progress_factor\n    node_density = total_nodes / (sum(sum(row) for row in distance_matrix) + 1e-6)\n    selection_pressure = base_pressure * (1 + 0.2 * node_density)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        min_cost = min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        max_cost = max(distance_matrix[current_node][n] for n in unvisited_nodes)\n        regret = (local_cost - min_cost) / (max_cost - min_cost + 1e-6)\n        adjusted_regret = regret * (1 + 0.1 * (centrality / (sum(centrality for n in unvisited_nodes) + 1e-6)))\n        proximity_bias = (1 - remaining_nodes / total_nodes) ** 1.5\n        hub_avoidance = 1 / (centrality + 1e-6)\n        weighted_score = selection_pressure * (0.6 * adjusted_regret + 0.2 * local_cost + 0.2 * hub_avoidance) + (1 - selection_pressure) * (0.4 * global_potential + 0.3 * proximity_bias)\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.56568,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node in TSP by balancing immediate cost (40%), regret (30%), and diversity (30%), with weights dynamically adjusted by progress (exploration_weight). It prioritizes lower local costs, penalizes high regrets (adaptive threshold), and avoids clustering (diversity penalty), while the exploration weight increases as the problem nears completion. The heuristic function combines these factors into a weighted score, ensuring a trade-off between short-term gains and long-term path efficiency.",
          "thought": "This new algorithm modifies the original by incorporating a probabilistic selection mechanism with adaptive regret thresholds and a dynamic exploration-exploitation trade-off, where node selection is influenced by both immediate cost and long-term path potential, using a novel scoring function that combines distance, regret, and diversity with time-dependent weights.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    exploration_weight = 0.3 + 0.7 * progress_factor\n\n    remaining_distance = distance_matrix[current_node][destination_node]\n    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes if remaining_nodes else 0\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        detour_cost = max(0, to_destination - remaining_distance)\n        regret_threshold = local_cost * (1 + 0.5 * (1 - progress_factor))\n        regret_values = [distance_matrix[current_node][n] - local_cost for n in unvisited_nodes if distance_matrix[current_node][n] > regret_threshold]\n        regret_term = sum(regret_values) / len(regret_values) if regret_values else 0\n        diversity_penalty = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        normalized_cost = local_cost / avg_distance if avg_distance else 1.0\n        weighted_score = (0.4 * normalized_cost + 0.3 * regret_term + 0.3 * (1 - diversity_penalty)) * exploration_weight\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.58484,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global considerations by adjusting selection pressure and temperature based on progress, prioritizing immediate costs early while incorporating regret and diversity bonuses later. It evaluates each unvisited node using a weighted heuristic combining current distance, potential to reach the destination, regret (missed opportunities), and diversity (spread of connections), with weights adapting to the remaining nodes. The selection pressure increases and temperature decreases as progress is made, shifting focus from exploration to exploitation.",
          "thought": "The new algorithm combines No.2's dynamic weight balancing with No.1's regret and diversity considerations, adjusting selection pressure and temperature based on progress to prioritize local costs early while incorporating regret terms and diversity bonuses as the path progresses.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.2:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.6 + 0.4 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = distance_matrix[node][destination_node]\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weight = 1 + 0.2 * (remaining_nodes / total_nodes)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.1 * regret_term) * temperature - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.59202,
          "other_inf": null
     }
]