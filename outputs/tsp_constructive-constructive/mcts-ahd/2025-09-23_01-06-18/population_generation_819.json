[
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with dynamic weight adjustment, prioritizing local costs early in the search and shifting to global potential as progress advances, while incorporating regret terms to avoid costly alternatives and diversity bonuses to prevent clustering. The weight shifts from local (1.0) to global (1.6) as progress increases, and temperature balances exploration (0.8) and exploitation (0.1) similarly. The regret term prioritizes high-cost alternatives, and the diversity bonus discourages clustering, with the destination being prioritized if it is nearby relative to average distances.",
          "thought": "The new algorithm combines nearest-neighbor selection with dynamic weight adjustment, global potential estimation, regret consideration, diversity encouragement, and temperature scaling, where the weight shifts from local to global focus, the regret term prioritizes high-cost alternatives, diversity bonus prevents clustering, and temperature balances exploration and exploitation, all while prioritizing the destination if it is nearby relative to the average distance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.1:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.6 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.4 * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.34249,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local (current node distance) and global (destination proximity) considerations with adaptive weights, using regret minimization to avoid poor local choices, and encourages diversity to explore alternatives. It aggressively prioritizes the destination when near the end (via the threshold check) and adjusts weights dynamically based on remaining nodes, shifting from stronger global focus early to local focus later. The heuristic function combines weighted local/global distances, regret terms, and diversity bonuses, with parameters like `weight` (1.8-0.8) and `progress_factor` controlling priority shifts.",
          "thought": "The new algorithm combines dynamic weight adjustment (balancing local and global considerations with adaptive progress factors), regret minimization (prioritizing potential improvements), and diversity encouragement (exploring alternatives), while aggressively prioritizing the destination when near the end and adjusting weights based on remaining nodes (stronger global focus initially, shifting to local focus later).",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.8 - 0.8 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.4 * regret_term) - 0.4 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.34792,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines **local proximity**, **global potential**, and **exploration** by dynamically adjusting weights based on progress (via `progress_factor` and `weight`), incorporating **regret minimization** (via `regret_term`), and encouraging **diversity** (via `diversity_bonus`). It prioritizes **local proximity** early in the search (higher `weight`) and shifts toward **global potential** as progress increases, while penalizing high regret and rewarding diverse node selections. The heuristic dynamically balances these factors using adaptive thresholds and predictive estimates.",
          "thought": "The new algorithm combines the dynamic weight adjustment and regret penalties from No.1 with the adaptive thresholding and predictive factors from No.2, creating a heuristic that balances local proximity, global potential, and exploration while dynamically adjusting weights based on progress and incorporating regret minimization and diversity encouragement.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.2 + (0.8 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.6 - 0.6 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.4 * regret_term) - 0.4 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.36399,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines local cost, global potential, regret, and diversity considerations, with weights dynamically adjusted based on progress (progress_factor). Early stages prioritize local cost and regret (weighted higher), while later stages emphasize global potential and diversity (lower weights). The temperature parameter introduces stochasticity, and the diversity_bonus discourages clustering. The heuristic function balances these factors multiplicatively, with regret_term scaled by regret_weight.",
          "thought": "The new algorithm combines the dynamic weight adjustment from No.1 and No.4, the global potential and regret consideration from No.3, the diversity bonus from No.4, and the early destination prioritization from No.2, while introducing adaptive regret weighting and a more aggressive weight shift to balance local and global considerations more effectively.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.15:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.5 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n    regret_weight = 0.3 * (1 - progress_factor)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + regret_weight * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.36425,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential (predictive factors and destination proximity), with adaptive weights shifting toward local proximity as progress advances. It incorporates regret minimization and diversity encouragement, while dynamically adjusting a threshold for destination proximity based on remaining nodes. The heuristic function combines distance to current node, global potential (averaged with destination distance and predictive factors), regret terms, and diversity bonuses, with weights favoring local proximity early in the process.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential, incorporating adaptive thresholding for destination proximity, predictive factors, regret minimization, and diversity encouragement, with weights shifting toward local proximity as progress advances and global potential as remaining nodes increase, while prioritizing the destination when it's nearby relative to average distances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.4 * regret_term) - 0.6 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.37111,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential, with adaptive thresholding for destination proximity, while incorporating regret minimization and diversity encouragement. It dynamically adjusts weights based on remaining nodes and prioritizes the destination when it's nearby relative to average distances. The heuristic combines distance to current node, potential to destination, predictive factors, regret terms, and diversity bonuses, with weights shifting toward local proximity as progress advances.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by a progress factor) and global potential, incorporating predictive factors, regret minimization, diversity encouragement, and adaptive thresholding based on remaining nodes, while prioritizing the destination node when it's nearby relative to the average distance to unvisited nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.3722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment (prioritizing destination proximity when few nodes remain) with regret penalties (avoiding suboptimal choices) and diversity bonuses (exploring alternatives), while balancing direct and predictive factors through weighted scoring. The heuristic prioritizes minimizing immediate distances (weighted by remaining nodes) while considering global potential (predictive factors) and trade-offs (regret and diversity terms), dynamically adjusting thresholds based on node density.",
          "thought": "The new algorithm combines dynamic weight adjustment based on remaining nodes, predictive factors considering global potential, regret penalties to avoid suboptimal choices, and diversity bonuses to explore alternatives, while prioritizing direct destination selection when near the end, with weights scaling inversely with visited nodes and thresholds adjusting based on the ratio of remaining nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 0.5 + (0.5 * (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        weight = 2.0 - remaining_ratio\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + predictive_factor * (1.0 - weight) + 0.5 * regret_term) - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.37824,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines **progress-dependent weighting** of immediate cost, regret, and hub connectivity, with **dynamic temperature modulation** and **diversity bonuses** to balance early exploration and late exploitation. It prioritizes **nearby nodes with low regret** early on but shifts to **hub nodes with high connectivity** later, while maintaining path diversity through a **diversity penalty**. The weights (`weight`, `temperature`) decrease with progress, favoring **immediate cost and hubs** in the later stages, while the **diversity bonus** discourages repetitive paths.",
          "thought": "The new algorithm combines progress-dependent weighting of immediate cost, regret, and hub connectivity with dynamic temperature modulation and diversity bonuses, balancing early exploration and late exploitation while prioritizing strategic hubs and maintaining path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.6 - 0.3 * progress\n    temperature = 0.8 - 0.5 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.15 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.3 * hub_score) * temperature - 0.35 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.38553,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights between immediate proximity (higher priority) and regret minimization (lower priority) based on progress, while using temperature modulation to refine selection. It also incorporates hub centrality and diversity bonuses to prioritize nodes with high connectivity and diversity, with the hub score and diversity bonus given moderate and lower priorities, respectively. The weight and temperature parameters adapt to progress, making early decisions more exploratory and later ones more exploitative.",
          "thought": "The new algorithm combines dynamic progress-based weighting between immediate proximity and regret minimization, with adaptive temperature modulation to balance exploration and exploitation, while incorporating hub centrality and diversity bonuses to refine selection.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39252,
          "other_inf": null
     }
]