[
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure (higher early on) and temperature (starting high for exploration), while incorporating regret terms (lower weight) and diversity bonuses (negative weight) to guide node selection toward promising but diverse paths. Local cost has higher priority in early stages, while global potential and regret terms gain importance as progress advances, with diversity bonuses slightly discouraging redundant choices.",
          "thought": "The new algorithm emphasizes early global optimization with high initial temperature (0.9) and gradually shifts to local refinement, using a more aggressive selection pressure (0.7) and reduced regret weighting (0.05), while increasing diversity penalty (-0.4) to encourage exploration.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.7 + 0.3 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.05 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44991,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure with regret-based optimization, prioritizing local cost minimization (30%) and hub avoidance (20%) early, while increasing global potential evaluation (50%) and diversity rewards (25%) as progress advances. It balances immediate cost savings with long-term efficiency by adjusting weights based on progress and node density, avoiding bottlenecks through centrality-based hub avoidance.",
          "thought": "The new algorithm combines dynamic selection pressure with regret-based optimization, local cost minimization, and global potential evaluation, while incorporating hub avoidance and diversity rewards to balance immediate cost savings with long-term efficiency, avoiding bottlenecks and local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    base_pressure = 0.3 + 0.7 * progress_factor\n    node_density = total_nodes / (sum(sum(row) for row in distance_matrix) + 1e-6)\n    selection_pressure = base_pressure * (1 + 0.2 * node_density)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        min_cost = min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        max_cost = max(distance_matrix[current_node][n] for n in unvisited_nodes)\n        regret = (local_cost - min_cost) / (max_cost - min_cost + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        hub_avoidance = 1 / (centrality + 1e-6)\n        weighted_score = selection_pressure * (0.5 * regret + 0.3 * local_cost + 0.2 * hub_avoidance) + (1 - selection_pressure) * (0.5 * global_potential - 0.25 * diversity_bonus)\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.52355,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure adjustment (prioritizing local cost early) with adaptive temperature scaling (balancing exploration/exploitation) and weighted regret consideration (minimizing suboptimal choices), while incorporating diversity-aware global potential assessment. It progressively shifts focus from local cost to global optimization, regret minimization, and path diversity, with selection pressure and temperature adjusting based on progress. The weighted score formula (selection_pressure * local_cost + (1-selection_pressure) * global_potential + regret_term) dynamically balances these factors, while diversity_bonus is subtracted to encourage path diversity.",
          "thought": "This new algorithm combines dynamic selection pressure adjustment, adaptive temperature scaling, weighted regret consideration, and diversity-aware global potential assessment to create a hybrid heuristic that prioritizes local cost early while progressively balancing global optimization, regret minimization, and path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n    temperature = 1.0 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.2 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.54141,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm enhances traditional TSP heuristics by dynamically balancing local and global decisions through adaptive selection pressure, regret-based node evaluation, and hub avoidance. It prioritizes regret-adjusted costs (60%) and hub avoidance (20%) under high selection pressure, while emphasizing global potential (40%) and proximity bias (30%) as nodes are visited. The heuristic combines node density, centrality, and progress factors to refine node selection, ensuring a mix of exploration and exploitation.",
          "thought": "The new algorithm enhances the provided heuristic by incorporating adaptive selection pressure based on both progress and remaining nodes, introducing a dynamic regret adjustment that considers node connectivity, and adding a hub avoidance mechanism through inverse centrality weighting while preserving the original's global-local balance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    base_pressure = 0.3 + 0.7 * progress_factor\n    node_density = total_nodes / (sum(sum(row) for row in distance_matrix) + 1e-6)\n    selection_pressure = base_pressure * (1 + 0.2 * node_density)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        min_cost = min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        max_cost = max(distance_matrix[current_node][n] for n in unvisited_nodes)\n        regret = (local_cost - min_cost) / (max_cost - min_cost + 1e-6)\n        adjusted_regret = regret * (1 + 0.1 * (centrality / (sum(centrality for n in unvisited_nodes) + 1e-6)))\n        proximity_bias = (1 - remaining_nodes / total_nodes) ** 1.5\n        hub_avoidance = 1 / (centrality + 1e-6)\n        weighted_score = selection_pressure * (0.6 * adjusted_regret + 0.2 * local_cost + 0.2 * hub_avoidance) + (1 - selection_pressure) * (0.4 * global_potential + 0.3 * proximity_bias)\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.56568,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node in TSP by balancing immediate cost (40%), regret (30%), and diversity (30%), with weights dynamically adjusted by progress (exploration_weight). It prioritizes lower local costs, penalizes high regrets (adaptive threshold), and avoids clustering (diversity penalty), while the exploration weight increases as the problem nears completion. The heuristic function combines these factors into a weighted score, ensuring a trade-off between short-term gains and long-term path efficiency.",
          "thought": "This new algorithm modifies the original by incorporating a probabilistic selection mechanism with adaptive regret thresholds and a dynamic exploration-exploitation trade-off, where node selection is influenced by both immediate cost and long-term path potential, using a novel scoring function that combines distance, regret, and diversity with time-dependent weights.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    exploration_weight = 0.3 + 0.7 * progress_factor\n\n    remaining_distance = distance_matrix[current_node][destination_node]\n    avg_distance = sum(distance_matrix[current_node][n] for n in unvisited_nodes) / remaining_nodes if remaining_nodes else 0\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        detour_cost = max(0, to_destination - remaining_distance)\n        regret_threshold = local_cost * (1 + 0.5 * (1 - progress_factor))\n        regret_values = [distance_matrix[current_node][n] - local_cost for n in unvisited_nodes if distance_matrix[current_node][n] > regret_threshold]\n        regret_term = sum(regret_values) / len(regret_values) if regret_values else 0\n        diversity_penalty = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        normalized_cost = local_cost / avg_distance if avg_distance else 1.0\n        weighted_score = (0.4 * normalized_cost + 0.3 * regret_term + 0.3 * (1 - diversity_penalty)) * exploration_weight\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.58484,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines regret-based local optimization with global potential evaluation, dynamically adjusting weights based on progress (favoring local costs early, global potential later) while penalizing centrality and diversity to avoid clustering. The heuristic prioritizes regret (weighted by progress) and local/global costs (70%/30%), with secondary penalties for centrality and diversity. The weight smoothly transitions from local to global focus as progress increases, ensuring a balance between short-term and long-term optimization.",
          "thought": "The new algorithm combines the dynamic weight adjustment of No.2 with the regret-based optimization and global potential evaluation of No.1, while incorporating centrality and diversity penalties to avoid clustering, and uses a nonlinear progress-based weight to balance local and global optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = (total_nodes - remaining_nodes) / total_nodes\n    weight = (1 - progress) ** 2\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = distance_matrix[node][destination_node]\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        return (1 - weight) * regret + weight * (0.7 * local_cost + 0.3 * global_potential) - 0.2 * centrality - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.59768,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines regret-based optimization (60% weight), local cost minimization (30% weight), and global potential evaluation (25% weight) while penalizing high-centrality nodes (-0.2 weight) and rewarding diversity (-0.25 weight). It dynamically adjusts selection pressure based on progress (progress_factor) to balance immediate cost savings with long-term efficiency, avoiding bottlenecks and local optima. The heuristic function prioritizes regret (early stages) and local/global trade-offs (later stages) while penalizing centrality and rewarding diversity.",
          "thought": "This new algorithm combines dynamic selection pressure adjustment with a hybrid heuristic that integrates regret-based optimization (60% weight), local cost minimization (30% weight), and global potential evaluation (25% weight), while penalizing high-centrality nodes (-0.2 weight) and rewarding diversity (-0.25 weight) to balance immediate cost savings with long-term efficiency and avoid bottlenecks and local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (1 - selection_pressure) * regret + selection_pressure * (0.6 * local_cost + 0.25 * global_potential) - 0.2 * centrality - 0.25 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.61994,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines multiple heuristics (regret minimization, local cost, global potential, proximity bias, and centrality penalty) with adaptive weights that adjust based on progress (selection pressure). Higher priority is given to regret minimization (70% weight) and local cost (30% weight) when selection pressure is high, while global potential (50% weight) and proximity bias (30% weight) dominate when selection pressure is low. Centrality penalty (20% weight) and diversity bonuses are used to avoid local optima, with weights dynamically adjusted to balance exploration and exploitation. The heuristic function evaluates each candidate node based on these weighted components, selecting the node with the lowest score.",
          "thought": "The new algorithm combines regret minimization (70% weight), local cost (30% weight), global potential (50% weight), proximity bias (30% weight), and centrality penalty (20% weight) under adaptive selection pressure, dynamically adjusting weights based on progress to balance exploration and exploitation while incorporating diversity bonuses to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.3 + 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n        proximity_bias = (1 - remaining_nodes / total_nodes) ** 2\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = selection_pressure * (0.7 * regret + 0.3 * local_cost) + (1 - selection_pressure) * (0.5 * global_potential + 0.3 * proximity_bias) - 0.2 * centrality - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.63099,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes local proximity (distance to current node) when few nodes remain, using a dynamic weight that scales inversely with unvisited nodes. When the destination is near, it switches to direct routing, with a threshold based on visited/total nodes. Predictive factors (average distances to remaining nodes) gain importance as more nodes are unvisited, balancing short-term and long-term efficiency. The heuristic function combines weighted distances to the current node and predictive factors, adjusting weights dynamically.",
          "thought": "The new algorithm prioritizes predictive factors when few nodes remain, using a dynamic weight that scales with the inverse of unvisited nodes, and switches to local proximity when the destination is near, with a threshold adjusted by the ratio of visited to total nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        weight = 2.0 - remaining_ratio\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        return to_current * weight + predictive_factor * (1.0 - weight)\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.64273,
          "other_inf": null
     }
]