[
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with dynamic weight adjustment, prioritizing local costs early in the search and shifting to global potential as progress advances, while incorporating regret terms to avoid costly alternatives and diversity bonuses to prevent clustering. The weight shifts from local (1.0) to global (1.6) as progress increases, and temperature balances exploration (0.8) and exploitation (0.1) similarly. The regret term prioritizes high-cost alternatives, and the diversity bonus discourages clustering, with the destination being prioritized if it is nearby relative to average distances.",
          "thought": "The new algorithm combines nearest-neighbor selection with dynamic weight adjustment, global potential estimation, regret consideration, diversity encouragement, and temperature scaling, where the weight shifts from local to global focus, the regret term prioritizes high-cost alternatives, diversity bonus prevents clustering, and temperature balances exploration and exploitation, all while prioritizing the destination if it is nearby relative to the average distance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.1:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.6 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.4 * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.34249,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential, with adaptive thresholding for destination proximity, while incorporating regret minimization and diversity encouragement. It dynamically adjusts weights based on remaining nodes and prioritizes the destination when it's nearby relative to average distances. The heuristic combines distance to current node, potential to destination, predictive factors, regret terms, and diversity bonuses, with weights shifting toward local proximity as progress advances.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by a progress factor) and global potential, incorporating predictive factors, regret minimization, diversity encouragement, and adaptive thresholding based on remaining nodes, while prioritizing the destination node when it's nearby relative to the average distance to unvisited nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.3722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights between immediate proximity (higher priority) and regret minimization (lower priority) based on progress, while using temperature modulation to refine selection. It also incorporates hub centrality and diversity bonuses to prioritize nodes with high connectivity and diversity, with the hub score and diversity bonus given moderate and lower priorities, respectively. The weight and temperature parameters adapt to progress, making early decisions more exploratory and later ones more exploitative.",
          "thought": "The new algorithm combines dynamic progress-based weighting between immediate proximity and regret minimization, with adaptive temperature modulation to balance exploration and exploitation, while incorporating hub centrality and diversity bonuses to refine selection.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39252,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances local and global optimization by dynamically adjusting weights between immediate distance (to the current node) and long-term potential (to the destination and unvisited nodes), while incorporating regret penalties to avoid suboptimal choices and diversity bonuses to explore alternative paths. The weight parameter shifts from prioritizing local decisions early to favoring global potential as the tour progresses, with regret penalties and diversity bonuses fine-tuning selections to balance exploration and exploitation. The heuristic function combines these factors with modified coefficients (e.g., 1.8, 0.5, 0.3) to refine node selection.",
          "thought": "The new algorithm focuses on balancing immediate distance reduction with long-term path optimization by dynamically adjusting weights between local and global factors, while incorporating regret penalties and diversity bonuses with modified parameters to encourage exploration and avoid premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.2 + (0.8 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.8 - 0.8 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.5 * regret_term) - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40068,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weights for local cost, regret minimization, and diversity bonuses, with selection pressure shifting from exploration (early) to exploitation (late). It prioritizes local cost and regret early (high selection pressure) but balances global potential and diversity late (lower pressure), using a weighted heuristic to select the next node. The progress factor dynamically adjusts weights based on remaining nodes, ensuring a balance between short-term and long-term considerations.",
          "thought": "The new algorithm combines adaptive weights for local cost, global potential, regret minimization, and diversity bonuses, with selection pressure adjusting from exploration to exploitation. It prioritizes local cost early, balances regret and global potential midway, and emphasizes diversity late to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = selection_pressure * (0.6 * local_cost + 0.4 * regret_term) + (1 - selection_pressure) * (0.5 * global_potential) - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42572,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines local proximity (weighted by dynamic `weight`) with global potential (distance to destination and average distances to unvisited nodes) and regret (difference between best and current local cost), while balancing exploration and exploitation via `temperature` and `progress_factor`. The `diversity_bonus` (average distance to unvisited nodes) is subtracted to encourage diversity, and the destination is prioritized early if it is close relative to the average distance. The `weight` and `temperature` adjust dynamically with progress, favoring local costs early and global potential later.",
          "thought": "The new algorithm combines local proximity (prioritized via dynamic weight adjustment) with global potential and regret consideration, incorporating diversity bonuses and dynamic temperature to balance exploration and exploitation as progress advances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.3:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.4 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.2 * regret_term) * temperature - 0.15 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42589,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically adjusts selection pressure and temperature based on progress, prioritizing local cost early and global potential later, while incorporating regret minimization and diversity promotion to refine choices. It balances cost efficiency with exploration through weighted scoring, where local cost dominates early (high selection pressure), global potential mid-search, and regret/diversity considerations refine late-stage decisions. The temperature scales down as progress increases to prevent premature convergence.",
          "thought": "The new algorithm combines dynamic selection pressure adjustment, global-local balance with progress, regret minimization, diversity promotion, and temperature scaling to create a hybrid heuristic that prioritizes cost efficiency early, balances global connectivity mid-search, and refines choices with regret and diversity considerations, while dynamically adjusting temperature to prevent premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 0.8 - 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.3 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44456,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances local cost (prioritized early with high weight) and global potential (increasingly weighted as progress advances), while incorporating a regret term and diversity bonus to avoid premature convergence. The weight and temperature parameters dynamically adjust based on progress (progress_factor), shifting focus from short-term efficiency to long-term optimization. The final decision is made by selecting the node with the lowest weighted score, combining these factors with a temperature scaling factor.",
          "thought": "The new algorithm prioritizes local cost early with a high weight, gradually shifts to global potential, and uses a fixed regret term to balance exploration and exploitation, while dynamically adjusting temperature to avoid early convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.2:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 0.6 + 0.8 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.3 * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure (higher early on) and temperature (starting high for exploration), while incorporating regret terms (lower weight) and diversity bonuses (negative weight) to guide node selection toward promising but diverse paths. Local cost has higher priority in early stages, while global potential and regret terms gain importance as progress advances, with diversity bonuses slightly discouraging redundant choices.",
          "thought": "The new algorithm emphasizes early global optimization with high initial temperature (0.9) and gradually shifts to local refinement, using a more aggressive selection pressure (0.7) and reduced regret weighting (0.05), while increasing diversity penalty (-0.4) to encourage exploration.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.7 + 0.3 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.05 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44991,
          "other_inf": null
     }
]