[
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential, with adaptive thresholding for destination proximity, while incorporating regret minimization and diversity encouragement. It dynamically adjusts weights based on remaining nodes and prioritizes the destination when it's nearby relative to average distances. The heuristic combines distance to current node, potential to destination, predictive factors, regret terms, and diversity bonuses, with weights shifting toward local proximity as progress advances.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by a progress factor) and global potential, incorporating predictive factors, regret minimization, diversity encouragement, and adaptive thresholding based on remaining nodes, while prioritizing the destination node when it's nearby relative to the average distance to unvisited nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.3722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances local and global optimization by dynamically adjusting weights between immediate distance (to the current node) and long-term potential (to the destination and unvisited nodes), while incorporating regret penalties to avoid suboptimal choices and diversity bonuses to explore alternative paths. The weight parameter shifts from prioritizing local decisions early to favoring global potential as the tour progresses, with regret penalties and diversity bonuses fine-tuning selections to balance exploration and exploitation. The heuristic function combines these factors with modified coefficients (e.g., 1.8, 0.5, 0.3) to refine node selection.",
          "thought": "The new algorithm focuses on balancing immediate distance reduction with long-term path optimization by dynamically adjusting weights between local and global factors, while incorporating regret penalties and diversity bonuses with modified parameters to encourage exploration and avoid premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.2 + (0.8 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.8 - 0.8 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.5 * regret_term) - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40068,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weights for local cost, regret minimization, and diversity bonuses, with selection pressure shifting from exploration (early) to exploitation (late). It prioritizes local cost and regret early (high selection pressure) but balances global potential and diversity late (lower pressure), using a weighted heuristic to select the next node. The progress factor dynamically adjusts weights based on remaining nodes, ensuring a balance between short-term and long-term considerations.",
          "thought": "The new algorithm combines adaptive weights for local cost, global potential, regret minimization, and diversity bonuses, with selection pressure adjusting from exploration to exploitation. It prioritizes local cost early, balances regret and global potential midway, and emphasizes diversity late to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = selection_pressure * (0.6 * local_cost + 0.4 * regret_term) + (1 - selection_pressure) * (0.5 * global_potential) - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42572,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines local proximity (weighted by dynamic `weight`) with global potential (distance to destination and average distances to unvisited nodes) and regret (difference between best and current local cost), while balancing exploration and exploitation via `temperature` and `progress_factor`. The `diversity_bonus` (average distance to unvisited nodes) is subtracted to encourage diversity, and the destination is prioritized early if it is close relative to the average distance. The `weight` and `temperature` adjust dynamically with progress, favoring local costs early and global potential later.",
          "thought": "The new algorithm combines local proximity (prioritized via dynamic weight adjustment) with global potential and regret consideration, incorporating diversity bonuses and dynamic temperature to balance exploration and exploitation as progress advances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.3:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.4 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.2 * regret_term) * temperature - 0.15 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42589,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically adjusts selection pressure and temperature based on progress, prioritizing local cost early and global potential later, while incorporating regret minimization and diversity promotion to refine choices. It balances cost efficiency with exploration through weighted scoring, where local cost dominates early (high selection pressure), global potential mid-search, and regret/diversity considerations refine late-stage decisions. The temperature scales down as progress increases to prevent premature convergence.",
          "thought": "The new algorithm combines dynamic selection pressure adjustment, global-local balance with progress, regret minimization, diversity promotion, and temperature scaling to create a hybrid heuristic that prioritizes cost efficiency early, balances global connectivity mid-search, and refines choices with regret and diversity considerations, while dynamically adjusting temperature to prevent premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 0.8 - 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.3 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44456,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure (higher early on) and temperature (starting high for exploration), while incorporating regret terms (lower weight) and diversity bonuses (negative weight) to guide node selection toward promising but diverse paths. Local cost has higher priority in early stages, while global potential and regret terms gain importance as progress advances, with diversity bonuses slightly discouraging redundant choices.",
          "thought": "The new algorithm emphasizes early global optimization with high initial temperature (0.9) and gradually shifts to local refinement, using a more aggressive selection pressure (0.7) and reduced regret weighting (0.05), while increasing diversity penalty (-0.4) to encourage exploration.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.7 + 0.3 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.05 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44991,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local proximity and global connectivity, adjusting selection pressure and temperature based on progress, while incorporating regret minimization and diversity encouragement. Early in the process, local cost dominates, but as progress increases, global potential and regret terms gain importance, with diversity bonuses acting as a penalty. The heuristic function combines these factors with weighted scores, where selection pressure and temperature control the balance between exploration and exploitation.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential from No.1, with selection pressure and temperature scaling from No.2, while incorporating regret minimization and diversity encouragement. It prioritizes local cost early but shifts to global connectivity later, balancing regret terms and diversity bonuses to avoid local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 0.9 - 0.6 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.3 * regret_term) * temperature - 0.5 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.45805,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global cost considerations, prioritizes low-regret and high-diversity nodes, and incorporates memory to avoid revisiting recent nodes, with selection pressure and temperature adjusting based on progress. Local cost and global potential are weighted by `selection_pressure`, while regret and diversity bonuses refine the score, and memory penalties discourage revisits. The heuristic function combines these factors into a weighted score, favoring nodes with minimal cost, high potential, and diversity while penalizing revisits, with temperature and memory factors modulating the balance between exploration and exploitation.",
          "thought": "The new algorithm modifies the original by introducing a dynamic bias towards nodes with high diversity and low regret, while incorporating a memory-based component to avoid revisiting recently visited nodes, and using a probabilistic selection mechanism to balance exploration and exploitation based on a learned preference factor.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 0.9 - 0.6 * progress_factor\n    memory_factor = 0.2 * (1 - progress_factor)\n\n    recent_nodes = set()\n    if len(unvisited_nodes) < total_nodes - 2:\n        recent_nodes.add(current_node)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        memory_penalty = 1.0 if node in recent_nodes else 1.0\n\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.25 * regret_term) * temperature\n        weighted_score -= 0.35 * diversity_bonus * (1 + memory_factor)\n        weighted_score *= memory_penalty\n\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.45881,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines local proximity (weighted by progress factor) with global potential, incorporating regret minimization and diversity encouragement, while dynamically adjusting selection pressure and temperature to balance exploration and exploitation. Local cost receives higher priority (weighted by selection pressure), while global potential contributes proportionally (1-selection pressure), with regret terms and diversity bonuses playing secondary roles. The heuristic score is computed as a weighted sum of these components, scaled by temperature, to guide node selection.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, incorporating regret minimization and diversity encouragement, with temperature and selection pressure adapting based on progress, to balance exploration and exploitation for better solution quality.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.6 + 0.4 * progress_factor\n    temperature = 0.8 - 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - local_cost for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.4 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.49334,
          "other_inf": null
     }
]