def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node
    if destination_node in unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    progress = 1 - remaining_nodes / total_nodes
    exploration_bonus = 0.1 * (1 - progress)  # Higher early, lower later

    def heuristic(node):
        immediate_cost = distance_matrix[current_node][node]
        detour_cost = distance_matrix[node][destination_node] - distance_matrix[current_node][destination_node]
        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)

        # Hub score with adaptive threshold
        hub_threshold = 1.2 - 0.1 * progress
        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < hub_threshold * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0

        # Centrality with adaptive threshold
        centrality_threshold = 1.1 - 0.05 * progress
        centrality = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < centrality_threshold * immediate_cost) if remaining_nodes > 1 else 0

        # Node density penalty (favors less dense regions)
        node_density = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.5 * immediate_cost) / remaining_nodes if remaining_nodes > 1 else 0

        # Dynamic weights with exploration bonus
        dynamic_weight = (
            (0.4 - 0.2 * progress) * immediate_cost +
            (0.3 - 0.15 * progress) * regret +
            (0.2 - 0.2 * progress) * detour_cost +
            (0.3 + 0.4 * progress) * hub_score +
            (0.1 + 0.2 * progress) * centrality -
            0.1 * node_density +
            exploration_bonus * (0.5 - 0.4 * progress)
        )

        return dynamic_weight

    next_node = min(unvisited_nodes, key=heuristic)
    return next_node
