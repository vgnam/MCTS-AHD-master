def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node
    if destination_node in unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    progress = 1 - remaining_nodes / total_nodes
    temperature = 0.9 - 0.6 * progress
    exploration_pressure = 1 / (1 + math.exp(-10 * (progress - 0.5)))

    def heuristic(node):
        immediate_cost = distance_matrix[current_node][node]
        regret_threshold = min(distance_matrix[current_node][n] for n in unvisited_nodes) * (1 + 0.5 * progress)
        regret = max(0, immediate_cost - regret_threshold)
        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.2 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0
        hub_scaling = (1 - progress) ** 2
        predictive_entropy = -sum((p / sum(distance_matrix[node])) * math.log(p + 1e-6) for p in distance_matrix[node]) if remaining_nodes > 1 else 0
        diversity_penalty = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)

        weighted_score = (
            (0.35 - 0.25 * progress) * immediate_cost +
            (0.4 + 0.25 * progress) * regret +
            (0.15 * hub_scaling) * hub_score +
            (0.2 * exploration_pressure) * predictive_entropy -
            (0.25 * (1 - exploration_pressure)) * diversity_penalty
        )
        return weighted_score * temperature

    next_node = min(unvisited_nodes, key=heuristic)
    return next_node
