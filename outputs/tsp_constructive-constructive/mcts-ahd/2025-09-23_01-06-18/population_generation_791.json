[
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with dynamic weight adjustment, prioritizing local costs early in the search and shifting to global potential as progress advances, while incorporating regret terms to avoid costly alternatives and diversity bonuses to prevent clustering. The weight shifts from local (1.0) to global (1.6) as progress increases, and temperature balances exploration (0.8) and exploitation (0.1) similarly. The regret term prioritizes high-cost alternatives, and the diversity bonus discourages clustering, with the destination being prioritized if it is nearby relative to average distances.",
          "thought": "The new algorithm combines nearest-neighbor selection with dynamic weight adjustment, global potential estimation, regret consideration, diversity encouragement, and temperature scaling, where the weight shifts from local to global focus, the regret term prioritizes high-cost alternatives, diversity bonus prevents clustering, and temperature balances exploration and exploitation, all while prioritizing the destination if it is nearby relative to the average distance.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.1:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.6 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.4 * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.34249,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines local cost, global potential, regret, and diversity considerations, with weights dynamically adjusted based on progress (progress_factor). Early stages prioritize local cost and regret (weighted higher), while later stages emphasize global potential and diversity (lower weights). The temperature parameter introduces stochasticity, and the diversity_bonus discourages clustering. The heuristic function balances these factors multiplicatively, with regret_term scaled by regret_weight.",
          "thought": "The new algorithm combines the dynamic weight adjustment from No.1 and No.4, the global potential and regret consideration from No.3, the diversity bonus from No.4, and the early destination prioritization from No.2, while introducing adaptive regret weighting and a more aggressive weight shift to balance local and global considerations more effectively.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        priority = remaining_distance / avg_distance\n        if priority <= 1.15:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    weight = 1 + 0.5 * progress_factor\n    temperature = 0.8 - 0.7 * progress_factor\n    regret_weight = 0.3 * (1 - progress_factor)\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + regret_weight * regret_term) * temperature - 0.2 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.36425,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes balancing local proximity (weighted by progress) and global potential, with adaptive thresholding for destination proximity, while incorporating regret minimization and diversity encouragement. It dynamically adjusts weights based on remaining nodes and prioritizes the destination when it's nearby relative to average distances. The heuristic combines distance to current node, potential to destination, predictive factors, regret terms, and diversity bonuses, with weights shifting toward local proximity as progress advances.",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity (weighted by a progress factor) and global potential, incorporating predictive factors, regret minimization, diversity encouragement, and adaptive thresholding based on remaining nodes, while prioritizing the destination node when it's nearby relative to the average distance to unvisited nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        global_potential = (to_destination + predictive_factor) / 2\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.3722,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines **progress-dependent weighting** of immediate cost, regret, and hub connectivity, with **dynamic temperature modulation** and **diversity bonuses** to balance early exploration and late exploitation. It prioritizes **nearby nodes with low regret** early on but shifts to **hub nodes with high connectivity** later, while maintaining path diversity through a **diversity penalty**. The weights (`weight`, `temperature`) decrease with progress, favoring **immediate cost and hubs** in the later stages, while the **diversity bonus** discourages repetitive paths.",
          "thought": "The new algorithm combines progress-dependent weighting of immediate cost, regret, and hub connectivity with dynamic temperature modulation and diversity bonuses, balancing early exploration and late exploitation while prioritizing strategic hubs and maintaining path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.6 - 0.3 * progress\n    temperature = 0.8 - 0.5 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.15 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.3 * hub_score) * temperature - 0.35 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.38553,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment between local proximity (weighted by progress factor) and global potential, while incorporating regret minimization and diversity encouragement. It prioritizes local proximity early in the search (higher weight) and shifts to global potential as progress increases, with added regret-based penalties and diversity bonuses to avoid local optima. The heuristic function integrates these factors to select the next node, with regret terms and diversity bonuses given moderate weights (0.3 and -0.5, respectively).",
          "thought": "The new algorithm combines dynamic weight adjustment between local proximity and global potential (scaled by progress factor), with added regret minimization and diversity encouragement, while maintaining direct routing when the destination is near.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.5 - 0.5 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.3 * regret_term) - 0.5 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39234,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights between immediate proximity (higher priority) and regret minimization (lower priority) based on progress, while using temperature modulation to refine selection. It also incorporates hub centrality and diversity bonuses to prioritize nodes with high connectivity and diversity, with the hub score and diversity bonus given moderate and lower priorities, respectively. The weight and temperature parameters adapt to progress, making early decisions more exploratory and later ones more exploitative.",
          "thought": "The new algorithm combines dynamic progress-based weighting between immediate proximity and regret minimization, with adaptive temperature modulation to balance exploration and exploitation, while incorporating hub centrality and diversity bonuses to refine selection.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * regret + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.39252,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances local and global optimization by dynamically adjusting weights between immediate distance (to the current node) and long-term potential (to the destination and unvisited nodes), while incorporating regret penalties to avoid suboptimal choices and diversity bonuses to explore alternative paths. The weight parameter shifts from prioritizing local decisions early to favoring global potential as the tour progresses, with regret penalties and diversity bonuses fine-tuning selections to balance exploration and exploitation. The heuristic function combines these factors with modified coefficients (e.g., 1.8, 0.5, 0.3) to refine node selection.",
          "thought": "The new algorithm focuses on balancing immediate distance reduction with long-term path optimization by dynamically adjusting weights between local and global factors, while incorporating regret penalties and diversity bonuses with modified parameters to encourage exploration and avoid premature convergence.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.2 + (0.8 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        progress_factor = 1 - remaining_ratio\n        weight = 1.8 - 0.8 * progress_factor\n        global_potential = (to_destination + sum(distance_matrix[node][other] for other in unvisited_nodes if other != node)) / (len(unvisited_nodes) + 1)\n        regret_term = max(distance_matrix[current_node][other] - to_current for other in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][other] for other in unvisited_nodes) / (len(unvisited_nodes) + 1e-6)\n        return (to_current * weight + global_potential * (1.0 - weight) + 0.5 * regret_term) - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40068,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines a weighted balance of immediate cost, regret, and hub connectivity while dynamically adjusting priorities through progress-dependent weighting, temperature modulation, and diversity bonuses. Early stages favor exploration (higher weight on regret and diversity), while later stages emphasize efficiency (higher weight on immediate cost and hub scores). The adaptive regret factor scales with progress, and the hub threshold tightens as nodes are visited, balancing exploration and exploitation.",
          "thought": "This new algorithm combines progress-dependent weighting of immediate cost, regret, and hub connectivity with dynamic temperature modulation and diversity bonuses, while incorporating a novel adaptive regret factor that scales with progress and a hub score threshold that tightens with remaining nodes, balancing early exploration with late exploitation for improved path optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n    hub_threshold = 1.1 + 0.05 * (1 - progress)\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < hub_threshold * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        adaptive_regret = regret * (1 + 0.5 * progress)\n        weighted_score = (weight * immediate_cost + (1 - weight) * adaptive_regret + 0.3 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.40485,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic weight adjustment (balancing local and global costs) with regret prioritization (avoiding immediate regrets) and hub centrality (prioritizing nodes with strong local connectivity). It also incorporates predictive factors (estimating future costs) and diversity penalties (avoiding clustering) while using temperature to control exploration vs. exploitation. Weights are highest for local cost (weighted by progress) and regret, with hub and predictive factors decreasing in importance as progress increases.",
          "thought": "The new algorithm combines the dynamic weight adjustment and regret prioritization from No.1 with the hub centrality and predictive factors from No.2, shifting focus from immediate costs to long-term benefits as progress increases while balancing exploration and exploitation through temperature and diversity penalties.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 1 + 0.6 * progress\n    temperature = 0.8 - 0.5 * progress\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1e-6)\n        regret = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.2 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (local_cost * weight + global_potential * (1 - weight) + 0.4 * regret + 0.3 * progress * hub_score + 0.1 * (1 - progress) * predictive_factor) * temperature - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.41015,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines adaptive weighting, regret minimization, and hub centrality to select the next node in TSP, dynamically balancing local (immediate cost) and global (predictive factors, regret, and hub scores) considerations with temperature modulation and progress-based adjustments. Higher priority is given to immediate cost and regret, while predictive factors and hub scores are weighted lower, with diversity bonuses applied as a penalty. The algorithm adjusts weights and temperature based on progress (1 - remaining nodes/total nodes) to shift focus from exploration to exploitation.",
          "thought": "The new algorithm will combine the adaptive weighting and progress-based adjustments from No.2 with the predictive factors, regret minimization, and diversity encouragement from No.1, while dynamically balancing local and global considerations with temperature modulation and hub centrality.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = 1 - remaining_nodes / total_nodes\n    weight = 0.7 - 0.4 * progress\n    temperature = 0.9 - 0.6 * progress\n\n    def heuristic(node):\n        immediate_cost = distance_matrix[current_node][node]\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        regret = immediate_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)\n        hub_score = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < 1.1 * min(distance_matrix[node][m] for m in unvisited_nodes if m != n)) if remaining_nodes > 1 else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (weight * immediate_cost + (1 - weight) * (0.7 * regret + 0.3 * predictive_factor) + 0.2 * hub_score) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.42215,
          "other_inf": null
     }
]