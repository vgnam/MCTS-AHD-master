[
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure (higher early on) and temperature (starting high for exploration), while incorporating regret terms (lower weight) and diversity bonuses (negative weight) to guide node selection toward promising but diverse paths. Local cost has higher priority in early stages, while global potential and regret terms gain importance as progress advances, with diversity bonuses slightly discouraging redundant choices.",
          "thought": "The new algorithm emphasizes early global optimization with high initial temperature (0.9) and gradually shifts to local refinement, using a more aggressive selection pressure (0.7) and reduced regret weighting (0.05), while increasing diversity penalty (-0.4) to encourage exploration.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.7 + 0.3 * progress_factor\n    temperature = 0.9 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.05 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.44991,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines dynamic selection pressure adjustment (prioritizing local cost early) with adaptive temperature scaling (balancing exploration/exploitation) and weighted regret consideration (minimizing suboptimal choices), while incorporating diversity-aware global potential assessment. It progressively shifts focus from local cost to global optimization, regret minimization, and path diversity, with selection pressure and temperature adjusting based on progress. The weighted score formula (selection_pressure * local_cost + (1-selection_pressure) * global_potential + regret_term) dynamically balances these factors, while diversity_bonus is subtracted to encourage path diversity.",
          "thought": "This new algorithm combines dynamic selection pressure adjustment, adaptive temperature scaling, weighted regret consideration, and diversity-aware global potential assessment to create a hybrid heuristic that prioritizes local cost early while progressively balancing global optimization, regret minimization, and path diversity.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.4 + 0.6 * progress_factor\n    temperature = 1.0 - 0.7 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.2 * regret_term) * temperature - 0.4 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.54141,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines regret-based local optimization with global potential evaluation, dynamically adjusting weights based on progress (favoring local costs early, global potential later) while penalizing centrality and diversity to avoid clustering. The heuristic prioritizes regret (weighted by progress) and local/global costs (70%/30%), with secondary penalties for centrality and diversity. The weight smoothly transitions from local to global focus as progress increases, ensuring a balance between short-term and long-term optimization.",
          "thought": "The new algorithm combines the dynamic weight adjustment of No.2 with the regret-based optimization and global potential evaluation of No.1, while incorporating centrality and diversity penalties to avoid clustering, and uses a nonlinear progress-based weight to balance local and global optimization.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress = (total_nodes - remaining_nodes) / total_nodes\n    weight = (1 - progress) ** 2\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = distance_matrix[node][destination_node]\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        return (1 - weight) * regret + weight * (0.7 * local_cost + 0.3 * global_potential) - 0.2 * centrality - 0.3 * diversity_bonus\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.59768,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes local proximity (distance to current node) when few nodes remain, using a dynamic weight that scales inversely with unvisited nodes. When the destination is near, it switches to direct routing, with a threshold based on visited/total nodes. Predictive factors (average distances to remaining nodes) gain importance as more nodes are unvisited, balancing short-term and long-term efficiency. The heuristic function combines weighted distances to the current node and predictive factors, adjusting weights dynamically.",
          "thought": "The new algorithm prioritizes predictive factors when few nodes remain, using a dynamic weight that scales with the inverse of unvisited nodes, and switches to local proximity when the destination is near, with a threshold adjusted by the ratio of visited to total nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    if destination_node in unvisited_nodes:\n        remaining_distance = distance_matrix[current_node][destination_node]\n        avg_distance = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / len(unvisited_nodes)\n        if avg_distance == 0:\n            return destination_node\n        threshold = 1.0 + (1.0 - (len(unvisited_nodes) / len(distance_matrix)))\n        if remaining_distance / avg_distance <= threshold:\n            return destination_node\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        remaining_ratio = len(unvisited_nodes) / len(distance_matrix)\n        weight = 2.0 - remaining_ratio\n        predictive_factor = sum(distance_matrix[node][other] for other in unvisited_nodes if other != node) / len(unvisited_nodes)\n        return to_current * weight + predictive_factor * (1.0 - weight)\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.64273,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local and global optimization by adjusting selection pressure and temperature based on progress, prioritizing local cost early and global potential later. It incorporates regret and diversity terms to avoid suboptimal choices, with regret weighted lower (0.1) and diversity penalized heavily (-0.3). The heuristic score is temperature-adjusted to refine selections as the problem progresses, ensuring a hybrid of greedy and global-aware node selection.",
          "thought": "This algorithm combines adaptive selection pressure, dynamic temperature scaling, regret-based global potential, diversity bonus, and progress-aware weighting to balance local and global optimization, while incorporating a hybrid heuristic that integrates local cost, global potential, regret, and diversity into a temperature-adjusted score to dynamically prioritize nodes based on problem progress.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n    temperature = 1.0 - 0.8 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] +\n                           sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (selection_pressure * local_cost + (1 - selection_pressure) * global_potential + 0.1 * regret_term) * temperature - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.64995,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines regret-based optimization (60% weight) and global potential evaluation (35%) while dynamically adjusting selection pressure based on progress, penalizing high-centrality nodes (-0.2 weight) and rewarding diversity (-0.3 weight). The weighted score balances immediate cost savings with long-term efficiency, using parameters (0.6, 0.35, -0.2, -0.3) to prioritize local optimization early and global optimization later, while avoiding bottlenecks and local optima.",
          "thought": "The new algorithm combines dynamic selection pressure adjustment, regret-based optimization, global potential evaluation, centrality penalty, and diversity bonus, while balancing immediate cost savings (60%) with long-term path efficiency (35%) and diversity (5%), using parameters (0.6, 0.35, -0.2, -0.3) to prioritize both local and global optimization while avoiding bottlenecks and local optima.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (distance_matrix[node][destination_node] + sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node)) / (remaining_nodes + 1)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n        diversity_bonus = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (1 - selection_pressure) * regret + selection_pressure * (0.6 * local_cost + 0.35 * global_potential) - 0.2 * centrality - 0.3 * diversity_bonus\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.66924,
          "other_inf": null
     },
     {
          "algorithm": "This heuristic combines proximity and detour cost with dynamic weighting, adaptive temperature, and regret-based selection, prioritizing local cost (50%), detour impact (30%), and diversity penalty (20%) while adjusting weights based on progress and node distances. The algorithm balances exploration (temperature) and exploitation (regret) to select the next node efficiently.",
          "thought": "The new algorithm combines No.1's dynamic weight balancing proximity and detour cost with No.2's adaptive temperature and weighted heuristic, introducing a regret-based detour adjustment and diversity penalty to enhance exploration and exploitation.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    temperature = 1.0 - 0.7 * progress_factor\n\n    remaining_distance = distance_matrix[current_node][destination_node]\n    dynamic_weight = 0.5 + 0.5 * (1 - remaining_distance / sum(distance_matrix[current_node]))\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        detour_cost = to_destination - remaining_distance\n        weighted_detour = dynamic_weight * local_cost + (1 - dynamic_weight) * detour_cost\n        regret_term = max(distance_matrix[current_node][n] - distance_matrix[current_node][node] for n in unvisited_nodes) if unvisited_nodes else 0\n        diversity_penalty = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        weighted_score = (0.5 * weighted_detour + 0.3 * regret_term) * temperature - 0.2 * diversity_penalty\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.67157,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances local optimization (prioritizing nearby nodes) and global path potential (considering future steps) using adaptive weights that shift with progress. It emphasizes regret minimization early (to avoid poor choices) and destination bias later (to ensure efficient returns), while centrality is downweighted to prevent premature clustering. The heuristic combines these factors with a weighted score, where selection pressure adjusts between exploration and exploitation.",
          "thought": "The new algorithm integrates dynamic selection pressure with adaptive regret weighting, incorporating node centrality and destination bias to balance local optimization with global path potential, using a novel scoring mechanism that dynamically adjusts weights based on tour progress and node characteristics.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    selection_pressure = 0.5 + 0.5 * progress_factor\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (1 - progress_factor) * distance_matrix[node][destination_node] + progress_factor * sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node) / (remaining_nodes)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        regret_factor = (1 - progress_factor) * 0.8 + progress_factor * 0.3\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n\n        destination_bias = 1 / (1 + distance_matrix[node][destination_node])\n        weighted_score = (1 - selection_pressure) * regret_factor * regret + selection_pressure * (0.6 * local_cost + 0.3 * global_potential + 0.1 * destination_bias) - 0.3 * centrality\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.76429,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances immediate distance, future potential, and completion progress by combining regret minimization, proximity bias, and centrality effects. It prioritizes local cost and global potential adaptively, with higher weight on regret early in the tour and proximity bias as progress increases. The heuristic dynamically adjusts exploration vs. exploitation via progress_factor and exploration_factor, while centrality is penalized to avoid hub nodes.",
          "thought": "The new algorithm combines the adaptive progress-based weighting from No.1 with the dynamic exploration factor and proximity bias from No.2, creating a heuristic that balances immediate distance, future potential, and completion progress while minimizing regret and centrality effects.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    progress_factor = 1 - (remaining_nodes / total_nodes)\n    exploration_factor = (remaining_nodes / total_nodes) ** 2\n\n    def heuristic(node):\n        local_cost = distance_matrix[current_node][node]\n        global_potential = (1 - progress_factor) * distance_matrix[node][destination_node] + progress_factor * sum(distance_matrix[node][n] for n in unvisited_nodes if n != destination_node) / (remaining_nodes)\n        centrality = sum(distance_matrix[node][n] for n in unvisited_nodes) / (remaining_nodes + 1e-6)\n        regret_factor = (1 - progress_factor) * 0.8 + progress_factor * 0.3\n        regret = (local_cost - min(distance_matrix[current_node][n] for n in unvisited_nodes)) / (max(distance_matrix[current_node][n] for n in unvisited_nodes) - min(distance_matrix[current_node][n] for n in unvisited_nodes) + 1e-6)\n\n        proximity_bias = (1 - remaining_nodes / total_nodes) ** 3\n        weighted_score = (1 - exploration_factor) * regret_factor * regret + exploration_factor * (0.5 * local_cost + 0.3 * global_potential + 0.2 * proximity_bias) - 0.2 * centrality\n        return weighted_score\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.76855,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances immediate distance, detour risk, and centrality to select the next node, adjusting weights based on progress (prioritizing detour minimization early) while penalizing high-centrality nodes (favoring peripheral nodes). It uses a heuristic combining current distance, a dynamic detour cost, average distance to unvisited nodes, and centrality factor (weighted lower), ensuring exploration and efficiency. The `dynamic_weight` and `centrality_factor` variables are key in balancing exploration and exploitation.",
          "thought": "The new algorithm combines dynamic weight adjustments based on progress and remaining nodes, detour cost consideration, and centrality balance to prioritize nodes that minimize immediate distance, detour risk, and centrality while encouraging exploration early.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n    if destination_node in unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = 1 - (remaining_nodes / len(distance_matrix))\n    dynamic_weight = 0.5 * (remaining_nodes / (remaining_nodes + 1)) * (1 - progress_factor)\n    avg_distance_to_unvisited = sum(distance_matrix[current_node][node] for node in unvisited_nodes) / remaining_nodes if remaining_nodes > 0 else 0\n    centrality = {node: sum(distance_matrix[node][j] for j in unvisited_nodes) / remaining_nodes for node in unvisited_nodes}\n\n    def heuristic(node):\n        to_current = distance_matrix[current_node][node]\n        to_destination = distance_matrix[node][destination_node]\n        detour_cost = to_destination - distance_matrix[current_node][destination_node]\n        centrality_factor = 1 - (centrality[node] / max(centrality.values()))\n        return to_current + dynamic_weight * detour_cost + 0.2 * avg_distance_to_unvisited + 0.3 * centrality_factor\n\n    next_node = min(unvisited_nodes, key=heuristic)\n    return next_node",
          "objective": 6.77965,
          "other_inf": null
     }
]