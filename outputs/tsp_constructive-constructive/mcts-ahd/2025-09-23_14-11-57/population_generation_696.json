[
     {
          "algorithm": "The algorithm adaptively balances immediate distance, future potential (weighted dynamically by progress), and penalties for reconsidered nodes, prioritizing immediate distances early and future costs later while penalizing late reconsiderations. It uses a normalized progress metric (0 to 1) to adjust the dynamic weight, decreasing future cost influence as the tour progresses. The weighted score combines these factors, with penalties applied only after half the nodes are visited.",
          "thought": "The new algorithm combines No.1's weighted balance between immediate and future distances with No.2's dynamic weight adjustment and penalty mechanism. It adaptively shifts focus from immediate distances to future costs while penalizing reconsidered nodes late in the process, using a normalized progress metric to modulate the dynamic weight.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes) if progress > 0.5 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.6 - 0.4 * progress  # Decrease future weight as progress increases\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44101,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distances (given a fixed weight of 0.5) while considering future potential (distance to the destination) for node selection. It applies a quadratic penalty to reconsidered nodes only after 70% progress, dynamically adjusting the penalty strength based on a linear progress metric. The code balances short-term and long-term considerations, with penalties only activated late in the process to refine choices.",
          "thought": "The new algorithm prioritizes immediate distances with a fixed future potential weight, applies a quadratic penalty for reconsidered nodes only after 70% progress, and uses a linear progress metric to dynamically adjust the penalty strength.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Linear progress metric (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = (sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes)) ** 2 if progress > 0.7 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.5  # Fixed future potential weight\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44688,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines a greedy approach with dynamic weighting and multi-step lookahead to balance immediate and future distances. It prioritizes immediate distances early in the search (higher `immediate_weight`) and future potential later (higher `future_weight`), while applying a memory penalty to discourage revisiting nodes. The `exploration_factor` encourages exploration in early stages, and normalization ensures fair comparison across nodes. The critical design choices are the dynamic adjustment of weights based on remaining nodes and the memory penalty to avoid cycles.",
          "thought": "This new algorithm combines the greedy lookahead mechanism of No.1 with the dynamic weighting and exploration penalty of No.2, while introducing a memory-based penalty to avoid revisiting recently visited nodes and a multi-step lookahead to better balance immediate and future distances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_immediate_weight = 0.5\n    base_future_weight = 0.5\n    stage_factor = 1.0 / (1.0 + 0.1 * remaining_nodes)\n\n    immediate_weight = base_immediate_weight * (1.0 - stage_factor)\n    future_weight = base_future_weight * (1.0 + stage_factor)\n\n    exploration_factor = 1.0 + 0.4 * (1.0 - (remaining_nodes / len(distance_matrix)))\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        if remaining_nodes > 2:\n            next_nodes = [n for n in unvisited_nodes if n != node]\n            future_potential = min(distance_matrix[node][n] + distance_matrix[n][destination_node] for n in next_nodes)\n        else:\n            future_potential = distance_matrix[node][destination_node]\n\n        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / len(distance_matrix))\n        normalized_future = future_potential / (sum(distance_matrix[node]) / len(distance_matrix))\n\n        memory_penalty = 0.2 * (1.0 / (immediate_distance + 1e-6)) * exploration_factor\n        combined_score = immediate_weight * normalized_immediate + future_weight * normalized_future - memory_penalty\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_node = node\n\n    return next_node",
          "objective": 6.52839,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node to visit in TSP by balancing immediate proximity (70% weight) and potential path efficiency (30% weight), while penalizing nodes too close to the current node to avoid cycles. The `select_next_node` function evaluates unvisited nodes based on their distance from the current node and their contribution to the overall path length, adjusting scores with a penalty term for very short distances.",
          "thought": "The new algorithm modifies the selection criterion by incorporating a weighted balance between immediate proximity to the current node and the potential to reduce the total path length, using a heuristic that considers both the current step and the overall path efficiency, while also introducing a penalty for revisiting nodes to avoid cycles.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        node_to_dest = distance_matrix[node][destination_node]\n        total_increase = current_to_node + node_to_dest\n\n        # Penalize nodes that are too close to avoid revisiting\n        penalty = 0.1 * (1.0 / (current_to_node + 1e-6)) if current_to_node < 0.5 else 0\n\n        # Weighted score: balance between immediate proximity and path efficiency\n        score = 0.7 * current_to_node + 0.3 * total_increase - penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.5779,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines immediate and lookahead distances with a weighted approach, prioritizing immediate distance (60%) over the best possible subsequent step (40%). It evaluates each unvisited node by computing a weighted sum of its direct distance from the current node and the shortest subsequent distance from that node, then selects the node with the lowest total score. The loop structure ensures all unvisited nodes are considered, while the distance matrix provides the necessary connectivity data.",
          "thought": "The new algorithm combines the balanced approach of No.2 (equal weights for immediate and lookahead distances) with the refined lookahead strategy of No.1 (evaluating the best possible subsequent step after the current candidate), while slightly adjusting the weights to favor immediate distance more than lookahead (60% vs. 40%).",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        best_lookahead_distance = float('inf')\n        for next_node in unvisited_nodes:\n            if next_node != node:\n                lookahead_distance = distance_matrix[node][next_node]\n                if lookahead_distance < best_lookahead_distance:\n                    best_lookahead_distance = lookahead_distance\n\n        score = 0.6 * immediate_distance + 0.4 * best_lookahead_distance\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.59312,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node by balancing immediate distance, average future distances to remaining nodes, and a penalty for revisiting nodes, with the penalty factor (0.3) giving higher priority to minimizing immediate and future distances while slightly discouraging revisits. The score is computed as `current_to_node + avg_remaining_dist + revisit_penalty`, where `avg_remaining_dist` and `revisit_penalty` are dynamically adjusted based on unvisited nodes. The algorithm prioritizes proximity and future potential while slightly penalizing revisits.",
          "thought": "The new algorithm extends the original by incorporating a dynamic lookahead mechanism that evaluates not only the immediate distance but also the average distance to remaining nodes, combined with a penalty factor for revisiting nodes, ensuring a balance between proximity and future path potential.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n    penalty_factor = 0.3\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            revisit_penalty = penalty_factor * distance_matrix[current_node][node]\n        else:\n            avg_remaining_dist = 0\n            revisit_penalty = 0\n\n        score = current_to_node + avg_remaining_dist + revisit_penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.60833,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines a weighted greedy approach with dynamic balancing between immediate distance and future potential, prioritizing immediate distance early in the traversal and future potential as more nodes are visited. The weights (`immediate_weight` and `future_weight`) adapt based on remaining nodes, while an exploration penalty discourages revisiting nearby nodes. The `combined_score` balances normalized immediate and future distances, with penalties favoring less explored paths.",
          "thought": "The new algorithm combines the greedy approach of No.2 with the dynamic balancing of proximity and future potential from No.1, using a weighted score that adaptively prioritizes immediate distance and future potential, with exploration incentives and penalties based on traversal progress.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_immediate_weight = 0.6\n    base_future_weight = 0.4\n    stage_factor = 1.0 / (1.0 + 0.1 * remaining_nodes)\n\n    immediate_weight = base_immediate_weight * (1.0 - stage_factor)\n    future_weight = base_future_weight * (1.0 + stage_factor)\n\n    exploration_factor = 1.0 + 0.4 * (1.0 - (remaining_nodes / len(distance_matrix)))\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / len(distance_matrix))\n        normalized_future = future_potential / (sum(distance_matrix[node]) / len(distance_matrix))\n\n        penalty = 0.15 * (1.0 / (immediate_distance + 1e-6)) * exploration_factor\n        combined_score = immediate_weight * normalized_immediate + future_weight * normalized_future - penalty\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_node = node\n\n    return next_node",
          "objective": 6.71064,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by balancing regret (with variance-adjusted scaling), immediate/future distance (with exponential decay), future connectivity diversity, and local density, prioritizing regret and distance early (higher weights) while gradually emphasizing diversity and density as nodes are visited. It uses adaptive weights that decay exponentially with remaining nodes, ensuring early-stage decisions focus on proximity and regret, while later stages prioritize path diversity and local clustering.",
          "thought": "\nThe new algorithm modifies the original by incorporating a dynamic regret scaling factor that adjusts based on the variance of available options, introducing a \"future path diversity\" metric to weigh nodes that connect to multiple high-potential future nodes, and using an exponential decay for proximity potential to emphasize early-stage decisions, while the original algorithm's weights were linear. The new approach also adds a \"local density\" factor to prioritize nodes in dense regions when fewer nodes remain.\n",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    proximity_potentials = []\n    future_diversities = []\n    local_densities = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n        distances.append(immediate_distance)\n\n        # Calculate regret with dynamic scaling based on variance of options\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            other_distances = [distance_matrix[current_node][n] for n in other_nodes]\n            variance = sum((d - sum(other_distances)/len(other_distances))**2 for d in other_distances) / len(other_distances)\n            second_best = min(other_distances)\n            regret = (distance_matrix[current_node][node] - second_best) * (1 + variance)\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        # Exponential decay for proximity potential to emphasize early decisions\n        remaining_nodes = len(unvisited_nodes)\n        proximity_potential = (immediate_distance + future_potential) * (0.9 ** remaining_nodes)\n        proximity_potentials.append(proximity_potential)\n\n        # Future diversity: number of high-potential future connections\n        future_diversity = sum(1 for n in unvisited_nodes if n != node and distance_matrix[node][n] < 2 * immediate_distance)\n        future_diversities.append(future_diversity)\n\n        # Local density: inverse of average distance to nearby nodes\n        nearby_distances = [distance_matrix[node][n] for n in unvisited_nodes if n != node]\n        local_density = 1 / (sum(nearby_distances) / len(nearby_distances)) if nearby_distances else 0\n        local_densities.append(local_density)\n\n    # Adaptive weights with exponential decay for proximity and local density\n    total_nodes = len(distance_matrix)\n    regret_weight = 0.5 * (0.8 ** remaining_nodes)\n    distance_weight = 0.4 * (0.8 ** remaining_nodes)\n    proximity_weight = 0.2 * (0.8 ** remaining_nodes)\n    diversity_weight = 0.3 * (1 - 0.8 ** remaining_nodes)\n    density_weight = 0.2 * (1 - 0.8 ** remaining_nodes)\n\n    # Combine weighted scores: balance all factors\n    scores = [\n        regret_weight * regret + distance_weight * distance + proximity_weight * potential +\n        diversity_weight * diversity + density_weight * density\n        for regret, distance, potential, diversity, density in zip(\n            regrets, distances, proximity_potentials, future_diversities, local_densities\n        )\n    ]\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.72696,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights for regret (higher priority early), distance (prioritized later), and centrality (moderate priority), using a sigmoid-based exploration phase to smooth transitions. It employs a dynamic regret threshold to filter unpromising options and includes exploration penalties to avoid local minima. The scoring system combines these factors to select the next node, with regret and distance dominating early and late phases, respectively.",
          "thought": "The new algorithm extends the original by incorporating a dynamic regret threshold that adapts based on the current exploration phase, using a sigmoid function to smooth the transition between exploration and exploitation, and introducing a node centrality measure to favor nodes that are central in the remaining subgraph, while maintaining the original's dynamic weighting scheme.",
          "code": "import math\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    centralities = []\n    exploration_penalties = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        distances.append(immediate_distance)\n\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            second_best = min(distance_matrix[current_node][n] for n in other_nodes)\n            regret = max(0, distance_matrix[current_node][node] - second_best)\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        # Centrality measure: sum of distances to all other unvisited nodes\n        centrality = sum(distance_matrix[node][n] for n in other_nodes) if other_nodes else 0\n        centralities.append(centrality)\n\n        exploration_penalties.append(0.15 * (1.0 / (immediate_distance**2 + 1e-6)))\n\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n\n    # Dynamic weights with sigmoid transition\n    exploration_phase = 1.0 - (remaining_nodes / total_nodes)\n    regret_weight = 0.6 * (1.0 - exploration_phase) + 0.3 * exploration_phase\n    distance_weight = 0.4 * exploration_phase + 0.6 * (1.0 - exploration_phase)\n    centrality_weight = 0.1 * exploration_phase + 0.3 * (1.0 - exploration_phase)\n    exploration_factor = 0.5 + 0.4 * exploration_phase\n\n    # Dynamic regret threshold based on exploration phase\n    regret_threshold = 0.5 * (1.0 - exploration_phase)\n\n    scores = []\n    for regret, distance, centrality, penalty in zip(regrets, distances, centralities, exploration_penalties):\n        # Apply regret threshold\n        effective_regret = regret if regret > regret_threshold else 0\n        score = (regret_weight * effective_regret +\n                 distance_weight * distance -\n                 centrality_weight * centrality -\n                 exploration_factor * penalty)\n        scores.append(score)\n\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.82752,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances proximity (prioritized early in the tour) and path efficiency (weighted more as the tour progresses) while penalizing nodes too close to the current one to avoid cycling. It estimates the impact of each node on the remaining tour using a heuristic and adjusts weights based on remaining unvisited nodes. The score combines these factors to select the next node, with penalties and heuristics refining the selection process.",
          "thought": "The new algorithm enhances the selection process by incorporating a dynamic weighting mechanism that adjusts the balance between immediate proximity and path efficiency based on the remaining unvisited nodes, while also introducing a local search penalty to prevent cycling and a heuristic for estimating the impact of choosing a node on the overall tour length.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    # Dynamic weighting based on remaining nodes\n    remaining_nodes = len(unvisited_nodes)\n    weight_proximity = 0.7 if remaining_nodes > 2 else 0.5\n    weight_efficiency = 1.0 - weight_proximity\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        node_to_dest = distance_matrix[node][destination_node]\n        total_increase = current_to_node + node_to_dest\n\n        # Local search penalty for nodes too close to current\n        penalty = 0.2 * (1.0 / (current_to_node + 1e-6)) if current_to_node < 0.3 else 0\n\n        # Heuristic for path efficiency (estimates impact on remaining tour)\n        heuristic = sum(min(distance_matrix[node][n], distance_matrix[n][node]) for n in unvisited_nodes if n != node)\n\n        # Combined score with dynamic weights and heuristic\n        score = (weight_proximity * current_to_node +\n                 weight_efficiency * total_increase +\n                 0.2 * heuristic) - penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.87563,
          "other_inf": null
     }
]