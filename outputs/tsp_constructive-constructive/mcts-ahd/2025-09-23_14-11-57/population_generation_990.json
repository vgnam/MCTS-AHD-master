[
     {
          "algorithm": "The algorithm adaptively balances immediate distance, future potential (weighted dynamically by progress), and penalties for reconsidered nodes, prioritizing immediate distances early and future costs later while penalizing late reconsiderations. It uses a normalized progress metric (0 to 1) to adjust the dynamic weight, decreasing future cost influence as the tour progresses. The weighted score combines these factors, with penalties applied only after half the nodes are visited.",
          "thought": "The new algorithm combines No.1's weighted balance between immediate and future distances with No.2's dynamic weight adjustment and penalty mechanism. It adaptively shifts focus from immediate distances to future costs while penalizing reconsidered nodes late in the process, using a normalized progress metric to modulate the dynamic weight.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes) if progress > 0.5 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.6 - 0.4 * progress  # Decrease future weight as progress increases\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44101,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distances (given a fixed weight of 0.5) while considering future potential (distance to the destination) for node selection. It applies a quadratic penalty to reconsidered nodes only after 70% progress, dynamically adjusting the penalty strength based on a linear progress metric. The code balances short-term and long-term considerations, with penalties only activated late in the process to refine choices.",
          "thought": "The new algorithm prioritizes immediate distances with a fixed future potential weight, applies a quadratic penalty for reconsidered nodes only after 70% progress, and uses a linear progress metric to dynamically adjust the penalty strength.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Linear progress metric (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = (sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes)) ** 2 if progress > 0.7 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.5  # Fixed future potential weight\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44688,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node in TSP by balancing immediate distance, future potential, exploration incentives, and path diversity, with weights dynamically adjusted based on progress (prioritizing future potential as progress increases). Immediate distance and future distance are weighted differently (distance_weight and future_weight), while exploration incentives (based on node centrality and connectivity) and diversity bonuses (comparing node-to-node distances) are given lower weights (0.4 and 0.3, respectively). The scoring mechanism combines these factors to minimize overall path cost while encouraging diverse, well-connected routes.",
          "thought": "The new algorithm modifies the original by incorporating a dynamic exploration-incentive mechanism that adjusts exploration bonuses based on node connectivity and path diversity, while maintaining a balance between immediate distance and future potential through adaptive weight modulation and a novel centrality-aware scoring mechanism.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    max_centrality = max(sum(row) / (total_nodes - 1) for row in distance_matrix)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = (1 - progress_factor) ** 2 * 0.8 + 0.2\n        future_weight = progress_factor ** 1.5 * 0.7 + 0.3\n\n        connectivity_bonus = (node_centrality / max_centrality) * (1 - (remaining_nodes / total_nodes))\n        exploration_incentive = (1 / (1 + immediate_distance)) * connectivity_bonus\n\n        diversity_factor = sum(1 for n in unvisited_nodes if distance_matrix[node][n] < immediate_distance * 1.5)\n        diversity_bonus = (diversity_factor / remaining_nodes) * 0.5\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.4 * exploration_incentive) + \\\n                         (0.3 * diversity_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.48777,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm balances immediate distance, future potential, and node centrality, with weights dynamically adjusted based on progress (higher future and centrality importance as progress increases). Exploration bonuses scale with distance and remaining nodes, while the final selection prioritizes the lowest combined score (minimizing distance, maximizing future potential and centrality). The code structures scores as a weighted sum of normalized components, with exploration bonuses subtracted for diversity.",
          "thought": "The new algorithm combines the dynamic weighting approach of No.2 with the progress-dependent centrality influence and exploration bonuses of No.1, adjusting weights to balance immediate distance, future potential, and node centrality based on progress, while incorporating exploration bonuses that scale with distance and remaining nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = 0.5 - 0.3 * progress_factor\n        future_weight = 0.2 + 0.3 * progress_factor\n        centrality_weight = 0.3 + 0.2 * progress_factor\n\n        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes) * (1 + (1.5 * (node_centrality / max(distance_matrix[node]))))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) + \\\n                         (centrality_weight * (1 / (1 + node_centrality))) - \\\n                         (0.5 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.489,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with dynamic weighting of immediate distance, future centrality, and node centrality, adjusting weights based on progress to balance exploration and exploitation. Early in the process, immediate distance is prioritized (distance_weight = 0.6), while later, future centrality and node centrality gain importance (future_weight and centrality_weight increase with progress). An exploration bonus encourages diverse paths, but the node with the lowest combined score (prioritizing immediate distance early, then future and centrality) is selected. The weights and exploration bonus dynamically adapt to the remaining unvisited nodes.",
          "thought": "The new algorithm combines nearest-neighbor selection with dynamic weighting of immediate distance, future centrality, and node centrality, adjusting weights based on progress to balance exploration and exploitation. It uses a progress-dependent exploration bonus to encourage diverse paths while favoring nodes that improve both short-term and long-term objectives. The next node is selected by minimizing a weighted sum of these factors, with weights dynamically adjusted to prioritize immediate distance early and future centrality later.",
          "code": "import math\n\ndef select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress = 1 - remaining_nodes / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = 0.6 - 0.4 * progress\n        future_weight = 0.2 + 0.4 * progress\n        centrality_weight = 0.2 + 0.2 * progress\n\n        exploration_bonus = (remaining_nodes / total_nodes) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) + \\\n                         (centrality_weight * (1 / (1 + node_centrality))) - \\\n                         (0.4 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.50834,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights for immediate distances (prioritized early) and future centrality (emphasized later), with a linear exploration bonus that fades as nodes are visited, resulting in a smooth transition. It avoids reconsideration penalties and uses a combined score of weighted immediate and future distances, with exploration bonuses, to select the next node. The progress variable (1 - remaining_nodes/total_nodes) controls the shift from distance-focused to centrality-focused selection.",
          "thought": "The new algorithm modifies the original by using a dynamic weight that emphasizes immediate distances early and future centrality later, with a linear exploration bonus and no reconsideration penalties, creating a smoother transition between exploration and exploitation phases.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress = 1 - remaining_nodes / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = 0.8 - 0.6 * progress\n        future_weight = 0.2 + 0.6 * progress\n\n        exploration_bonus = (remaining_nodes / total_nodes) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        reconsideration_penalty = 0\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.2 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.50876,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines immediate distance, future potential, and exploration bonuses, dynamically adjusting weights based on progress. It prioritizes immediate distance early (higher weight) and future potential later (higher weight), while balancing exploration via a bonus that considers node centrality and remaining nodes. The exploration bonus is inversely proportional to distance and centrality, with a modulation factor based on progress.",
          "thought": "The new algorithm combines No.1's exploration bonus with No.2's centrality-based future weighting, dynamically adjusting weights to balance immediate distance, future potential, and exploration, while modulating weights based on progress and incorporating a refined exploration bonus that considers both node centrality and remaining nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = (1 - progress_factor) * 0.6 + 0.4\n        future_weight = progress_factor * 0.5 + 0.5\n\n        exploration_bonus = (remaining_nodes / total_nodes) * (1 / (1 + immediate_distance)) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.4 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.51491,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines nearest-neighbor selection with adaptive weighting, prioritizing immediate distance early (high weight) and balancing future centrality and node centrality as progress advances (weights increase over time). It also includes an exploration bonus to encourage visiting less central nodes early, dynamically adjusting priorities to optimize path length. The combined score minimizes immediate distance, maximizes future and node centrality, and balances exploration, with weights scaling with progress.",
          "thought": "The new algorithm combines nearest-neighbor selection with adaptive weighting of immediate distance, future centrality, node centrality, and a progress-dependent exploration bonus, dynamically adjusting weights to prioritize immediate distance early and balance future centrality, node centrality, and exploration as progress advances, while minimizing the combined score to optimize the path length.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress = 1 - remaining_nodes / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = 0.7 - 0.5 * progress\n        future_weight = 0.2 + 0.3 * progress\n        centrality_weight = 0.1 + 0.2 * progress\n\n        exploration_bonus = (remaining_nodes / total_nodes) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) + \\\n                         (centrality_weight * (1 / (1 + node_centrality))) - \\\n                         (0.5 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.52022,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by balancing immediate distance, future potential, and node centrality, with weights adjusted based on progress (early stages prioritize exploration and centrality, later stages favor efficiency). It uses a progress-dependent centrality influence and exploration bonuses scaled by distance and remaining nodes, with the combined score minimizing immediate distance while considering future paths and node importance. The algorithm prioritizes exploration in early stages and efficiency in later stages, with centrality influencing both future potential and exploration bonuses.",
          "thought": "The new algorithm dynamically balances immediate distance, future potential, node centrality, and exploration diversity by adjusting weights based on progress (early stages prioritize exploration and centrality, later stages favor efficiency and future potential), using a progress-dependent centrality influence and exploration bonuses scaled by both distance and remaining nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = (1 - progress_factor) * 0.6 + 0.4 - (0.15 * (node_centrality / max(distance_matrix[node])))\n        future_weight = progress_factor * 0.5 + 0.5 + (0.25 * (node_centrality / max(distance_matrix[node])))\n        exploration_weight = (1 - progress_factor) * 0.4 + 0.6\n\n        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes) * (1 + (2 * (node_centrality / max(distance_matrix[node]))))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (exploration_weight * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.52656,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines a greedy approach with dynamic weighting and multi-step lookahead to balance immediate and future distances. It prioritizes immediate distances early in the search (higher `immediate_weight`) and future potential later (higher `future_weight`), while applying a memory penalty to discourage revisiting nodes. The `exploration_factor` encourages exploration in early stages, and normalization ensures fair comparison across nodes. The critical design choices are the dynamic adjustment of weights based on remaining nodes and the memory penalty to avoid cycles.",
          "thought": "This new algorithm combines the greedy lookahead mechanism of No.1 with the dynamic weighting and exploration penalty of No.2, while introducing a memory-based penalty to avoid revisiting recently visited nodes and a multi-step lookahead to better balance immediate and future distances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_immediate_weight = 0.5\n    base_future_weight = 0.5\n    stage_factor = 1.0 / (1.0 + 0.1 * remaining_nodes)\n\n    immediate_weight = base_immediate_weight * (1.0 - stage_factor)\n    future_weight = base_future_weight * (1.0 + stage_factor)\n\n    exploration_factor = 1.0 + 0.4 * (1.0 - (remaining_nodes / len(distance_matrix)))\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        if remaining_nodes > 2:\n            next_nodes = [n for n in unvisited_nodes if n != node]\n            future_potential = min(distance_matrix[node][n] + distance_matrix[n][destination_node] for n in next_nodes)\n        else:\n            future_potential = distance_matrix[node][destination_node]\n\n        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / len(distance_matrix))\n        normalized_future = future_potential / (sum(distance_matrix[node]) / len(distance_matrix))\n\n        memory_penalty = 0.2 * (1.0 / (immediate_distance + 1e-6)) * exploration_factor\n        combined_score = immediate_weight * normalized_immediate + future_weight * normalized_future - memory_penalty\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_node = node\n\n    return next_node",
          "objective": 6.52839,
          "other_inf": null
     }
]