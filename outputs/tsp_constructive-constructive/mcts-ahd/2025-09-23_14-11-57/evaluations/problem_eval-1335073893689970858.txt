import math

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    scores = []
    total_nodes = len(distance_matrix)
    remaining_nodes = len(unvisited_nodes)
    progress = 1 - remaining_nodes / total_nodes

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]

        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)
        avg_distance = sum(sum(row) for row in distance_matrix) / (total_nodes * (total_nodes - 1))

        distance_weight = (1 - progress) * 0.7 + 0.3 - (0.1 * (node_centrality / max(distance_matrix[node])))
        future_weight = progress * 0.6 + 0.4 + (0.2 * (node_centrality / max(distance_matrix[node])))

        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes) * (1 + (2 * (node_centrality / max(distance_matrix[node]))))

        revisit_penalty = 0
        if progress > 0.5:
            revisit_count = total_nodes - remaining_nodes - 1
            revisit_penalty = (revisit_count / total_nodes) * (immediate_distance / avg_distance)

        reward_factor = math.exp(-immediate_distance) * (1 / (1 + future_distance))

        combined_score = (distance_weight * immediate_distance) + \
                         (future_weight * (1 / (1 + future_distance))) + \
                         revisit_penalty - \
                         (0.5 * exploration_bonus) + \
                         (0.3 * (1 / reward_factor))

        scores.append(combined_score)

    selected_index = scores.index(min(scores))
    next_node = list(unvisited_nodes)[selected_index]

    return next_node
