import math

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    scores = []
    total_nodes = len(distance_matrix)
    remaining_nodes = len(unvisited_nodes)
    progress = 1 - remaining_nodes / total_nodes

    # Decaying exploration factor
    exploration_factor = math.exp(-progress * 3) * 0.3

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]

        # Path quality estimate (simplified reinforcement learning signal)
        path_quality = (immediate_distance + future_distance) / (1 + sum(distance_matrix[node]))

        # Node centrality adjusted by remaining nodes
        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)
        centrality_score = node_centrality * (1 - progress)

        # Dynamic weights with exploration component
        distance_weight = 0.5 + 0.3 * exploration_factor
        future_weight = 0.3 + 0.2 * (1 - exploration_factor)
        centrality_weight = 0.2 + 0.1 * (1 - exploration_factor)

        # Novel scoring equation combining all factors
        combined_score = (distance_weight * immediate_distance) + \
                         (future_weight * (1 / (1 + future_distance))) + \
                         (centrality_weight * centrality_score) + \
                         (exploration_factor * path_quality)

        scores.append(combined_score)

    selected_index = scores.index(min(scores))
    next_node = list(unvisited_nodes)[selected_index]

    return next_node
