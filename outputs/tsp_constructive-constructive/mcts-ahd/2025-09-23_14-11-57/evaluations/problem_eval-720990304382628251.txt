def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)
    temperature = 1 - progress  # Decrease temperature as progress increases

    scores = []
    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_potential = distance_matrix[node][destination_node]

        if len(unvisited_nodes) > 1:
            remaining_nodes = [n for n in unvisited_nodes if n != node]
            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)
            regret_penalty = (1 - progress) ** 2 * sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes)
        else:
            avg_remaining_dist = 0
            regret_penalty = 0

        dynamic_weight = 0.7 - 0.5 * progress  # More aggressive decrease in future weight
        weighted_score = immediate_distance + dynamic_weight * future_potential + regret_penalty
        scores.append((node, weighted_score))

    # Apply softmax selection with decreasing temperature
    exp_scores = [math.exp(-score / temperature) for _, score in scores]
    sum_exp_scores = sum(exp_scores)
    probs = [exp_score / sum_exp_scores for exp_score in exp_scores]

    next_node = random.choices([node for node, _ in scores], weights=probs, k=1)[0]
    return next_node
