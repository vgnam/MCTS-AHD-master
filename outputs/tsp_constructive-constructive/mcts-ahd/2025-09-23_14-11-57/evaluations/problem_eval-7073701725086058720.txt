import math

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    scores = []
    historical_weights = {node: 1.0 for node in unvisited_nodes}  # Initialize historical weights

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]

        # Dynamic weighting based on historical performance
        historical_factor = historical_weights[node]
        reward_factor = math.exp(-immediate_distance) * (1 / (1 + future_distance)) * historical_factor

        total_nodes = len(distance_matrix)
        remaining_nodes = len(unvisited_nodes)
        progress_factor = (total_nodes - remaining_nodes) / total_nodes

        # Adaptive scoring with exploration component
        exploration_bias = 1.0 / (1 + math.log(1 + immediate_distance))
        combined_score = (1 - progress_factor) * immediate_distance + progress_factor * (1 / reward_factor) + exploration_bias

        scores.append(combined_score)

    selected_index = scores.index(min(scores))
    next_node = list(unvisited_nodes)[selected_index]

    # Update historical weights based on selection
    for node in unvisited_nodes:
        if node == next_node:
            historical_weights[node] *= 0.9  # Reward selected node
        else:
            historical_weights[node] *= 1.1  # Penalize unselected nodes

    return next_node
