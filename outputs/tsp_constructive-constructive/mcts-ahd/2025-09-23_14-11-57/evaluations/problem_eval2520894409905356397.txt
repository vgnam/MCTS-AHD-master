def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)

    # Dynamic weight adaptation with multi-stage progression
    stage = 1.0 - (remaining_nodes / total_nodes)
    immediate_weight = 0.5 * (1.0 - stage) + 0.3
    future_weight = 0.5 * stage + 0.3
    diversity_weight = 0.2 * (1.0 - stage)

    # Exploration bonus based on historical traversal
    exploration_bonus = {}
    for node in unvisited_nodes:
        historical_penalty = sum(1.0 / (distance_matrix[current_node][n] + 1e-6) for n in unvisited_nodes if n != node)
        exploration_bonus[node] = 1.0 / (1.0 + historical_penalty)

    # Path diversity penalty
    diversity_penalty = {}
    for node in unvisited_nodes:
        diversity_penalty[node] = 0.0
        for other in unvisited_nodes:
            if other != node:
                diversity_penalty[node] += 1.0 / (distance_matrix[node][other] + 1e-6)

    best_node = None
    best_score = float('inf')

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_potential = distance_matrix[node][destination_node]

        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / total_nodes)
        normalized_future = future_potential / (sum(distance_matrix[node]) / total_nodes)

        combined_score = (immediate_weight * normalized_immediate +
                          future_weight * normalized_future -
                          diversity_weight * diversity_penalty[node] +
                          0.1 * exploration_bonus[node])

        if combined_score < best_score:
            best_score = combined_score
            best_node = node

    return next_node
