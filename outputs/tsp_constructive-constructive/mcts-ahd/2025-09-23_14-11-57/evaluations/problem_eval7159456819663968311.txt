def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix, visited_history=None):
    if not unvisited_nodes:
        return destination_node

    if visited_history is None:
        visited_history = {}

    best_node = None
    min_weighted_score = float('inf')
    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_potential = distance_matrix[node][destination_node]

        if len(unvisited_nodes) > 1:
            remaining_nodes = [n for n in unvisited_nodes if n != node]
            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)

            # Sigmoid-adjusted dynamic weight
            dynamic_weight = 1 / (1 + np.exp(-10 * (0.5 - progress)))  # Smooth transition from exploration to exploitation

            # Regret-based penalty
            penalty = 0
            if node in visited_history:
                penalty = (visited_history[node] / (visited_history[node] + 1)) * immediate_distance
        else:
            avg_remaining_dist = 0
            dynamic_weight = 0
            penalty = 0

        weighted_score = immediate_distance + dynamic_weight * (future_potential + avg_remaining_dist) + penalty

        if weighted_score < min_weighted_score:
            min_weighted_score = weighted_score
            best_node = node

    # Update visited history
    if best_node in visited_history:
        visited_history[best_node] += 1
    else:
        visited_history[best_node] = 1

    return next_node
