def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    scores = []
    total_nodes = len(distance_matrix)
    remaining_nodes = len(unvisited_nodes)
    progress = 1 - remaining_nodes / total_nodes

    centrality_weights = [sum(distance_matrix[node]) / (total_nodes - 1) for node in unvisited_nodes]
    max_centrality = max(centrality_weights) if centrality_weights else 1

    distance_variances = [np.var([distance_matrix[node][n] for n in unvisited_nodes if n != node]) for node in unvisited_nodes]

    for i, node in enumerate(unvisited_nodes):
        immediate_distance = distance_matrix[current_node][node]
        future_distance = distance_matrix[node][destination_node]

        normalized_centrality = centrality_weights[i] / max_centrality if max_centrality else 0
        normalized_variance = distance_variances[i] / max(distance_variances) if distance_variances else 0

        adaptive_weight = 0.5 + 0.5 * (1 - progress)
        distance_weight = 0.6 * adaptive_weight
        future_weight = 0.4 * adaptive_weight

        exploration_bonus = (1 / (1 + immediate_distance)) * (1 + normalized_centrality) * (1 + normalized_variance)

        if progress > 0.6:
            reconsideration_penalty = sum(distance_matrix[current_node][n] for n in unvisited_nodes if n != node) / len(unvisited_nodes)
            reconsideration_penalty *= (1 + progress)
        else:
            reconsideration_penalty = 0

        combined_score = (distance_weight * immediate_distance) + \
                         (future_weight * (1 / (1 + future_distance))) + \
                         reconsideration_penalty - \
                         (0.4 * exploration_bonus)

        scores.append(combined_score)

    selected_index = scores.index(min(scores))
    next_node = list(unvisited_nodes)[selected_index]

    return next_node
