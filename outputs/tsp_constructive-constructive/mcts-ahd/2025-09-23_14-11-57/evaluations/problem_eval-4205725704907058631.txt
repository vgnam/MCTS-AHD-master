def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    progress = 1.0 - remaining_nodes / total_nodes

    # Dynamic weights with inverted progress influence
    immediate_weight = 0.4 + 0.3 * progress
    future_weight = 0.3 - 0.2 * progress
    exploration_weight = 0.3 + 0.4 * progress

    best_node = None
    best_score = float('inf')

    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        future_potential = distance_matrix[node][destination_node]

        # Normalized scores
        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / total_nodes)
        normalized_future = future_potential / (sum(distance_matrix[node]) / total_nodes)

        # Exploration penalty based on remaining nodes
        exploration_penalty = exploration_weight * (1.0 / (1.0 + remaining_nodes)) * (1.0 / (immediate_distance + 1e-6))

        # Combined score with adaptive weights
        combined_score = (immediate_weight * normalized_immediate +
                          future_weight * normalized_future +
                          exploration_penalty)

        if combined_score < best_score:
            best_score = combined_score
            best_node = node

    return next_node
