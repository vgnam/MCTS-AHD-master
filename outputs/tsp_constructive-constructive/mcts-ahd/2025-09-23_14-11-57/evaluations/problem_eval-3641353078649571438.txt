import random
import math
from collections import defaultdict

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    progress = 1.0 - remaining_nodes / total_nodes

    # Historical visit frequencies (simulated)
    visit_counts = defaultdict(int)
    for node in unvisited_nodes:
        visit_counts[node] = random.randint(1, 10)  # Simulated historical data

    # Dynamic neighborhood density and momentum factors
    local_density = 1.0 / (1.0 + sum(distance_matrix[current_node][n] for n in unvisited_nodes) / len(unvisited_nodes))
    momentum = 0.3 * (1 - progress)  # Higher early, lower later

    # Adaptive weights with reinforcement learning elements
    exploration_weight = 0.4 + 0.3 * progress - 0.2 * local_density
    exploitation_weight = 0.5 - 0.3 * progress + 0.3 * local_density
    reward_weight = 0.6 - 0.4 * progress + 0.2 * local_density

    scores = []
    for node in unvisited_nodes:
        immediate_distance = distance_matrix[current_node][node]
        global_estimate = distance_matrix[node][destination_node]

        # Reinforcement learning components
        visit_reward = 1.0 / (1.0 + visit_counts[node])
        detour_penalty = max(0, (immediate_distance + distance_matrix[node][destination_node] - global_estimate) / global_estimate)

        # Neighborhood connectivity score
        if remaining_nodes > 1:
            remaining = [n for n in unvisited_nodes if n != node]
            neighborhood_score = 1.0 / (1.0 + sum(distance_matrix[node][n] for n in remaining) / len(remaining))
        else:
            neighborhood_score = 0

        # Combined score with momentum term
        score = (exploration_weight * immediate_distance +
                 exploitation_weight * global_estimate +
                 reward_weight * (1 - visit_reward) +
                 0.5 * (1 - neighborhood_score) +
                 0.8 * detour_penalty +
                 momentum * distance_matrix[current_node][node])

        scores.append(score)

    selected_index = scores.index(min(scores))
    next_node = list(unvisited_nodes)[selected_index]

    return next_node
