[
     {
          "algorithm": "The algorithm adaptively balances immediate distance, future potential (weighted dynamically by progress), and penalties for reconsidered nodes, prioritizing immediate distances early and future costs later while penalizing late reconsiderations. It uses a normalized progress metric (0 to 1) to adjust the dynamic weight, decreasing future cost influence as the tour progresses. The weighted score combines these factors, with penalties applied only after half the nodes are visited.",
          "thought": "The new algorithm combines No.1's weighted balance between immediate and future distances with No.2's dynamic weight adjustment and penalty mechanism. It adaptively shifts focus from immediate distances to future costs while penalizing reconsidered nodes late in the process, using a normalized progress metric to modulate the dynamic weight.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes) if progress > 0.5 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.6 - 0.4 * progress  # Decrease future weight as progress increases\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44101,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distances (given a fixed weight of 0.5) while considering future potential (distance to the destination) for node selection. It applies a quadratic penalty to reconsidered nodes only after 70% progress, dynamically adjusting the penalty strength based on a linear progress metric. The code balances short-term and long-term considerations, with penalties only activated late in the process to refine choices.",
          "thought": "The new algorithm prioritizes immediate distances with a fixed future potential weight, applies a quadratic penalty for reconsidered nodes only after 70% progress, and uses a linear progress metric to dynamically adjust the penalty strength.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Linear progress metric (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = (sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes)) ** 2 if progress > 0.7 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.5  # Fixed future potential weight\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44688,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines a greedy approach with dynamic weighting and multi-step lookahead to balance immediate and future distances. It prioritizes immediate distances early in the search (higher `immediate_weight`) and future potential later (higher `future_weight`), while applying a memory penalty to discourage revisiting nodes. The `exploration_factor` encourages exploration in early stages, and normalization ensures fair comparison across nodes. The critical design choices are the dynamic adjustment of weights based on remaining nodes and the memory penalty to avoid cycles.",
          "thought": "This new algorithm combines the greedy lookahead mechanism of No.1 with the dynamic weighting and exploration penalty of No.2, while introducing a memory-based penalty to avoid revisiting recently visited nodes and a multi-step lookahead to better balance immediate and future distances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_immediate_weight = 0.5\n    base_future_weight = 0.5\n    stage_factor = 1.0 / (1.0 + 0.1 * remaining_nodes)\n\n    immediate_weight = base_immediate_weight * (1.0 - stage_factor)\n    future_weight = base_future_weight * (1.0 + stage_factor)\n\n    exploration_factor = 1.0 + 0.4 * (1.0 - (remaining_nodes / len(distance_matrix)))\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        if remaining_nodes > 2:\n            next_nodes = [n for n in unvisited_nodes if n != node]\n            future_potential = min(distance_matrix[node][n] + distance_matrix[n][destination_node] for n in next_nodes)\n        else:\n            future_potential = distance_matrix[node][destination_node]\n\n        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / len(distance_matrix))\n        normalized_future = future_potential / (sum(distance_matrix[node]) / len(distance_matrix))\n\n        memory_penalty = 0.2 * (1.0 / (immediate_distance + 1e-6)) * exploration_factor\n        combined_score = immediate_weight * normalized_immediate + future_weight * normalized_future - memory_penalty\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_node = node\n\n    return next_node",
          "objective": 6.52839,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distance (highest weight) and future connectivity diversity (high weight) early, gradually shifting to regret (medium weight) and local density (lowest weight) as nodes are visited, using linear decay of weights to balance criteria throughout the selection process. The code calculates multiple metrics (distance, regret, diversity, density) for each unvisited node, combines them with dynamically adjusted weights, and selects the node with the minimum weighted score.",
          "thought": "The new algorithm prioritizes immediate distance and future connectivity diversity early with high weights, gradually shifting to local density and regret as nodes are visited, using linear decay of weights to maintain balance throughout the selection process.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    future_diversities = []\n    local_densities = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n        distances.append(immediate_distance)\n\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            other_distances = [distance_matrix[current_node][n] for n in other_nodes]\n            second_best = min(other_distances)\n            regret = immediate_distance - second_best\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        future_diversity = sum(1 for n in unvisited_nodes if n != node and distance_matrix[node][n] < 1.5 * immediate_distance)\n        future_diversities.append(future_diversity)\n\n        nearby_distances = [distance_matrix[node][n] for n in unvisited_nodes if n != node]\n        local_density = 1 / (sum(nearby_distances) / len(nearby_distances)) if nearby_distances else 0\n        local_densities.append(local_density)\n\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    distance_weight = 0.6 - (0.4 * remaining_nodes / total_nodes)\n    diversity_weight = 0.4 - (0.2 * remaining_nodes / total_nodes)\n    regret_weight = 0.2 * (1 - remaining_nodes / total_nodes)\n    density_weight = 0.1 * (1 - remaining_nodes / total_nodes)\n\n    scores = [\n        distance_weight * distance + diversity_weight * diversity +\n        regret_weight * regret + density_weight * density\n        for distance, diversity, regret, density in zip(\n            distances, future_diversities, regrets, local_densities\n        )\n    ]\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.56813,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node to visit in TSP by balancing immediate proximity (70% weight) and potential path efficiency (30% weight), while penalizing nodes too close to the current node to avoid cycles. The `select_next_node` function evaluates unvisited nodes based on their distance from the current node and their contribution to the overall path length, adjusting scores with a penalty term for very short distances.",
          "thought": "The new algorithm modifies the selection criterion by incorporating a weighted balance between immediate proximity to the current node and the potential to reduce the total path length, using a heuristic that considers both the current step and the overall path efficiency, while also introducing a penalty for revisiting nodes to avoid cycles.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        node_to_dest = distance_matrix[node][destination_node]\n        total_increase = current_to_node + node_to_dest\n\n        # Penalize nodes that are too close to avoid revisiting\n        penalty = 0.1 * (1.0 / (current_to_node + 1e-6)) if current_to_node < 0.5 else 0\n\n        # Weighted score: balance between immediate proximity and path efficiency\n        score = 0.7 * current_to_node + 0.3 * total_increase - penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.5779,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines immediate and lookahead distances with a weighted approach, prioritizing immediate distance (60%) over the best possible subsequent step (40%). It evaluates each unvisited node by computing a weighted sum of its direct distance from the current node and the shortest subsequent distance from that node, then selects the node with the lowest total score. The loop structure ensures all unvisited nodes are considered, while the distance matrix provides the necessary connectivity data.",
          "thought": "The new algorithm combines the balanced approach of No.2 (equal weights for immediate and lookahead distances) with the refined lookahead strategy of No.1 (evaluating the best possible subsequent step after the current candidate), while slightly adjusting the weights to favor immediate distance more than lookahead (60% vs. 40%).",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        best_lookahead_distance = float('inf')\n        for next_node in unvisited_nodes:\n            if next_node != node:\n                lookahead_distance = distance_matrix[node][next_node]\n                if lookahead_distance < best_lookahead_distance:\n                    best_lookahead_distance = lookahead_distance\n\n        score = 0.6 * immediate_distance + 0.4 * best_lookahead_distance\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.59312,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by combining regret-based selection (40% weight early, decaying), adaptive exploration (50% weight increasing with phase), and local clustering (10% weight increasing late). It prioritizes immediate distance (50%) and regret (30%) in node potential, while exploration factors balance near-term and long-term distances with a decaying weight. The phase-based weighting (0-1) adjusts priorities\u2014favoring regret early, exploration midway, and clustering late\u2014creating a balanced, adaptive heuristic.",
          "thought": "The new algorithm modifies the provided approach by introducing a dynamic priority system that combines regret-based selection with adaptive path exploration, using a novel \"node potential\" metric that integrates immediate distance, future connectivity, and local clustering, while employing a decaying weight scheme to balance exploration and exploitation across different phases of the tour construction.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    node_potentials = []\n    exploration_factors = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        # Calculate regret with dynamic scaling\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            other_distances = [distance_matrix[current_node][n] for n in other_nodes]\n            regret = immediate_distance - min(other_distances)\n            regret_scaled = regret * (1 + (sum(other_distances) / len(other_distances)) - immediate_distance)\n        else:\n            regret_scaled = 0\n\n        # Calculate exploration factor (future connectivity)\n        exploration = sum(1 for n in unvisited_nodes if n != node and\n                         distance_matrix[node][n] < 1.5 * immediate_distance)\n\n        # Calculate local clustering (inverse of average distance to nearby nodes)\n        nearby_distances = [distance_matrix[node][n] for n in unvisited_nodes if n != node]\n        clustering = 1 / (sum(nearby_distances) / len(nearby_distances)) if nearby_distances else 0\n\n        # Node potential combines distance, regret, and clustering\n        node_potential = (0.5 * immediate_distance + 0.3 * regret_scaled + 0.2 * clustering)\n        node_potentials.append(node_potential)\n\n        # Exploration factor balances immediate and future potential\n        exploration_factor = (0.6 * immediate_distance + 0.4 * future_distance) * (0.9 ** len(unvisited_nodes))\n        exploration_factors.append(exploration_factor)\n\n    # Adaptive weights with phase-based adjustment\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    phase = 1 - (remaining_nodes / total_nodes)\n\n    regret_weight = 0.4 * (1 - phase**2)\n    exploration_weight = 0.5 * phase\n    clustering_weight = 0.1 * phase**2\n\n    # Combine scores with dynamic weights\n    scores = [\n        regret_weight * potential + exploration_weight * factor + clustering_weight * (factor**0.5)\n        for potential, factor in zip(node_potentials, exploration_factors)\n    ]\n\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.59942,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node by balancing immediate distance, average future distances to remaining nodes, and a penalty for revisiting nodes, with the penalty factor (0.3) giving higher priority to minimizing immediate and future distances while slightly discouraging revisits. The score is computed as `current_to_node + avg_remaining_dist + revisit_penalty`, where `avg_remaining_dist` and `revisit_penalty` are dynamically adjusted based on unvisited nodes. The algorithm prioritizes proximity and future potential while slightly penalizing revisits.",
          "thought": "The new algorithm extends the original by incorporating a dynamic lookahead mechanism that evaluates not only the immediate distance but also the average distance to remaining nodes, combined with a penalty factor for revisiting nodes, ensuring a balance between proximity and future path potential.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n    penalty_factor = 0.3\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            revisit_penalty = penalty_factor * distance_matrix[current_node][node]\n        else:\n            avg_remaining_dist = 0\n            revisit_penalty = 0\n\n        score = current_to_node + avg_remaining_dist + revisit_penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.60833,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm combines regret-based selection, distance optimization, and clustering analysis with dynamic phase-based weighting. It prioritizes regret (high weight early) and clustering (higher weight later) while balancing distance (moderate weight throughout). The weights adapt based on remaining nodes, emphasizing regret early and clustering late. The \"look-ahead\" clustering considers both immediate and future connections to improve long-term path quality.",
          "thought": "The new algorithm combines the adaptive weighting of regret, distance, and clustering from all three algorithms, with dynamic phase-based adjustments, and incorporates a novel \"look-ahead\" clustering metric that considers both immediate and future connections to improve long-term path quality.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    clusterings = []\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        distances.append(immediate_distance)\n\n        # Calculate regret\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            second_best = min(distance_matrix[current_node][n] for n in other_nodes)\n            regret = (distance_matrix[current_node][node] - second_best) if distance_matrix[current_node][node] > second_best else 0\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        # Calculate look-ahead clustering\n        nearby_distances = [distance_matrix[node][n] for n in unvisited_nodes if n != node]\n        future_distances = [distance_matrix[node][destination_node]] if destination_node in unvisited_nodes else []\n        all_distances = nearby_distances + future_distances\n        clustering = 1 / (sum(all_distances) / len(all_distances)) if all_distances else 0\n        clusterings.append(clustering)\n\n    # Adaptive weights based on phase\n    remaining_nodes = len(unvisited_nodes)\n    total_nodes = len(distance_matrix)\n    phase = 1 - (remaining_nodes / total_nodes)\n    regret_weight = max(0.1, 0.8 * (1 - phase**3))\n    distance_weight = 0.3 * phase\n    clustering_weight = 0.2 * phase**2 + 0.1 * (1 - phase)\n\n    # Combine weighted scores\n    scores = [regret_weight * regret + distance_weight * distance + clustering_weight * clustering\n              for regret, distance, clustering in zip(regrets, distances, clusterings)]\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.67074,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines multiple TSP heuristics\u2014regret, immediate distance, proximity potential, and future diversity\u2014with dynamically adjusted weights. Early in the search, it heavily prioritizes regret and proximity (with exponential decay), while later focusing more on distance and diversity. The weights adapt based on remaining nodes, ensuring a smooth transition from exploration to exploitation. The regret is variance-adjusted to improve decision-making, and proximity potential considers both immediate and future distances. The algorithm selects the next node by minimizing a weighted combination of these factors.",
          "thought": "The new algorithm combines adaptive weighting of regret, immediate distance, proximity potential, and future diversity, with weights dynamically adjusted based on remaining nodes to prioritize regret and proximity early while gradually emphasizing distance and diversity, using exponential decay for smoother transitions and variance-adjusted regret scaling for better decision-making.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    proximity_potentials = []\n    future_diversities = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n        distances.append(immediate_distance)\n\n        # Calculate regret with variance-adjusted scaling\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            other_distances = [distance_matrix[current_node][n] for n in other_nodes]\n            variance = sum((d - sum(other_distances)/len(other_distances))**2 for d in other_distances) / len(other_distances)\n            second_best = min(other_distances)\n            regret = (distance_matrix[current_node][node] - second_best) * (1 + variance)\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        # Calculate proximity potential with exponential decay\n        remaining_nodes = len(unvisited_nodes)\n        proximity_potential = (immediate_distance + future_potential) * (0.9 ** remaining_nodes)\n        proximity_potentials.append(proximity_potential)\n\n        # Calculate future diversity\n        future_diversity = sum(1 for n in unvisited_nodes if n != node and distance_matrix[node][n] < 2 * immediate_distance)\n        future_diversities.append(future_diversity)\n\n    # Adaptive weights with exponential decay\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    regret_weight = 0.5 * (0.8 ** remaining_nodes)\n    distance_weight = 0.3 * (0.8 ** remaining_nodes)\n    proximity_weight = 0.4 * (0.8 ** remaining_nodes)\n    diversity_weight = 0.2 * (1 - 0.8 ** remaining_nodes)\n\n    # Combine weighted scores\n    scores = [\n        regret_weight * regret + distance_weight * distance + proximity_weight * potential + diversity_weight * diversity\n        for regret, distance, potential, diversity in zip(\n            regrets, distances, proximity_potentials, future_diversities\n        )\n    ]\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.67613,
          "other_inf": null
     }
]