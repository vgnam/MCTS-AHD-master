[
     {
          "algorithm": "The algorithm adaptively balances immediate distance, future potential (weighted dynamically by progress), and penalties for reconsidered nodes, prioritizing immediate distances early and future costs later while penalizing late reconsiderations. It uses a normalized progress metric (0 to 1) to adjust the dynamic weight, decreasing future cost influence as the tour progresses. The weighted score combines these factors, with penalties applied only after half the nodes are visited.",
          "thought": "The new algorithm combines No.1's weighted balance between immediate and future distances with No.2's dynamic weight adjustment and penalty mechanism. It adaptively shifts focus from immediate distances to future costs while penalizing reconsidered nodes late in the process, using a normalized progress metric to modulate the dynamic weight.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Normalized progress (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes) if progress > 0.5 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.6 - 0.4 * progress  # Decrease future weight as progress increases\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44101,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distances (given a fixed weight of 0.5) while considering future potential (distance to the destination) for node selection. It applies a quadratic penalty to reconsidered nodes only after 70% progress, dynamically adjusting the penalty strength based on a linear progress metric. The code balances short-term and long-term considerations, with penalties only activated late in the process to refine choices.",
          "thought": "The new algorithm prioritizes immediate distances with a fixed future potential weight, applies a quadratic penalty for reconsidered nodes only after 70% progress, and uses a linear progress metric to dynamically adjust the penalty strength.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    min_weighted_score = float('inf')\n    progress = 1 - len(unvisited_nodes) / (len(unvisited_nodes) + 1)  # Linear progress metric (0 to 1)\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n\n        if len(unvisited_nodes) > 1:\n            remaining_nodes = [n for n in unvisited_nodes if n != node]\n            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes)\n            penalty = (sum(distance_matrix[current_node][n] for n in remaining_nodes) / len(remaining_nodes)) ** 2 if progress > 0.7 else 0\n        else:\n            avg_remaining_dist = 0\n            penalty = 0\n\n        dynamic_weight = 0.5  # Fixed future potential weight\n        weighted_score = immediate_distance + dynamic_weight * future_potential + penalty\n\n        if weighted_score < min_weighted_score:\n            min_weighted_score = weighted_score\n            best_node = node\n\n    return next_node",
          "objective": 6.44688,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances exploration and exploitation by adjusting weights for immediate distances (prioritized early) and future centrality (emphasized later), with a linear exploration bonus that fades as nodes are visited, resulting in a smooth transition. It avoids reconsideration penalties and uses a combined score of weighted immediate and future distances, with exploration bonuses, to select the next node. The progress variable (1 - remaining_nodes/total_nodes) controls the shift from distance-focused to centrality-focused selection.",
          "thought": "The new algorithm modifies the original by using a dynamic weight that emphasizes immediate distances early and future centrality later, with a linear exploration bonus and no reconsideration penalties, creating a smoother transition between exploration and exploitation phases.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress = 1 - remaining_nodes / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = 0.8 - 0.6 * progress\n        future_weight = 0.2 + 0.6 * progress\n\n        exploration_bonus = (remaining_nodes / total_nodes) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        reconsideration_penalty = 0\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.2 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.50876,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by balancing immediate distance, future potential, and node centrality, with weights adjusted based on progress (early stages prioritize exploration and centrality, later stages favor efficiency). It uses a progress-dependent centrality influence and exploration bonuses scaled by distance and remaining nodes, with the combined score minimizing immediate distance while considering future paths and node importance. The algorithm prioritizes exploration in early stages and efficiency in later stages, with centrality influencing both future potential and exploration bonuses.",
          "thought": "The new algorithm dynamically balances immediate distance, future potential, node centrality, and exploration diversity by adjusting weights based on progress (early stages prioritize exploration and centrality, later stages favor efficiency and future potential), using a progress-dependent centrality influence and exploration bonuses scaled by both distance and remaining nodes.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        distance_weight = (1 - progress_factor) * 0.6 + 0.4 - (0.15 * (node_centrality / max(distance_matrix[node])))\n        future_weight = progress_factor * 0.5 + 0.5 + (0.25 * (node_centrality / max(distance_matrix[node])))\n        exploration_weight = (1 - progress_factor) * 0.4 + 0.6\n\n        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes) * (1 + (2 * (node_centrality / max(distance_matrix[node]))))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (exploration_weight * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.52656,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm combines a greedy approach with dynamic weighting and multi-step lookahead to balance immediate and future distances. It prioritizes immediate distances early in the search (higher `immediate_weight`) and future potential later (higher `future_weight`), while applying a memory penalty to discourage revisiting nodes. The `exploration_factor` encourages exploration in early stages, and normalization ensures fair comparison across nodes. The critical design choices are the dynamic adjustment of weights based on remaining nodes and the memory penalty to avoid cycles.",
          "thought": "This new algorithm combines the greedy lookahead mechanism of No.1 with the dynamic weighting and exploration penalty of No.2, while introducing a memory-based penalty to avoid revisiting recently visited nodes and a multi-step lookahead to better balance immediate and future distances.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    remaining_nodes = len(unvisited_nodes)\n    base_immediate_weight = 0.5\n    base_future_weight = 0.5\n    stage_factor = 1.0 / (1.0 + 0.1 * remaining_nodes)\n\n    immediate_weight = base_immediate_weight * (1.0 - stage_factor)\n    future_weight = base_future_weight * (1.0 + stage_factor)\n\n    exploration_factor = 1.0 + 0.4 * (1.0 - (remaining_nodes / len(distance_matrix)))\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n\n        if remaining_nodes > 2:\n            next_nodes = [n for n in unvisited_nodes if n != node]\n            future_potential = min(distance_matrix[node][n] + distance_matrix[n][destination_node] for n in next_nodes)\n        else:\n            future_potential = distance_matrix[node][destination_node]\n\n        normalized_immediate = immediate_distance / (sum(distance_matrix[current_node]) / len(distance_matrix))\n        normalized_future = future_potential / (sum(distance_matrix[node]) / len(distance_matrix))\n\n        memory_penalty = 0.2 * (1.0 / (immediate_distance + 1e-6)) * exploration_factor\n        combined_score = immediate_weight * normalized_immediate + future_weight * normalized_future - memory_penalty\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_node = node\n\n    return next_node",
          "objective": 6.52839,
          "other_inf": null
     },
     {
          "algorithm": "This algorithm dynamically balances exploration and exploitation by prioritizing immediate distances early in the search (using a phase-based weighting system) while gradually favoring future costs (to the destination) and penalizing revisits to avoid cycles. It incorporates probabilistic exploration bonuses based on node centrality and distance, with higher weights given to central nodes early on, and a memory-based penalty that increases with revisits to encourage diverse paths. The selection is made by minimizing a combined score that adaptively adjusts weights between immediate, future, and exploration factors.",
          "thought": "This new algorithm introduces a dynamic phase-based weighting system that adapts to the search phase (early vs. late) by using non-linear progress weighting, incorporates a probabilistic exploration component based on node centrality and distance, and applies a memory-based penalty mechanism that increases with revisits to encourage diverse paths, while maintaining a balance between immediate and future costs through adaptive weight adjustments.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress = 1 - remaining_nodes / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n        avg_distance = sum(sum(row) for row in distance_matrix) / (total_nodes * (total_nodes - 1))\n\n        phase_factor = (progress ** 2) if progress <= 0.5 else (1 - (1 - progress) ** 2)\n        distance_weight = 0.8 - 0.6 * phase_factor\n        future_weight = 0.2 + 0.6 * phase_factor\n\n        exploration_prob = (node_centrality / avg_distance) * (1 - progress)\n        exploration_bonus = (1 / (1 + immediate_distance)) * exploration_prob * (1 + (2 * (node_centrality / max(distance_matrix[node]))))\n\n        revisit_penalty = 0\n        if progress > 0.5:\n            revisit_count = total_nodes - remaining_nodes - 1\n            revisit_penalty = (revisit_count / total_nodes) * (immediate_distance / avg_distance)\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) + \\\n                         revisit_penalty - \\\n                         (0.4 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.54022,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm prioritizes immediate distance (highest weight) and future connectivity diversity (high weight) early, gradually shifting to regret (medium weight) and local density (lowest weight) as nodes are visited, using linear decay of weights to balance criteria throughout the selection process. The code calculates multiple metrics (distance, regret, diversity, density) for each unvisited node, combines them with dynamically adjusted weights, and selects the node with the minimum weighted score.",
          "thought": "The new algorithm prioritizes immediate distance and future connectivity diversity early with high weights, gradually shifting to local density and regret as nodes are visited, using linear decay of weights to maintain balance throughout the selection process.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    distances = []\n    regrets = []\n    future_diversities = []\n    local_densities = []\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_potential = distance_matrix[node][destination_node]\n        distances.append(immediate_distance)\n\n        other_nodes = [n for n in unvisited_nodes if n != node]\n        if other_nodes:\n            other_distances = [distance_matrix[current_node][n] for n in other_nodes]\n            second_best = min(other_distances)\n            regret = immediate_distance - second_best\n        else:\n            regret = 0\n        regrets.append(regret)\n\n        future_diversity = sum(1 for n in unvisited_nodes if n != node and distance_matrix[node][n] < 1.5 * immediate_distance)\n        future_diversities.append(future_diversity)\n\n        nearby_distances = [distance_matrix[node][n] for n in unvisited_nodes if n != node]\n        local_density = 1 / (sum(nearby_distances) / len(nearby_distances)) if nearby_distances else 0\n        local_densities.append(local_density)\n\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    distance_weight = 0.6 - (0.4 * remaining_nodes / total_nodes)\n    diversity_weight = 0.4 - (0.2 * remaining_nodes / total_nodes)\n    regret_weight = 0.2 * (1 - remaining_nodes / total_nodes)\n    density_weight = 0.1 * (1 - remaining_nodes / total_nodes)\n\n    scores = [\n        distance_weight * distance + diversity_weight * diversity +\n        regret_weight * regret + density_weight * density\n        for distance, diversity, regret, density in zip(\n            distances, future_diversities, regrets, local_densities\n        )\n    ]\n    min_score = min(scores)\n    selected_index = scores.index(min_score)\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.56813,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically balances immediate distance, future potential, and exploration diversity by adjusting weights based on progress (earlier stages prioritize exploration, later stages favor efficiency). It uses a progress factor to modulate weights (distance_weight decreases, future_weight increases) and incorporates an exploration bonus scaled inversely with distance and remaining nodes. The combined score prioritizes minimizing immediate and future distances while encouraging diversity early on.",
          "thought": "The new algorithm modifies the original by incorporating a dynamic weight adjustment mechanism that balances immediate distance, future potential, and a novel \"exploration bonus\" term to encourage diversity in early selection while maintaining efficiency as the path nears completion.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        # Dynamic weight adjustment\n        distance_weight = (1 - progress_factor) * 0.8 + 0.2\n        future_weight = progress_factor * 0.7 + 0.3\n\n        # Exploration bonus for diversity\n        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes)\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.5 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.57163,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm selects the next node to visit in TSP by balancing immediate proximity (70% weight) and potential path efficiency (30% weight), while penalizing nodes too close to the current node to avoid cycles. The `select_next_node` function evaluates unvisited nodes based on their distance from the current node and their contribution to the overall path length, adjusting scores with a penalty term for very short distances.",
          "thought": "The new algorithm modifies the selection criterion by incorporating a weighted balance between immediate proximity to the current node and the potential to reduce the total path length, using a heuristic that considers both the current step and the overall path efficiency, while also introducing a penalty for revisiting nodes to avoid cycles.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    best_node = None\n    best_score = float('inf')\n\n    for node in unvisited_nodes:\n        current_to_node = distance_matrix[current_node][node]\n        node_to_dest = distance_matrix[node][destination_node]\n        total_increase = current_to_node + node_to_dest\n\n        # Penalize nodes that are too close to avoid revisiting\n        penalty = 0.1 * (1.0 / (current_to_node + 1e-6)) if current_to_node < 0.5 else 0\n\n        # Weighted score: balance between immediate proximity and path efficiency\n        score = 0.7 * current_to_node + 0.3 * total_increase - penalty\n\n        if score < best_score:\n            best_score = score\n            best_node = node\n\n    return next_node",
          "objective": 6.5779,
          "other_inf": null
     },
     {
          "algorithm": "The algorithm dynamically selects the next node in TSP by balancing immediate distance, future potential, and node centrality, with weights adjusted based on progress (prioritizing future potential as progress increases) and centrality (favoring nodes with high connectivity). It uses a centrality score to scale exploration bonuses and penalizes long-term distances more heavily early on while emphasizing future efficiency as the tour progresses. The code prioritizes minimizing immediate and future distances while balancing exploration via a combined score.",
          "thought": "The new algorithm enhances the original by incorporating a dynamic adaptation mechanism that adjusts weights based on both progress and node centrality, using a novel centrality score that combines immediate distance, future potential, and node connectivity, while maintaining the original's exploration bonus but with a more sophisticated scaling factor.",
          "code": "def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):\n    if not unvisited_nodes:\n        return destination_node\n\n    scores = []\n    total_nodes = len(distance_matrix)\n    remaining_nodes = len(unvisited_nodes)\n    progress_factor = (total_nodes - remaining_nodes) / total_nodes\n\n    # Calculate centrality scores for each node\n    centrality_scores = []\n    for node in unvisited_nodes:\n        immediate_distance = distance_matrix[current_node][node]\n        future_distance = distance_matrix[node][destination_node]\n\n        # Calculate node centrality based on average distance to all other nodes\n        node_centrality = sum(distance_matrix[node]) / (total_nodes - 1)\n\n        # Dynamic weight adjustment with centrality influence\n        distance_weight = (1 - progress_factor) * 0.7 + 0.3 - (0.1 * (node_centrality / max(distance_matrix[node])))\n        future_weight = progress_factor * 0.6 + 0.4 + (0.2 * (node_centrality / max(distance_matrix[node])))\n\n        # Exploration bonus with centrality-aware scaling\n        exploration_bonus = (1 / (1 + immediate_distance)) * (remaining_nodes / total_nodes) * (1 + (node_centrality / max(distance_matrix[node])))\n\n        combined_score = (distance_weight * immediate_distance) + \\\n                         (future_weight * (1 / (1 + future_distance))) - \\\n                         (0.6 * exploration_bonus)\n\n        scores.append(combined_score)\n\n    selected_index = scores.index(min(scores))\n    next_node = list(unvisited_nodes)[selected_index]\n\n    return next_node",
          "objective": 6.58956,
          "other_inf": null
     }
]