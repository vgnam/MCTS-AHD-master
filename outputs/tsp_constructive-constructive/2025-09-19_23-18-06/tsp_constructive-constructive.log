[2025-09-19 23:18:06,653][root][INFO] - Workspace: D:\MCTS-AHD-master\outputs\tsp_constructive-constructive\2025-09-19_23-18-06
[2025-09-19 23:18:06,653][root][INFO] - Project Root: D:\MCTS-AHD-master
[2025-09-19 23:18:06,654][root][INFO] - Using LLM: mistral/codestral-latest
[2025-09-19 23:18:06,654][root][INFO] - Using Algorithm: mcts-ahd
[2025-09-19 23:18:06,725][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:07,910][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:07,926][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:07,928][root][INFO] - LLM usage: prompt_tokens = 163, completion_tokens = 95
[2025-09-19 23:18:07,929][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:08,983][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:08,985][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:08,986][root][INFO] - LLM usage: prompt_tokens = 445, completion_tokens = 197
[2025-09-19 23:18:08,987][root][INFO] - Iteration 0: Running Code -9023721833840542948
[2025-09-19 23:18:09,475][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:09,544][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:18:09,545][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:10,669][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:10,673][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:10,679][root][INFO] - LLM usage: prompt_tokens = 842, completion_tokens = 351
[2025-09-19 23:18:10,681][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:11,595][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:11,599][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:11,604][root][INFO] - LLM usage: prompt_tokens = 1100, completion_tokens = 444
[2025-09-19 23:18:11,606][root][INFO] - Iteration 0: Running Code 7933494222087287344
[2025-09-19 23:18:12,116][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:18:12,153][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:12,153][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:13,206][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:13,210][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:13,212][root][INFO] - LLM usage: prompt_tokens = 1497, completion_tokens = 593
[2025-09-19 23:18:13,212][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:14,300][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:14,304][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:14,309][root][INFO] - LLM usage: prompt_tokens = 1756, completion_tokens = 672
[2025-09-19 23:18:14,312][root][INFO] - Iteration 0: Running Code -9038440628593359677
[2025-09-19 23:18:14,810][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:18:14,848][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:14,849][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:16,055][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:16,056][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:16,058][root][INFO] - LLM usage: prompt_tokens = 2153, completion_tokens = 848
[2025-09-19 23:18:16,058][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:17,120][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:17,124][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:17,129][root][INFO] - LLM usage: prompt_tokens = 2413, completion_tokens = 941
[2025-09-19 23:18:17,131][root][INFO] - Iteration 0: Running Code -9038440628593359677
[2025-09-19 23:18:17,663][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:18:17,699][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:17,700][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:18,979][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:18,983][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:18,988][root][INFO] - LLM usage: prompt_tokens = 2810, completion_tokens = 1129
[2025-09-19 23:18:18,990][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:20,291][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:20,295][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:20,301][root][INFO] - LLM usage: prompt_tokens = 3190, completion_tokens = 1254
[2025-09-19 23:18:20,303][root][INFO] - Iteration 0: Running Code -2082811658108239060
[2025-09-19 23:18:20,813][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:20,862][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:20,863][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:22,599][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:22,601][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:22,602][root][INFO] - LLM usage: prompt_tokens = 3587, completion_tokens = 1462
[2025-09-19 23:18:22,602][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:23,757][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:23,761][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:23,767][root][INFO] - LLM usage: prompt_tokens = 3987, completion_tokens = 1554
[2025-09-19 23:18:23,769][root][INFO] - Iteration 0: Running Code -3039088771380614416
[2025-09-19 23:18:24,269][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:24,305][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:24,306][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:25,907][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:25,911][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:25,917][root][INFO] - LLM usage: prompt_tokens = 4384, completion_tokens = 1754
[2025-09-19 23:18:25,919][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:27,044][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:27,048][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:27,053][root][INFO] - LLM usage: prompt_tokens = 4776, completion_tokens = 1851
[2025-09-19 23:18:27,055][root][INFO] - Iteration 0: Running Code 3540655414463686209
[2025-09-19 23:18:27,580][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:28,308][root][INFO] - Iteration 0, response_id 0: Objective value: 8.38246197867023
[2025-09-19 23:18:28,309][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:30,016][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:30,018][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:30,023][root][INFO] - LLM usage: prompt_tokens = 5551, completion_tokens = 2094
[2025-09-19 23:18:30,024][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:31,147][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:31,151][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:31,157][root][INFO] - LLM usage: prompt_tokens = 5986, completion_tokens = 2202
[2025-09-19 23:18:31,159][root][INFO] - Iteration 0: Running Code -8302438661772430546
[2025-09-19 23:18:31,647][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:31,685][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:31,686][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:33,000][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:33,002][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:33,006][root][INFO] - LLM usage: prompt_tokens = 6761, completion_tokens = 2403
[2025-09-19 23:18:33,007][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:34,064][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:34,068][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:34,073][root][INFO] - LLM usage: prompt_tokens = 7154, completion_tokens = 2486
[2025-09-19 23:18:34,075][root][INFO] - Iteration 0: Running Code -8319999266094524305
[2025-09-19 23:18:34,602][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:35,406][root][INFO] - Iteration 0, response_id 0: Objective value: 7.446624865203746
[2025-09-19 23:18:35,407][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:36,998][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:37,001][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:37,006][root][INFO] - LLM usage: prompt_tokens = 8175, completion_tokens = 2668
[2025-09-19 23:18:37,007][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:38,749][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:38,752][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:38,755][root][INFO] - LLM usage: prompt_tokens = 8549, completion_tokens = 2748
[2025-09-19 23:18:38,756][root][INFO] - Iteration 0: Running Code -8178120078137810560
[2025-09-19 23:18:39,252][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:39,959][root][INFO] - Iteration 0, response_id 0: Objective value: 7.624956896119002
[2025-09-19 23:18:39,960][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:41,182][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:41,187][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:41,193][root][INFO] - LLM usage: prompt_tokens = 9258, completion_tokens = 2964
[2025-09-19 23:18:41,195][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:42,213][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:42,219][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:42,224][root][INFO] - LLM usage: prompt_tokens = 9666, completion_tokens = 3073
[2025-09-19 23:18:42,226][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:43,648][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:43,652][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:43,659][root][INFO] - LLM usage: prompt_tokens = 10349, completion_tokens = 3266
[2025-09-19 23:18:43,660][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:44,936][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:44,938][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:44,940][root][INFO] - LLM usage: prompt_tokens = 10734, completion_tokens = 3385
[2025-09-19 23:18:44,940][root][INFO] - Iteration 0: Running Code 3580049960973486073
[2025-09-19 23:18:45,433][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:46,138][root][INFO] - Iteration 0, response_id 0: Objective value: 7.469096015925271
[2025-09-19 23:18:46,139][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:48,844][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:48,847][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:48,848][root][INFO] - LLM usage: prompt_tokens = 11110, completion_tokens = 3525
[2025-09-19 23:18:48,849][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:49,760][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:49,763][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:49,765][root][INFO] - LLM usage: prompt_tokens = 11442, completion_tokens = 3615
[2025-09-19 23:18:49,765][root][INFO] - Iteration 0: Running Code 4435168693327001135
[2025-09-19 23:18:50,253][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:50,776][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:18:50,777][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:51,892][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:51,895][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:51,898][root][INFO] - LLM usage: prompt_tokens = 11799, completion_tokens = 3767
[2025-09-19 23:18:51,899][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:52,892][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:52,896][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:52,901][root][INFO] - LLM usage: prompt_tokens = 12113, completion_tokens = 3840
[2025-09-19 23:18:52,903][root][INFO] - Iteration 0: Running Code -389823077414691058
[2025-09-19 23:18:53,402][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:18:53,440][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:53,440][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:54,729][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:54,731][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:54,733][root][INFO] - LLM usage: prompt_tokens = 12470, completion_tokens = 4025
[2025-09-19 23:18:54,733][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:55,637][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:55,641][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:55,645][root][INFO] - LLM usage: prompt_tokens = 12829, completion_tokens = 4095
[2025-09-19 23:18:55,646][root][INFO] - Iteration 0: Running Code -728292564767379212
[2025-09-19 23:18:56,145][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:18:56,183][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:56,183][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:57,420][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:57,423][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:57,429][root][INFO] - LLM usage: prompt_tokens = 13186, completion_tokens = 4271
[2025-09-19 23:18:57,431][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:18:58,221][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:18:58,225][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:18:58,226][root][INFO] - LLM usage: prompt_tokens = 13554, completion_tokens = 4337
[2025-09-19 23:18:58,227][root][INFO] - Iteration 0: Running Code -4126113620259478888
[2025-09-19 23:18:58,717][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:18:58,753][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:18:58,754][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:00,410][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:00,414][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:00,416][root][INFO] - LLM usage: prompt_tokens = 14272, completion_tokens = 4577
[2025-09-19 23:19:00,416][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:01,440][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:01,444][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:01,450][root][INFO] - LLM usage: prompt_tokens = 14704, completion_tokens = 4671
[2025-09-19 23:19:01,452][root][INFO] - Iteration 0: Running Code 6018591985385797500
[2025-09-19 23:19:01,938][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:03,178][root][INFO] - Iteration 0, response_id 0: Objective value: 14.727729555124103
[2025-09-19 23:19:03,179][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:04,930][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:04,934][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:04,940][root][INFO] - LLM usage: prompt_tokens = 15106, completion_tokens = 4894
[2025-09-19 23:19:04,942][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:06,045][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:06,049][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:06,053][root][INFO] - LLM usage: prompt_tokens = 15521, completion_tokens = 4984
[2025-09-19 23:19:06,055][root][INFO] - Iteration 0: Running Code 7401217093758628195
[2025-09-19 23:19:06,550][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:07,730][root][INFO] - Iteration 0, response_id 0: Objective value: 6.6083304961946165
[2025-09-19 23:19:07,731][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:08,911][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:08,913][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:08,914][root][INFO] - LLM usage: prompt_tokens = 15904, completion_tokens = 5157
[2025-09-19 23:19:08,915][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:10,019][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:10,021][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:10,024][root][INFO] - LLM usage: prompt_tokens = 16264, completion_tokens = 5254
[2025-09-19 23:19:10,025][root][INFO] - Iteration 0: Running Code 8117883217024307259
[2025-09-19 23:19:10,524][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:11,045][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:19:11,046][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:12,682][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:12,687][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:12,693][root][INFO] - LLM usage: prompt_tokens = 16881, completion_tokens = 5411
[2025-09-19 23:19:12,694][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:13,700][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:13,704][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:13,710][root][INFO] - LLM usage: prompt_tokens = 17230, completion_tokens = 5496
[2025-09-19 23:19:13,712][root][INFO] - Iteration 0: Running Code 1576260772438228185
[2025-09-19 23:19:14,211][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:14,248][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:19:14,248][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:15,651][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:15,656][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:15,662][root][INFO] - LLM usage: prompt_tokens = 17847, completion_tokens = 5699
[2025-09-19 23:19:15,663][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:16,760][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:16,764][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:16,769][root][INFO] - LLM usage: prompt_tokens = 18242, completion_tokens = 5806
[2025-09-19 23:19:16,772][root][INFO] - Iteration 0: Running Code 5379138313770419558
[2025-09-19 23:19:17,280][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:17,840][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:19:17,842][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:19,371][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:19,373][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:19,375][root][INFO] - LLM usage: prompt_tokens = 19027, completion_tokens = 6076
[2025-09-19 23:19:19,375][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:20,801][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:20,805][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:20,807][root][INFO] - LLM usage: prompt_tokens = 19484, completion_tokens = 6172
[2025-09-19 23:19:20,807][root][INFO] - Iteration 0: Running Code -5566560298776414350
[2025-09-19 23:19:21,297][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:23,112][root][INFO] - Iteration 0, response_id 0: Objective value: 7.548675330050564
[2025-09-19 23:19:23,113][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:25,084][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:25,087][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:25,089][root][INFO] - LLM usage: prompt_tokens = 19962, completion_tokens = 6511
[2025-09-19 23:19:25,089][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:26,264][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:26,268][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:26,274][root][INFO] - LLM usage: prompt_tokens = 20493, completion_tokens = 6615
[2025-09-19 23:19:26,277][root][INFO] - Iteration 0: Running Code 6019225903593997847
[2025-09-19 23:19:26,793][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:28,695][root][INFO] - Iteration 0, response_id 0: Objective value: 6.925865461999637
[2025-09-19 23:19:28,696][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:29,992][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:29,994][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:29,997][root][INFO] - LLM usage: prompt_tokens = 20952, completion_tokens = 6833
[2025-09-19 23:19:29,997][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:30,955][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:30,959][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:30,961][root][INFO] - LLM usage: prompt_tokens = 21362, completion_tokens = 6899
[2025-09-19 23:19:30,961][root][INFO] - Iteration 0: Running Code 2659193057746388468
[2025-09-19 23:19:31,452][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:32,651][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9387571193957545
[2025-09-19 23:19:32,654][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:33,999][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:34,001][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:34,003][root][INFO] - LLM usage: prompt_tokens = 22263, completion_tokens = 7130
[2025-09-19 23:19:34,004][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:35,044][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:35,047][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:35,049][root][INFO] - LLM usage: prompt_tokens = 22681, completion_tokens = 7216
[2025-09-19 23:19:35,051][root][INFO] - Iteration 0: Running Code 2730105180279404573
[2025-09-19 23:19:35,548][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:36,712][root][INFO] - Iteration 0, response_id 0: Objective value: 6.6083304961946165
[2025-09-19 23:19:36,715][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:38,309][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:38,314][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:38,320][root][INFO] - LLM usage: prompt_tokens = 23475, completion_tokens = 7465
[2025-09-19 23:19:38,322][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:39,575][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:39,576][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:39,578][root][INFO] - LLM usage: prompt_tokens = 23916, completion_tokens = 7557
[2025-09-19 23:19:39,578][root][INFO] - Iteration 0: Running Code 1466157023855148756
[2025-09-19 23:19:40,111][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:41,374][root][INFO] - Iteration 0, response_id 0: Objective value: 6.622385941112075
[2025-09-19 23:19:41,375][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:42,783][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:42,787][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:42,793][root][INFO] - LLM usage: prompt_tokens = 24373, completion_tokens = 7789
[2025-09-19 23:19:42,795][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:44,096][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:44,099][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:44,102][root][INFO] - LLM usage: prompt_tokens = 24797, completion_tokens = 7889
[2025-09-19 23:19:44,103][root][INFO] - Iteration 0: Running Code 6704229390303956595
[2025-09-19 23:19:44,617][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:44,656][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:19:44,656][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:46,238][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:46,241][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:46,243][root][INFO] - LLM usage: prompt_tokens = 25254, completion_tokens = 8154
[2025-09-19 23:19:46,244][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:47,407][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:47,410][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:47,414][root][INFO] - LLM usage: prompt_tokens = 25711, completion_tokens = 8249
[2025-09-19 23:19:47,415][root][INFO] - Iteration 0: Running Code -2458185449407266231
[2025-09-19 23:19:47,934][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:47,972][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:19:47,973][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:49,543][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:49,548][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:49,554][root][INFO] - LLM usage: prompt_tokens = 26168, completion_tokens = 8499
[2025-09-19 23:19:49,556][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:50,755][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:50,759][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:50,765][root][INFO] - LLM usage: prompt_tokens = 26610, completion_tokens = 8596
[2025-09-19 23:19:50,767][root][INFO] - Iteration 0: Running Code -5332781707312584768
[2025-09-19 23:19:51,282][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:51,318][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:19:51,319][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:52,876][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:52,880][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:52,886][root][INFO] - LLM usage: prompt_tokens = 27048, completion_tokens = 8807
[2025-09-19 23:19:52,888][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:53,836][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:53,840][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:53,845][root][INFO] - LLM usage: prompt_tokens = 27451, completion_tokens = 8892
[2025-09-19 23:19:53,848][root][INFO] - Iteration 0: Running Code 3073089796581887125
[2025-09-19 23:19:54,349][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:55,106][root][INFO] - Iteration 0, response_id 0: Objective value: 7.33660476062888
[2025-09-19 23:19:55,110][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:56,544][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:56,545][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:56,547][root][INFO] - LLM usage: prompt_tokens = 28194, completion_tokens = 9137
[2025-09-19 23:19:56,547][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:19:57,685][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:19:57,690][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:19:57,695][root][INFO] - LLM usage: prompt_tokens = 28626, completion_tokens = 9239
[2025-09-19 23:19:57,697][root][INFO] - Iteration 0: Running Code -5518214026404757344
[2025-09-19 23:19:58,198][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:19:59,419][root][INFO] - Iteration 0, response_id 0: Objective value: 6.951731762371727
[2025-09-19 23:19:59,419][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:01,900][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:01,901][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:01,904][root][INFO] - LLM usage: prompt_tokens = 29134, completion_tokens = 9613
[2025-09-19 23:20:01,904][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:03,329][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:03,331][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:03,333][root][INFO] - LLM usage: prompt_tokens = 29700, completion_tokens = 9709
[2025-09-19 23:20:03,335][root][INFO] - Iteration 0: Running Code -2428784207425455580
[2025-09-19 23:20:03,827][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:27,372][root][INFO] - Iteration 0, response_id 0: Objective value: 6.815755236426682
[2025-09-19 23:20:27,372][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:28,745][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:28,746][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:28,747][root][INFO] - LLM usage: prompt_tokens = 30189, completion_tokens = 9946
[2025-09-19 23:20:28,748][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:29,723][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:29,724][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:29,726][root][INFO] - LLM usage: prompt_tokens = 30618, completion_tokens = 10021
[2025-09-19 23:20:29,726][root][INFO] - Iteration 0: Running Code 8641036432815256853
[2025-09-19 23:20:30,222][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:31,437][root][INFO] - Iteration 0, response_id 0: Objective value: 7.004208136026807
[2025-09-19 23:20:31,440][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:32,946][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:32,948][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:32,950][root][INFO] - LLM usage: prompt_tokens = 31422, completion_tokens = 10301
[2025-09-19 23:20:32,950][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:33,905][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:33,909][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:33,915][root][INFO] - LLM usage: prompt_tokens = 31894, completion_tokens = 10385
[2025-09-19 23:20:33,917][root][INFO] - Iteration 0: Running Code 4158257237983925294
[2025-09-19 23:20:34,404][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:35,671][root][INFO] - Iteration 0, response_id 0: Objective value: 6.612061666709245
[2025-09-19 23:20:35,673][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:37,495][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:37,497][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:37,500][root][INFO] - LLM usage: prompt_tokens = 32902, completion_tokens = 10731
[2025-09-19 23:20:37,500][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:38,726][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:38,731][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:38,737][root][INFO] - LLM usage: prompt_tokens = 33440, completion_tokens = 10848
[2025-09-19 23:20:38,739][root][INFO] - Iteration 0: Running Code 8394970453608877274
[2025-09-19 23:20:39,243][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:40,503][root][INFO] - Iteration 0, response_id 0: Objective value: 6.643530465948105
[2025-09-19 23:20:40,504][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:42,929][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:42,930][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:42,932][root][INFO] - LLM usage: prompt_tokens = 33964, completion_tokens = 11176
[2025-09-19 23:20:42,932][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:44,364][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:44,369][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:44,374][root][INFO] - LLM usage: prompt_tokens = 34484, completion_tokens = 11286
[2025-09-19 23:20:44,377][root][INFO] - Iteration 0: Running Code -4112612981163280702
[2025-09-19 23:20:44,880][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:44,918][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:20:44,918][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:47,583][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:47,584][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:47,586][root][INFO] - LLM usage: prompt_tokens = 35008, completion_tokens = 11639
[2025-09-19 23:20:47,586][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:48,577][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:48,582][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:48,587][root][INFO] - LLM usage: prompt_tokens = 35553, completion_tokens = 11723
[2025-09-19 23:20:48,589][root][INFO] - Iteration 0: Running Code 8836770736415447327
[2025-09-19 23:20:49,120][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:50,453][root][INFO] - Iteration 0, response_id 0: Objective value: 6.607022711544704
[2025-09-19 23:20:50,453][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:56,856][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:56,860][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:56,862][root][INFO] - LLM usage: prompt_tokens = 36058, completion_tokens = 12016
[2025-09-19 23:20:56,863][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:20:57,939][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:20:57,941][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:20:57,942][root][INFO] - LLM usage: prompt_tokens = 36538, completion_tokens = 12108
[2025-09-19 23:20:57,943][root][INFO] - Iteration 0: Running Code -4105361658113327148
[2025-09-19 23:20:58,443][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:20:59,691][root][INFO] - Iteration 0, response_id 0: Objective value: 23.275454796472264
[2025-09-19 23:20:59,693][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:01,206][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:01,210][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:01,218][root][INFO] - LLM usage: prompt_tokens = 37672, completion_tokens = 12382
[2025-09-19 23:21:01,219][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:02,319][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:02,323][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:02,328][root][INFO] - LLM usage: prompt_tokens = 38138, completion_tokens = 12470
[2025-09-19 23:21:02,331][root][INFO] - Iteration 0: Running Code -8568677766089660127
[2025-09-19 23:21:02,869][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:04,114][root][INFO] - Iteration 0, response_id 0: Objective value: 6.612061666709245
[2025-09-19 23:21:04,116][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:05,644][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:05,650][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:05,657][root][INFO] - LLM usage: prompt_tokens = 38958, completion_tokens = 12730
[2025-09-19 23:21:05,658][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:07,026][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:07,029][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:07,033][root][INFO] - LLM usage: prompt_tokens = 39410, completion_tokens = 12829
[2025-09-19 23:21:07,034][root][INFO] - Iteration 0: Running Code 6891234980200714766
[2025-09-19 23:21:07,570][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:08,782][root][INFO] - Iteration 0, response_id 0: Objective value: 6.976547165763392
[2025-09-19 23:21:08,782][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:10,617][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:10,620][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:10,624][root][INFO] - LLM usage: prompt_tokens = 39858, completion_tokens = 13063
[2025-09-19 23:21:10,626][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:11,771][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:11,775][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:11,779][root][INFO] - LLM usage: prompt_tokens = 40284, completion_tokens = 13143
[2025-09-19 23:21:11,782][root][INFO] - Iteration 0: Running Code 4735330625350621974
[2025-09-19 23:21:12,291][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:12,328][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:21:12,329][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:14,253][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:14,256][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:14,261][root][INFO] - LLM usage: prompt_tokens = 40732, completion_tokens = 13428
[2025-09-19 23:21:14,263][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:15,476][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:15,480][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:15,486][root][INFO] - LLM usage: prompt_tokens = 41209, completion_tokens = 13542
[2025-09-19 23:21:15,488][root][INFO] - Iteration 0: Running Code 4168281809398865800
[2025-09-19 23:21:15,989][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:17,327][root][INFO] - Iteration 0, response_id 0: Objective value: 8.625744332535195
[2025-09-19 23:21:17,328][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:18,587][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:18,588][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:18,590][root][INFO] - LLM usage: prompt_tokens = 41638, completion_tokens = 13743
[2025-09-19 23:21:18,590][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:19,672][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:19,674][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:19,676][root][INFO] - LLM usage: prompt_tokens = 42031, completion_tokens = 13852
[2025-09-19 23:21:19,676][root][INFO] - Iteration 0: Running Code 6576729908646124550
[2025-09-19 23:21:20,158][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:20,893][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9869957971920496
[2025-09-19 23:21:20,898][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:22,287][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:22,289][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:22,291][root][INFO] - LLM usage: prompt_tokens = 43402, completion_tokens = 13992
[2025-09-19 23:21:22,292][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:26,796][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:26,800][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:26,805][root][INFO] - LLM usage: prompt_tokens = 43734, completion_tokens = 14073
[2025-09-19 23:21:26,807][root][INFO] - Iteration 0: Running Code -1056765948916245794
[2025-09-19 23:21:27,319][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:27,860][root][INFO] - Iteration 0, response_id 0: Objective value: 36.645936399521986
[2025-09-19 23:21:27,861][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:29,353][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:29,357][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:29,359][root][INFO] - LLM usage: prompt_tokens = 44585, completion_tokens = 14354
[2025-09-19 23:21:29,359][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:30,607][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:30,611][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:30,617][root][INFO] - LLM usage: prompt_tokens = 45058, completion_tokens = 14476
[2025-09-19 23:21:30,619][root][INFO] - Iteration 0: Running Code -8768535644487656905
[2025-09-19 23:21:31,125][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:32,935][root][INFO] - Iteration 0, response_id 0: Objective value: 8.375068008434738
[2025-09-19 23:21:32,936][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:35,193][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:35,196][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:35,198][root][INFO] - LLM usage: prompt_tokens = 45532, completion_tokens = 14742
[2025-09-19 23:21:35,198][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:36,266][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:36,270][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:36,275][root][INFO] - LLM usage: prompt_tokens = 45990, completion_tokens = 14836
[2025-09-19 23:21:36,278][root][INFO] - Iteration 0: Running Code 3944123526378005693
[2025-09-19 23:21:36,778][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:36,815][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:21:36,815][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:38,659][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:38,662][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:38,664][root][INFO] - LLM usage: prompt_tokens = 46464, completion_tokens = 15164
[2025-09-19 23:21:38,665][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:39,840][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:39,845][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:39,850][root][INFO] - LLM usage: prompt_tokens = 46979, completion_tokens = 15269
[2025-09-19 23:21:39,853][root][INFO] - Iteration 0: Running Code 1513445600596726606
[2025-09-19 23:21:40,348][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:41,109][root][INFO] - Iteration 0, response_id 0: Objective value: 21.788537591685618
[2025-09-19 23:21:41,110][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:42,316][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:42,319][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:42,321][root][INFO] - LLM usage: prompt_tokens = 47434, completion_tokens = 15455
[2025-09-19 23:21:42,321][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:43,316][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:43,320][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:43,325][root][INFO] - LLM usage: prompt_tokens = 47812, completion_tokens = 15532
[2025-09-19 23:21:43,328][root][INFO] - Iteration 0: Running Code 8225264722705561349
[2025-09-19 23:21:43,829][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:44,557][root][INFO] - Iteration 0, response_id 0: Objective value: 8.545816361959812
[2025-09-19 23:21:44,562][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:46,149][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:46,153][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:46,160][root][INFO] - LLM usage: prompt_tokens = 48702, completion_tokens = 15772
[2025-09-19 23:21:46,162][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:47,326][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:47,328][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:47,330][root][INFO] - LLM usage: prompt_tokens = 49134, completion_tokens = 15892
[2025-09-19 23:21:47,331][root][INFO] - Iteration 0: Running Code -837602969346267288
[2025-09-19 23:21:47,855][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:49,061][root][INFO] - Iteration 0, response_id 0: Objective value: 6.976851498402754
[2025-09-19 23:21:49,062][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:51,018][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:51,020][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:51,022][root][INFO] - LLM usage: prompt_tokens = 49652, completion_tokens = 16229
[2025-09-19 23:21:51,023][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:52,141][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:52,143][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:52,145][root][INFO] - LLM usage: prompt_tokens = 50181, completion_tokens = 16322
[2025-09-19 23:21:52,147][root][INFO] - Iteration 0: Running Code 3552020512999905788
[2025-09-19 23:21:52,709][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:52,751][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:21:52,752][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:55,132][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:55,135][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:55,137][root][INFO] - LLM usage: prompt_tokens = 50699, completion_tokens = 16643
[2025-09-19 23:21:55,138][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:56,250][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:56,251][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:21:56,253][root][INFO] - LLM usage: prompt_tokens = 51212, completion_tokens = 16724
[2025-09-19 23:21:56,254][root][INFO] - Iteration 0: Running Code 3841215946877663484
[2025-09-19 23:21:56,736][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:21:58,414][root][INFO] - Iteration 0, response_id 0: Objective value: 6.452120749742063
[2025-09-19 23:21:58,415][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:21:59,993][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:21:59,996][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:00,001][root][INFO] - LLM usage: prompt_tokens = 51711, completion_tokens = 16989
[2025-09-19 23:22:00,002][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:01,028][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:01,031][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:01,035][root][INFO] - LLM usage: prompt_tokens = 52163, completion_tokens = 17064
[2025-09-19 23:22:01,036][root][INFO] - Iteration 0: Running Code 2385111537389253755
[2025-09-19 23:22:01,530][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:02,762][root][INFO] - Iteration 0, response_id 0: Objective value: 6.61070553990568
[2025-09-19 23:22:02,765][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:04,535][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:04,540][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:04,547][root][INFO] - LLM usage: prompt_tokens = 52968, completion_tokens = 17355
[2025-09-19 23:22:04,549][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:06,161][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:06,163][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:06,165][root][INFO] - LLM usage: prompt_tokens = 53451, completion_tokens = 17479
[2025-09-19 23:22:06,165][root][INFO] - Iteration 0: Running Code -454753521390439386
[2025-09-19 23:22:06,759][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:08,599][root][INFO] - Iteration 0, response_id 0: Objective value: 7.547631231773624
[2025-09-19 23:22:08,602][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:10,083][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:10,084][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:10,086][root][INFO] - LLM usage: prompt_tokens = 54270, completion_tokens = 17733
[2025-09-19 23:22:10,087][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:11,454][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:11,458][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:11,464][root][INFO] - LLM usage: prompt_tokens = 54716, completion_tokens = 17834
[2025-09-19 23:22:11,466][root][INFO] - Iteration 0: Running Code 2532198989905795070
[2025-09-19 23:22:11,972][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:13,227][root][INFO] - Iteration 0, response_id 0: Objective value: 6.998664499577924
[2025-09-19 23:22:13,228][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:14,903][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:14,907][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:14,913][root][INFO] - LLM usage: prompt_tokens = 55199, completion_tokens = 18091
[2025-09-19 23:22:14,915][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:16,099][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:16,101][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:16,103][root][INFO] - LLM usage: prompt_tokens = 55648, completion_tokens = 18203
[2025-09-19 23:22:16,103][root][INFO] - Iteration 0: Running Code -2731947103084039104
[2025-09-19 23:22:16,592][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:17,339][root][INFO] - Iteration 0, response_id 0: Objective value: 8.414032721473978
[2025-09-19 23:22:17,340][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:18,693][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:18,697][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:18,699][root][INFO] - LLM usage: prompt_tokens = 56112, completion_tokens = 18423
[2025-09-19 23:22:18,700][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:19,937][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:19,941][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:19,947][root][INFO] - LLM usage: prompt_tokens = 56524, completion_tokens = 18509
[2025-09-19 23:22:19,950][root][INFO] - Iteration 0: Running Code -1206902067035246427
[2025-09-19 23:22:20,461][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:21,225][root][INFO] - Iteration 0, response_id 0: Objective value: 7.713119058241831
[2025-09-19 23:22:21,228][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:22,867][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:22,871][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:22,878][root][INFO] - LLM usage: prompt_tokens = 57293, completion_tokens = 18747
[2025-09-19 23:22:22,880][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:24,055][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:24,059][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:24,065][root][INFO] - LLM usage: prompt_tokens = 57723, completion_tokens = 18840
[2025-09-19 23:22:24,067][root][INFO] - Iteration 0: Running Code -62945826406498404
[2025-09-19 23:22:24,576][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:25,915][root][INFO] - Iteration 0, response_id 0: Objective value: 8.524090267139584
[2025-09-19 23:22:25,917][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:27,661][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:27,664][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:27,665][root][INFO] - LLM usage: prompt_tokens = 58899, completion_tokens = 19078
[2025-09-19 23:22:27,666][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:28,858][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:28,861][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:28,864][root][INFO] - LLM usage: prompt_tokens = 59329, completion_tokens = 19171
[2025-09-19 23:22:28,866][root][INFO] - Iteration 0: Running Code -1734548742923671756
[2025-09-19 23:22:29,366][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:30,072][root][INFO] - Iteration 0, response_id 0: Objective value: 7.743167378350634
[2025-09-19 23:22:30,073][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:32,121][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:32,125][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:32,133][root][INFO] - LLM usage: prompt_tokens = 60228, completion_tokens = 19512
[2025-09-19 23:22:32,134][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:33,525][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:33,528][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:33,531][root][INFO] - LLM usage: prompt_tokens = 60761, completion_tokens = 19629
[2025-09-19 23:22:33,532][root][INFO] - Iteration 0: Running Code 363999756830422236
[2025-09-19 23:22:34,038][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:35,837][root][INFO] - Iteration 0, response_id 0: Objective value: 6.667595294907628
[2025-09-19 23:22:35,838][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:38,512][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:38,516][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:38,523][root][INFO] - LLM usage: prompt_tokens = 61323, completion_tokens = 20084
[2025-09-19 23:22:38,525][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:39,721][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:39,725][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:39,731][root][INFO] - LLM usage: prompt_tokens = 61970, completion_tokens = 20196
[2025-09-19 23:22:39,734][root][INFO] - Iteration 0: Running Code 7838775973034246200
[2025-09-19 23:22:40,241][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:40,279][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:22:40,280][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:42,598][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:42,600][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:42,602][root][INFO] - LLM usage: prompt_tokens = 62532, completion_tokens = 20622
[2025-09-19 23:22:42,602][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:43,957][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:43,961][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:43,967][root][INFO] - LLM usage: prompt_tokens = 63145, completion_tokens = 20711
[2025-09-19 23:22:43,970][root][INFO] - Iteration 0: Running Code 5077323400135889703
[2025-09-19 23:22:44,468][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:46,362][root][INFO] - Iteration 0, response_id 0: Objective value: 25.03702484021195
[2025-09-19 23:22:46,363][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:48,149][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:48,150][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:48,152][root][INFO] - LLM usage: prompt_tokens = 63688, completion_tokens = 20987
[2025-09-19 23:22:48,153][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:49,369][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:49,373][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:49,379][root][INFO] - LLM usage: prompt_tokens = 64156, completion_tokens = 21080
[2025-09-19 23:22:49,382][root][INFO] - Iteration 0: Running Code 4930777685846789718
[2025-09-19 23:22:49,875][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:51,220][root][INFO] - Iteration 0, response_id 0: Objective value: 8.044691529891947
[2025-09-19 23:22:51,223][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:52,917][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:52,921][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:52,929][root][INFO] - LLM usage: prompt_tokens = 65005, completion_tokens = 21358
[2025-09-19 23:22:52,930][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:54,135][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:54,139][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:54,145][root][INFO] - LLM usage: prompt_tokens = 65475, completion_tokens = 21478
[2025-09-19 23:22:54,147][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:55,717][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:55,721][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:55,728][root][INFO] - LLM usage: prompt_tokens = 66324, completion_tokens = 21765
[2025-09-19 23:22:55,729][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:22:56,901][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:22:56,905][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:22:56,911][root][INFO] - LLM usage: prompt_tokens = 66803, completion_tokens = 21860
[2025-09-19 23:22:56,913][root][INFO] - Iteration 0: Running Code -8398087856292541234
[2025-09-19 23:22:57,436][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:22:58,902][root][INFO] - Iteration 0, response_id 0: Objective value: 7.66539694416263
[2025-09-19 23:22:58,904][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:00,578][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:00,582][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:00,589][root][INFO] - LLM usage: prompt_tokens = 67671, completion_tokens = 22139
[2025-09-19 23:23:00,591][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:01,666][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:01,668][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:01,670][root][INFO] - LLM usage: prompt_tokens = 68142, completion_tokens = 22224
[2025-09-19 23:23:01,670][root][INFO] - Iteration 0: Running Code 5222416411457714515
[2025-09-19 23:23:02,189][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:03,389][root][INFO] - Iteration 0, response_id 0: Objective value: 24.29765077907938
[2025-09-19 23:23:03,389][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:05,556][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:05,560][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:05,566][root][INFO] - LLM usage: prompt_tokens = 68643, completion_tokens = 22591
[2025-09-19 23:23:05,568][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:06,687][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:06,691][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:06,697][root][INFO] - LLM usage: prompt_tokens = 69202, completion_tokens = 22695
[2025-09-19 23:23:06,700][root][INFO] - Iteration 0: Running Code -3554142630600901178
[2025-09-19 23:23:07,192][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:08,625][root][INFO] - Iteration 0, response_id 0: Objective value: 7.65468806442275
[2025-09-19 23:23:08,626][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:10,376][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:10,380][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:10,386][root][INFO] - LLM usage: prompt_tokens = 69684, completion_tokens = 22932
[2025-09-19 23:23:10,388][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:11,612][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:11,617][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:11,622][root][INFO] - LLM usage: prompt_tokens = 70108, completion_tokens = 23048
[2025-09-19 23:23:11,625][root][INFO] - Iteration 0: Running Code -837826724004263272
[2025-09-19 23:23:12,130][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:12,855][root][INFO] - Iteration 0, response_id 0: Objective value: 10.841439334583786
[2025-09-19 23:23:12,860][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:14,996][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:15,000][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:15,008][root][INFO] - LLM usage: prompt_tokens = 71113, completion_tokens = 23521
[2025-09-19 23:23:15,010][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:16,048][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:16,051][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:16,056][root][INFO] - LLM usage: prompt_tokens = 71778, completion_tokens = 23626
[2025-09-19 23:23:16,059][root][INFO] - Iteration 0: Running Code 1820906255253133565
[2025-09-19 23:23:16,568][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:18,502][root][INFO] - Iteration 0, response_id 0: Objective value: 7.553392628631524
[2025-09-19 23:23:18,502][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:20,941][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:20,945][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:20,953][root][INFO] - LLM usage: prompt_tokens = 72416, completion_tokens = 24106
[2025-09-19 23:23:20,955][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:22,067][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:22,069][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:22,071][root][INFO] - LLM usage: prompt_tokens = 73083, completion_tokens = 24187
[2025-09-19 23:23:22,072][root][INFO] - Iteration 0: Running Code 7544586302895676796
[2025-09-19 23:23:22,577][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:25,218][root][INFO] - Iteration 0, response_id 0: Objective value: 7.009132420389942
[2025-09-19 23:23:25,218][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:27,537][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:27,541][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:27,548][root][INFO] - LLM usage: prompt_tokens = 73702, completion_tokens = 24600
[2025-09-19 23:23:27,549][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:29,199][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:29,203][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:29,210][root][INFO] - LLM usage: prompt_tokens = 74307, completion_tokens = 24687
[2025-09-19 23:23:29,213][root][INFO] - Iteration 0: Running Code -4097967404487436130
[2025-09-19 23:23:29,728][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:31,278][root][INFO] - Iteration 0, response_id 0: Objective value: 8.29727377389754
[2025-09-19 23:23:31,283][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:34,757][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:34,762][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:34,763][root][INFO] - LLM usage: prompt_tokens = 75285, completion_tokens = 25144
[2025-09-19 23:23:34,764][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:35,944][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:35,945][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:35,947][root][INFO] - LLM usage: prompt_tokens = 75934, completion_tokens = 25256
[2025-09-19 23:23:35,947][root][INFO] - Iteration 0: Running Code 6149843803726986890
[2025-09-19 23:23:36,433][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:38,467][root][INFO] - Iteration 0, response_id 0: Objective value: 7.293546414590314
[2025-09-19 23:23:38,471][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:40,392][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:40,397][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:40,405][root][INFO] - LLM usage: prompt_tokens = 77176, completion_tokens = 25528
[2025-09-19 23:23:40,407][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:41,907][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:41,912][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:41,917][root][INFO] - LLM usage: prompt_tokens = 77635, completion_tokens = 25639
[2025-09-19 23:23:41,920][root][INFO] - Iteration 0: Running Code 1300612810129513823
[2025-09-19 23:23:42,418][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:42,471][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:23:42,472][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:44,883][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:44,887][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:44,896][root][INFO] - LLM usage: prompt_tokens = 78715, completion_tokens = 26003
[2025-09-19 23:23:44,898][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:46,042][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:46,046][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:46,052][root][INFO] - LLM usage: prompt_tokens = 79266, completion_tokens = 26103
[2025-09-19 23:23:46,054][root][INFO] - Iteration 0: Running Code 8179297883988209086
[2025-09-19 23:23:46,538][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:47,280][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9869957971920496
[2025-09-19 23:23:47,281][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:48,806][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:48,810][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:48,817][root][INFO] - LLM usage: prompt_tokens = 80207, completion_tokens = 26355
[2025-09-19 23:23:48,819][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:49,964][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:49,969][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:49,973][root][INFO] - LLM usage: prompt_tokens = 80651, completion_tokens = 26441
[2025-09-19 23:23:49,977][root][INFO] - Iteration 0: Running Code 5563157239174723676
[2025-09-19 23:23:50,485][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:51,249][root][INFO] - Iteration 0, response_id 0: Objective value: 7.227035612744023
[2025-09-19 23:23:51,250][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:52,695][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:52,699][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:52,701][root][INFO] - LLM usage: prompt_tokens = 81460, completion_tokens = 26696
[2025-09-19 23:23:52,701][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:53,732][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:53,736][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:53,742][root][INFO] - LLM usage: prompt_tokens = 81907, completion_tokens = 26781
[2025-09-19 23:23:53,744][root][INFO] - Iteration 0: Running Code 8094692979559504768
[2025-09-19 23:23:54,257][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:55,479][root][INFO] - Iteration 0, response_id 0: Objective value: 6.551400947540846
[2025-09-19 23:23:55,480][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:57,154][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:57,159][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:57,163][root][INFO] - LLM usage: prompt_tokens = 82371, completion_tokens = 27011
[2025-09-19 23:23:57,165][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:23:58,616][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:23:58,620][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:23:58,625][root][INFO] - LLM usage: prompt_tokens = 82793, completion_tokens = 27093
[2025-09-19 23:23:58,627][root][INFO] - Iteration 0: Running Code -6787429099280368228
[2025-09-19 23:23:59,128][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:23:59,165][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:23:59,166][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:00,770][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:00,774][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:00,780][root][INFO] - LLM usage: prompt_tokens = 83257, completion_tokens = 27324
[2025-09-19 23:24:00,782][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:01,992][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:01,995][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:01,999][root][INFO] - LLM usage: prompt_tokens = 83680, completion_tokens = 27408
[2025-09-19 23:24:02,000][root][INFO] - Iteration 0: Running Code -1331679727068330035
[2025-09-19 23:24:02,502][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:03,286][root][INFO] - Iteration 0, response_id 0: Objective value: 9.325844570181482
[2025-09-19 23:24:03,287][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:04,540][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:04,544][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:04,545][root][INFO] - LLM usage: prompt_tokens = 84125, completion_tokens = 27615
[2025-09-19 23:24:04,547][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:05,918][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:05,920][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:05,921][root][INFO] - LLM usage: prompt_tokens = 84524, completion_tokens = 27710
[2025-09-19 23:24:05,922][root][INFO] - Iteration 0: Running Code -6600042647102611097
[2025-09-19 23:24:06,446][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:07,218][root][INFO] - Iteration 0, response_id 0: Objective value: 23.928571831861447
[2025-09-19 23:24:07,223][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:09,079][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:09,083][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:09,090][root][INFO] - LLM usage: prompt_tokens = 85284, completion_tokens = 28001
[2025-09-19 23:24:09,092][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:10,133][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:10,138][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:10,139][root][INFO] - LLM usage: prompt_tokens = 85767, completion_tokens = 28085
[2025-09-19 23:24:10,140][root][INFO] - Iteration 0: Running Code 1362690322488584211
[2025-09-19 23:24:10,622][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:11,367][root][INFO] - Iteration 0, response_id 0: Objective value: 7.401484463550982
[2025-09-19 23:24:11,368][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:13,183][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:13,184][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:13,186][root][INFO] - LLM usage: prompt_tokens = 86753, completion_tokens = 28484
[2025-09-19 23:24:13,187][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:14,367][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:14,369][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:14,370][root][INFO] - LLM usage: prompt_tokens = 87344, completion_tokens = 28587
[2025-09-19 23:24:14,371][root][INFO] - Iteration 0: Running Code 4717225514787363248
[2025-09-19 23:24:14,863][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:16,055][root][INFO] - Iteration 0, response_id 0: Objective value: 7.61983299043445
[2025-09-19 23:24:16,056][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:18,429][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:18,433][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:18,441][root][INFO] - LLM usage: prompt_tokens = 87971, completion_tokens = 29055
[2025-09-19 23:24:18,443][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:19,679][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:19,683][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:19,688][root][INFO] - LLM usage: prompt_tokens = 88265, completion_tokens = 29160
[2025-09-19 23:24:19,690][root][INFO] - Iteration 0: Running Code 6490094660803338246
[2025-09-19 23:24:20,191][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:24:20,227][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:24:20,227][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:22,301][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:22,302][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:22,305][root][INFO] - LLM usage: prompt_tokens = 88892, completion_tokens = 29570
[2025-09-19 23:24:22,306][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:23,407][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:23,410][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:23,412][root][INFO] - LLM usage: prompt_tokens = 89494, completion_tokens = 29663
[2025-09-19 23:24:23,413][root][INFO] - Iteration 0: Running Code -7800939928921404890
[2025-09-19 23:24:23,901][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:25,297][root][INFO] - Iteration 0, response_id 0: Objective value: 8.268363909447055
[2025-09-19 23:24:25,298][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:27,125][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:27,129][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:27,136][root][INFO] - LLM usage: prompt_tokens = 90102, completion_tokens = 30039
[2025-09-19 23:24:27,138][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:28,420][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:28,425][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:28,431][root][INFO] - LLM usage: prompt_tokens = 90670, completion_tokens = 30118
[2025-09-19 23:24:28,433][root][INFO] - Iteration 0: Running Code -8046635257047262141
[2025-09-19 23:24:28,937][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:29,668][root][INFO] - Iteration 0, response_id 0: Objective value: 7.526042649699715
[2025-09-19 23:24:29,672][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:32,250][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:32,255][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:32,262][root][INFO] - LLM usage: prompt_tokens = 91636, completion_tokens = 30540
[2025-09-19 23:24:32,265][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:33,434][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:33,438][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:33,444][root][INFO] - LLM usage: prompt_tokens = 92250, completion_tokens = 30633
[2025-09-19 23:24:33,446][root][INFO] - Iteration 0: Running Code -3575832508623332656
[2025-09-19 23:24:33,953][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:35,148][root][INFO] - Iteration 0, response_id 0: Objective value: 7.61983299043445
[2025-09-19 23:24:35,148][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:37,559][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:37,560][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:37,561][root][INFO] - LLM usage: prompt_tokens = 92856, completion_tokens = 31063
[2025-09-19 23:24:37,562][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:38,921][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:38,925][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:38,931][root][INFO] - LLM usage: prompt_tokens = 93478, completion_tokens = 31183
[2025-09-19 23:24:38,934][root][INFO] - Iteration 0: Running Code -4005337294136716498
[2025-09-19 23:24:39,443][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:39,482][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:24:39,482][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:42,340][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:42,344][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:42,351][root][INFO] - LLM usage: prompt_tokens = 94084, completion_tokens = 31639
[2025-09-19 23:24:42,353][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:43,611][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:43,616][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:43,622][root][INFO] - LLM usage: prompt_tokens = 94732, completion_tokens = 31752
[2025-09-19 23:24:43,624][root][INFO] - Iteration 0: Running Code 7282003946366310147
[2025-09-19 23:24:44,124][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:44,209][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:24:44,209][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:46,874][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:46,878][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:46,885][root][INFO] - LLM usage: prompt_tokens = 95338, completion_tokens = 32292
[2025-09-19 23:24:46,887][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:48,197][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:48,198][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:48,200][root][INFO] - LLM usage: prompt_tokens = 96070, completion_tokens = 32389
[2025-09-19 23:24:48,201][root][INFO] - Iteration 0: Running Code 3477450301744282637
[2025-09-19 23:24:48,688][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:50,082][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9225993245964
[2025-09-19 23:24:50,083][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:52,099][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:52,103][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:52,110][root][INFO] - LLM usage: prompt_tokens = 96657, completion_tokens = 32759
[2025-09-19 23:24:52,111][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:53,080][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:53,084][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:53,090][root][INFO] - LLM usage: prompt_tokens = 97214, completion_tokens = 32826
[2025-09-19 23:24:53,093][root][INFO] - Iteration 0: Running Code 9030287176438717183
[2025-09-19 23:24:53,580][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:54,297][root][INFO] - Iteration 0, response_id 0: Objective value: 9.811201204047158
[2025-09-19 23:24:54,303][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:56,353][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:56,354][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:56,356][root][INFO] - LLM usage: prompt_tokens = 98285, completion_tokens = 33200
[2025-09-19 23:24:56,357][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:24:57,494][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:24:57,496][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:24:57,497][root][INFO] - LLM usage: prompt_tokens = 98851, completion_tokens = 33281
[2025-09-19 23:24:57,498][root][INFO] - Iteration 0: Running Code 4448187120409362470
[2025-09-19 23:24:57,994][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:24:58,726][root][INFO] - Iteration 0, response_id 0: Objective value: 7.122423392482045
[2025-09-19 23:24:58,728][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:00,545][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:00,549][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:00,552][root][INFO] - LLM usage: prompt_tokens = 100394, completion_tokens = 33604
[2025-09-19 23:25:00,552][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:01,628][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:01,632][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:01,638][root][INFO] - LLM usage: prompt_tokens = 100909, completion_tokens = 33679
[2025-09-19 23:25:01,640][root][INFO] - Iteration 0: Running Code 4531850756774684028
[2025-09-19 23:25:02,129][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:03,372][root][INFO] - Iteration 0, response_id 0: Objective value: 19.838606690798983
[2025-09-19 23:25:03,372][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:04,875][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:04,879][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:04,880][root][INFO] - LLM usage: prompt_tokens = 101645, completion_tokens = 33880
[2025-09-19 23:25:04,881][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:05,981][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:05,985][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:05,991][root][INFO] - LLM usage: prompt_tokens = 102038, completion_tokens = 33989
[2025-09-19 23:25:05,993][root][INFO] - Iteration 0: Running Code 4604749007077067271
[2025-09-19 23:25:06,498][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:07,245][root][INFO] - Iteration 0, response_id 0: Objective value: 6.5657110998186745
[2025-09-19 23:25:07,246][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:08,809][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:08,810][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:08,812][root][INFO] - LLM usage: prompt_tokens = 102952, completion_tokens = 34260
[2025-09-19 23:25:08,813][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:09,963][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:09,964][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:09,965][root][INFO] - LLM usage: prompt_tokens = 103415, completion_tokens = 34369
[2025-09-19 23:25:09,966][root][INFO] - Iteration 0: Running Code 8283714164027701656
[2025-09-19 23:25:10,478][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:11,711][root][INFO] - Iteration 0, response_id 0: Objective value: 6.58704584838065
[2025-09-19 23:25:11,711][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:14,267][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:14,271][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:14,278][root][INFO] - LLM usage: prompt_tokens = 103902, completion_tokens = 34663
[2025-09-19 23:25:14,280][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:15,727][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:15,732][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:15,738][root][INFO] - LLM usage: prompt_tokens = 104388, completion_tokens = 34761
[2025-09-19 23:25:15,740][root][INFO] - Iteration 0: Running Code -2347660430767329284
[2025-09-19 23:25:16,235][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:16,271][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:25:16,272][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:18,079][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:18,081][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:18,082][root][INFO] - LLM usage: prompt_tokens = 104875, completion_tokens = 35042
[2025-09-19 23:25:18,083][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:20,814][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:20,818][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:20,824][root][INFO] - LLM usage: prompt_tokens = 105348, completion_tokens = 35150
[2025-09-19 23:25:20,826][root][INFO] - Iteration 0: Running Code -5980805708499662103
[2025-09-19 23:25:21,323][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:22,685][root][INFO] - Iteration 0, response_id 0: Objective value: 7.088569265914105
[2025-09-19 23:25:22,686][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:24,087][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:24,091][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:24,097][root][INFO] - LLM usage: prompt_tokens = 105816, completion_tokens = 35366
[2025-09-19 23:25:24,099][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:25,211][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:25,215][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:25,221][root][INFO] - LLM usage: prompt_tokens = 106224, completion_tokens = 35454
[2025-09-19 23:25:25,223][root][INFO] - Iteration 0: Running Code -815866677944042583
[2025-09-19 23:25:25,722][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:26,419][root][INFO] - Iteration 0, response_id 0: Objective value: 7.74605758490636
[2025-09-19 23:25:26,424][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:27,899][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:27,901][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:27,903][root][INFO] - LLM usage: prompt_tokens = 106926, completion_tokens = 35699
[2025-09-19 23:25:27,904][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:29,021][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:29,025][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:29,031][root][INFO] - LLM usage: prompt_tokens = 107363, completion_tokens = 35814
[2025-09-19 23:25:29,032][root][INFO] - Iteration 0: Running Code -543037147807764764
[2025-09-19 23:25:29,523][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:30,222][root][INFO] - Iteration 0, response_id 0: Objective value: 7.064895055288651
[2025-09-19 23:25:30,224][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:32,221][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:32,223][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:32,225][root][INFO] - LLM usage: prompt_tokens = 108454, completion_tokens = 36181
[2025-09-19 23:25:32,226][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:33,563][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:33,567][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:33,573][root][INFO] - LLM usage: prompt_tokens = 109023, completion_tokens = 36274
[2025-09-19 23:25:33,576][root][INFO] - Iteration 0: Running Code -8637438161916728505
[2025-09-19 23:25:34,076][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:25:34,113][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:25:34,114][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:36,378][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:36,383][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:36,387][root][INFO] - LLM usage: prompt_tokens = 110114, completion_tokens = 36644
[2025-09-19 23:25:36,387][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:38,334][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:38,336][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:38,339][root][INFO] - LLM usage: prompt_tokens = 110686, completion_tokens = 36777
[2025-09-19 23:25:38,340][root][INFO] - Iteration 0: Running Code 7125719307923535606
[2025-09-19 23:25:38,841][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:25:38,878][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:25:38,878][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:41,089][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:41,093][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:41,094][root][INFO] - LLM usage: prompt_tokens = 111826, completion_tokens = 37144
[2025-09-19 23:25:41,095][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:42,206][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:42,209][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:42,211][root][INFO] - LLM usage: prompt_tokens = 112385, completion_tokens = 37231
[2025-09-19 23:25:42,211][root][INFO] - Iteration 0: Running Code -1856802293382867901
[2025-09-19 23:25:42,728][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:43,898][root][INFO] - Iteration 0, response_id 0: Objective value: 7.712447122650615
[2025-09-19 23:25:43,899][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:45,916][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:45,922][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:45,929][root][INFO] - LLM usage: prompt_tokens = 113116, completion_tokens = 37629
[2025-09-19 23:25:45,931][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:47,283][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:47,284][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:47,286][root][INFO] - LLM usage: prompt_tokens = 113706, completion_tokens = 37740
[2025-09-19 23:25:47,287][root][INFO] - Iteration 0: Running Code 5832366030220735072
[2025-09-19 23:25:47,800][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:47,837][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:25:47,838][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:50,474][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:50,479][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:50,487][root][INFO] - LLM usage: prompt_tokens = 114437, completion_tokens = 38309
[2025-09-19 23:25:50,489][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:51,672][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:51,676][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:51,682][root][INFO] - LLM usage: prompt_tokens = 115198, completion_tokens = 38389
[2025-09-19 23:25:51,685][root][INFO] - Iteration 0: Running Code -5987102881602263797
[2025-09-19 23:25:52,192][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:25:54,847][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0045837042454515
[2025-09-19 23:25:54,848][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:57,901][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:57,905][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:57,913][root][INFO] - LLM usage: prompt_tokens = 115910, completion_tokens = 38860
[2025-09-19 23:25:57,915][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:25:59,037][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:25:59,041][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:25:59,047][root][INFO] - LLM usage: prompt_tokens = 116599, completion_tokens = 38924
[2025-09-19 23:25:59,050][root][INFO] - Iteration 0: Running Code -1139364500969912316
[2025-09-19 23:25:59,547][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:25:59,585][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:25:59,585][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:01,527][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:01,528][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:01,530][root][INFO] - LLM usage: prompt_tokens = 117311, completion_tokens = 39352
[2025-09-19 23:26:01,531][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:02,473][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:02,474][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:02,476][root][INFO] - LLM usage: prompt_tokens = 117926, completion_tokens = 39438
[2025-09-19 23:26:02,477][root][INFO] - Iteration 0: Running Code 4957574862855680524
[2025-09-19 23:26:02,967][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:05,247][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:26:05,255][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:08,266][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:08,271][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:08,281][root][INFO] - LLM usage: prompt_tokens = 119441, completion_tokens = 39957
[2025-09-19 23:26:08,283][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:09,450][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:09,451][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:09,453][root][INFO] - LLM usage: prompt_tokens = 120152, completion_tokens = 40055
[2025-09-19 23:26:09,453][root][INFO] - Iteration 0: Running Code 1684252029411635469
[2025-09-19 23:26:09,958][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:12,629][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:26:12,630][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:14,246][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:14,249][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:14,257][root][INFO] - LLM usage: prompt_tokens = 121063, completion_tokens = 40329
[2025-09-19 23:26:14,258][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:15,376][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:15,377][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:15,379][root][INFO] - LLM usage: prompt_tokens = 121529, completion_tokens = 40423
[2025-09-19 23:26:15,380][root][INFO] - Iteration 0: Running Code -5509302174686116998
[2025-09-19 23:26:15,897][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:17,298][root][INFO] - Iteration 0, response_id 0: Objective value: 7.605394369788808
[2025-09-19 23:26:17,299][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:18,617][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:18,618][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:18,620][root][INFO] - LLM usage: prompt_tokens = 122450, completion_tokens = 40667
[2025-09-19 23:26:18,621][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:19,781][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:19,786][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:19,791][root][INFO] - LLM usage: prompt_tokens = 122886, completion_tokens = 40797
[2025-09-19 23:26:19,793][root][INFO] - Iteration 0: Running Code -2342302518632518760
[2025-09-19 23:26:20,308][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:21,078][root][INFO] - Iteration 0, response_id 0: Objective value: 7.069190691223298
[2025-09-19 23:26:21,079][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:22,832][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:22,836][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:22,843][root][INFO] - LLM usage: prompt_tokens = 123454, completion_tokens = 41134
[2025-09-19 23:26:22,844][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:24,317][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:24,321][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:24,327][root][INFO] - LLM usage: prompt_tokens = 123983, completion_tokens = 41243
[2025-09-19 23:26:24,329][root][INFO] - Iteration 0: Running Code 2689681731210276353
[2025-09-19 23:26:24,846][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:24,884][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:26:24,885][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:26,870][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:26,872][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:26,875][root][INFO] - LLM usage: prompt_tokens = 124551, completion_tokens = 41573
[2025-09-19 23:26:26,876][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:27,956][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:27,957][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:27,960][root][INFO] - LLM usage: prompt_tokens = 125079, completion_tokens = 41654
[2025-09-19 23:26:27,960][root][INFO] - Iteration 0: Running Code 349571428291498819
[2025-09-19 23:26:28,492][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:26:28,529][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:26:28,529][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:32,166][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:32,171][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:32,177][root][INFO] - LLM usage: prompt_tokens = 125647, completion_tokens = 42159
[2025-09-19 23:26:32,179][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:33,279][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:33,283][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:33,290][root][INFO] - LLM usage: prompt_tokens = 126344, completion_tokens = 42250
[2025-09-19 23:26:33,291][root][INFO] - Iteration 0: Running Code 5340504498383515062
[2025-09-19 23:26:33,788][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:35,010][root][INFO] - Iteration 0, response_id 0: Objective value: 25.331778941384037
[2025-09-19 23:26:35,010][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:36,911][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:36,916][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:36,923][root][INFO] - LLM usage: prompt_tokens = 126893, completion_tokens = 42516
[2025-09-19 23:26:36,924][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:37,965][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:37,969][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:37,975][root][INFO] - LLM usage: prompt_tokens = 127351, completion_tokens = 42609
[2025-09-19 23:26:37,977][root][INFO] - Iteration 0: Running Code -19741077367319896
[2025-09-19 23:26:38,481][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:39,699][root][INFO] - Iteration 0, response_id 0: Objective value: 32.62961067822204
[2025-09-19 23:26:39,707][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:41,526][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:41,530][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:41,538][root][INFO] - LLM usage: prompt_tokens = 128530, completion_tokens = 42948
[2025-09-19 23:26:41,539][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:42,644][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:42,648][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:42,653][root][INFO] - LLM usage: prompt_tokens = 129056, completion_tokens = 43054
[2025-09-19 23:26:42,655][root][INFO] - Iteration 0: Running Code -8154400124340171726
[2025-09-19 23:26:43,173][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:45,360][root][INFO] - Iteration 0, response_id 0: Objective value: 7.374630446570211
[2025-09-19 23:26:45,362][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:46,707][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:46,711][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:46,719][root][INFO] - LLM usage: prompt_tokens = 130070, completion_tokens = 43322
[2025-09-19 23:26:46,722][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:47,634][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:47,635][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:47,636][root][INFO] - LLM usage: prompt_tokens = 130530, completion_tokens = 43412
[2025-09-19 23:26:47,637][root][INFO] - Iteration 0: Running Code 5064503443975799767
[2025-09-19 23:26:48,132][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:48,842][root][INFO] - Iteration 0, response_id 0: Objective value: 8.827442341771173
[2025-09-19 23:26:48,842][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:50,907][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:50,911][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:50,919][root][INFO] - LLM usage: prompt_tokens = 131191, completion_tokens = 43888
[2025-09-19 23:26:50,920][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:52,142][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:52,144][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:52,147][root][INFO] - LLM usage: prompt_tokens = 131859, completion_tokens = 44025
[2025-09-19 23:26:52,148][root][INFO] - Iteration 0: Running Code -4555860146582579659
[2025-09-19 23:26:52,666][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:53,858][root][INFO] - Iteration 0, response_id 0: Objective value: 7.855928235404853
[2025-09-19 23:26:53,860][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:55,730][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:55,734][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:55,742][root][INFO] - LLM usage: prompt_tokens = 132501, completion_tokens = 44426
[2025-09-19 23:26:55,743][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:26:56,650][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:26:56,654][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:26:56,660][root][INFO] - LLM usage: prompt_tokens = 133094, completion_tokens = 44506
[2025-09-19 23:26:56,663][root][INFO] - Iteration 0: Running Code -8149189706358335082
[2025-09-19 23:26:57,177][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:26:58,390][root][INFO] - Iteration 0, response_id 0: Objective value: 9.464107099326785
[2025-09-19 23:26:58,396][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:00,721][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:00,723][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:00,725][root][INFO] - LLM usage: prompt_tokens = 134220, completion_tokens = 44935
[2025-09-19 23:27:00,726][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:01,664][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:01,665][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:01,667][root][INFO] - LLM usage: prompt_tokens = 134841, completion_tokens = 45026
[2025-09-19 23:27:01,667][root][INFO] - Iteration 0: Running Code -6993754533161964496
[2025-09-19 23:27:02,152][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:03,375][root][INFO] - Iteration 0, response_id 0: Objective value: 8.14181221890124
[2025-09-19 23:27:03,377][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:04,871][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:04,875][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:04,880][root][INFO] - LLM usage: prompt_tokens = 135513, completion_tokens = 45213
[2025-09-19 23:27:04,882][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:05,889][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:05,893][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:05,898][root][INFO] - LLM usage: prompt_tokens = 135892, completion_tokens = 45315
[2025-09-19 23:27:05,900][root][INFO] - Iteration 0: Running Code -1499338463395153731
[2025-09-19 23:27:06,390][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:07,777][root][INFO] - Iteration 0, response_id 0: Objective value: 15.343605008949261
[2025-09-19 23:27:07,778][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:09,401][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:09,405][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:09,412][root][INFO] - LLM usage: prompt_tokens = 136827, completion_tokens = 45571
[2025-09-19 23:27:09,414][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:10,754][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:10,756][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:10,757][root][INFO] - LLM usage: prompt_tokens = 137275, completion_tokens = 45669
[2025-09-19 23:27:10,758][root][INFO] - Iteration 0: Running Code 6464744072273261571
[2025-09-19 23:27:11,244][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:12,007][root][INFO] - Iteration 0, response_id 0: Objective value: 7.227035612744023
[2025-09-19 23:27:12,008][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:14,577][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:14,579][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:14,581][root][INFO] - LLM usage: prompt_tokens = 138155, completion_tokens = 45991
[2025-09-19 23:27:14,581][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:15,695][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:15,697][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:15,700][root][INFO] - LLM usage: prompt_tokens = 138669, completion_tokens = 46090
[2025-09-19 23:27:15,701][root][INFO] - Iteration 0: Running Code -5955293653878784438
[2025-09-19 23:27:16,202][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:17,445][root][INFO] - Iteration 0, response_id 0: Objective value: 6.699016292496846
[2025-09-19 23:27:17,446][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:19,801][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:19,805][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:19,811][root][INFO] - LLM usage: prompt_tokens = 139189, completion_tokens = 46428
[2025-09-19 23:27:19,813][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:21,110][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:21,112][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:21,113][root][INFO] - LLM usage: prompt_tokens = 139719, completion_tokens = 46519
[2025-09-19 23:27:21,114][root][INFO] - Iteration 0: Running Code 338287300728766118
[2025-09-19 23:27:21,628][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:23,404][root][INFO] - Iteration 0, response_id 0: Objective value: 7.279017239669747
[2025-09-19 23:27:23,404][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:25,316][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:25,320][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:25,327][root][INFO] - LLM usage: prompt_tokens = 140220, completion_tokens = 46798
[2025-09-19 23:27:25,329][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:26,504][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:26,506][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:26,507][root][INFO] - LLM usage: prompt_tokens = 140691, completion_tokens = 46903
[2025-09-19 23:27:26,508][root][INFO] - Iteration 0: Running Code -5000827425158768359
[2025-09-19 23:27:26,997][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:27:27,787][root][INFO] - Iteration 0, response_id 0: Objective value: 7.377179588750645
[2025-09-19 23:27:27,794][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:31,065][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:31,066][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:31,068][root][INFO] - LLM usage: prompt_tokens = 141507, completion_tokens = 47369
[2025-09-19 23:27:31,068][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:27:35,226][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:27:35,229][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:27:35,231][root][INFO] - LLM usage: prompt_tokens = 142165, completion_tokens = 47482
[2025-09-19 23:27:35,231][root][INFO] - Iteration 0: Running Code 8147471755976798957
[2025-09-19 23:27:35,715][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:00,802][root][INFO] - Iteration 0, response_id 0: Objective value: 7.315681116135279
[2025-09-19 23:28:00,803][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:03,340][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:03,342][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:03,343][root][INFO] - LLM usage: prompt_tokens = 142878, completion_tokens = 47639
[2025-09-19 23:28:03,344][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:04,499][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:04,500][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:04,502][root][INFO] - LLM usage: prompt_tokens = 143227, completion_tokens = 47721
[2025-09-19 23:28:04,503][root][INFO] - Iteration 0: Running Code 8167579523693709351
[2025-09-19 23:28:04,997][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:05,560][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:28:05,561][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:07,160][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:07,164][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:07,172][root][INFO] - LLM usage: prompt_tokens = 144199, completion_tokens = 48001
[2025-09-19 23:28:07,174][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:08,793][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:08,871][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:08,874][root][INFO] - LLM usage: prompt_tokens = 144671, completion_tokens = 48097
[2025-09-19 23:28:08,875][root][INFO] - Iteration 0: Running Code 759559111426089671
[2025-09-19 23:28:09,384][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:10,188][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0814967987570085
[2025-09-19 23:28:10,189][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:12,464][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:12,465][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:12,466][root][INFO] - LLM usage: prompt_tokens = 145165, completion_tokens = 48445
[2025-09-19 23:28:12,467][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:13,861][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:13,864][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:13,866][root][INFO] - LLM usage: prompt_tokens = 145705, completion_tokens = 48571
[2025-09-19 23:28:13,867][root][INFO] - Iteration 0: Running Code -98501507634904315
[2025-09-19 23:28:14,357][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:14,394][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:28:14,394][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:17,276][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:17,280][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:17,286][root][INFO] - LLM usage: prompt_tokens = 146199, completion_tokens = 48905
[2025-09-19 23:28:17,288][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:18,575][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:18,577][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:18,579][root][INFO] - LLM usage: prompt_tokens = 146725, completion_tokens = 49001
[2025-09-19 23:28:18,580][root][INFO] - Iteration 0: Running Code 7309501138216129410
[2025-09-19 23:28:19,078][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:19,114][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:28:19,115][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:21,121][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:21,122][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:21,124][root][INFO] - LLM usage: prompt_tokens = 147219, completion_tokens = 49303
[2025-09-19 23:28:21,124][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:23,459][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:23,463][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:23,469][root][INFO] - LLM usage: prompt_tokens = 147713, completion_tokens = 49422
[2025-09-19 23:28:23,471][root][INFO] - Iteration 0: Running Code 2837550401228652861
[2025-09-19 23:28:23,988][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:25,413][root][INFO] - Iteration 0, response_id 0: Objective value: 8.021528500811744
[2025-09-19 23:28:25,414][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:27,014][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:27,015][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:27,017][root][INFO] - LLM usage: prompt_tokens = 148188, completion_tokens = 49611
[2025-09-19 23:28:27,017][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:28,471][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:28,472][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:28,473][root][INFO] - LLM usage: prompt_tokens = 148569, completion_tokens = 49716
[2025-09-19 23:28:28,474][root][INFO] - Iteration 0: Running Code 1832826269661584847
[2025-09-19 23:28:28,987][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:29,729][root][INFO] - Iteration 0, response_id 0: Objective value: 7.74605758490636
[2025-09-19 23:28:29,736][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:32,003][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:32,007][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:32,009][root][INFO] - LLM usage: prompt_tokens = 149278, completion_tokens = 49971
[2025-09-19 23:28:32,009][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:33,742][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:33,747][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:33,752][root][INFO] - LLM usage: prompt_tokens = 149720, completion_tokens = 50087
[2025-09-19 23:28:33,754][root][INFO] - Iteration 0: Running Code -6965268664847670379
[2025-09-19 23:28:34,253][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:35,008][root][INFO] - Iteration 0, response_id 0: Objective value: 6.8455817332096265
[2025-09-19 23:28:35,010][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:37,389][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:37,393][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:37,401][root][INFO] - LLM usage: prompt_tokens = 150730, completion_tokens = 50402
[2025-09-19 23:28:37,403][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:39,629][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:39,633][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:39,639][root][INFO] - LLM usage: prompt_tokens = 151232, completion_tokens = 50484
[2025-09-19 23:28:39,641][root][INFO] - Iteration 0: Running Code -954089778664495857
[2025-09-19 23:28:40,139][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:41,406][root][INFO] - Iteration 0, response_id 0: Objective value: 6.643530465948105
[2025-09-19 23:28:41,406][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:44,404][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:44,408][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:44,410][root][INFO] - LLM usage: prompt_tokens = 151764, completion_tokens = 50841
[2025-09-19 23:28:44,410][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:45,552][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:45,556][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:45,558][root][INFO] - LLM usage: prompt_tokens = 152313, completion_tokens = 50929
[2025-09-19 23:28:45,559][root][INFO] - Iteration 0: Running Code 2131593932335076489
[2025-09-19 23:28:46,051][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:28:57,567][root][INFO] - Iteration 0, response_id 0: Objective value: 7.5982532906087705
[2025-09-19 23:28:57,568][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:28:59,219][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:28:59,222][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:28:59,224][root][INFO] - LLM usage: prompt_tokens = 152826, completion_tokens = 51199
[2025-09-19 23:28:59,225][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:00,256][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:00,260][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:00,266][root][INFO] - LLM usage: prompt_tokens = 153288, completion_tokens = 51276
[2025-09-19 23:29:00,268][root][INFO] - Iteration 0: Running Code -7656861650271222036
[2025-09-19 23:29:00,774][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:01,567][root][INFO] - Iteration 0, response_id 0: Objective value: 7.488243433641234
[2025-09-19 23:29:01,574][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:03,580][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:03,585][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:03,592][root][INFO] - LLM usage: prompt_tokens = 154116, completion_tokens = 51654
[2025-09-19 23:29:03,594][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:05,091][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:05,095][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:05,101][root][INFO] - LLM usage: prompt_tokens = 154686, completion_tokens = 51765
[2025-09-19 23:29:05,103][root][INFO] - Iteration 0: Running Code -4157966322987951579
[2025-09-19 23:29:05,614][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:29,427][root][INFO] - Iteration 0, response_id 0: Objective value: 7.320990209055778
[2025-09-19 23:29:29,428][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:30,876][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:30,880][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:30,887][root][INFO] - LLM usage: prompt_tokens = 155457, completion_tokens = 52002
[2025-09-19 23:29:30,889][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:32,060][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:32,061][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:32,062][root][INFO] - LLM usage: prompt_tokens = 155886, completion_tokens = 52097
[2025-09-19 23:29:32,063][root][INFO] - Iteration 0: Running Code -156493058458417787
[2025-09-19 23:29:32,610][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:33,951][root][INFO] - Iteration 0, response_id 0: Objective value: 6.551400947540846
[2025-09-19 23:29:33,952][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:35,458][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:35,463][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:35,469][root][INFO] - LLM usage: prompt_tokens = 156297, completion_tokens = 52326
[2025-09-19 23:29:35,470][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:36,619][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:36,621][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:36,622][root][INFO] - LLM usage: prompt_tokens = 156718, completion_tokens = 52408
[2025-09-19 23:29:36,623][root][INFO] - Iteration 0: Running Code 6619025064096674106
[2025-09-19 23:29:37,113][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:37,151][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:29:37,152][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:38,713][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:38,717][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:38,723][root][INFO] - LLM usage: prompt_tokens = 157129, completion_tokens = 52643
[2025-09-19 23:29:38,725][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:39,833][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:39,837][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:39,843][root][INFO] - LLM usage: prompt_tokens = 157551, completion_tokens = 52741
[2025-09-19 23:29:39,845][root][INFO] - Iteration 0: Running Code -4599780105920881878
[2025-09-19 23:29:40,342][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:55,288][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:29:55,289][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:56,465][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:56,469][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:56,475][root][INFO] - LLM usage: prompt_tokens = 157943, completion_tokens = 52909
[2025-09-19 23:29:56,477][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:29:57,774][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:29:57,778][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:29:57,784][root][INFO] - LLM usage: prompt_tokens = 158298, completion_tokens = 53021
[2025-09-19 23:29:57,785][root][INFO] - Iteration 0: Running Code 2280429517003166085
[2025-09-19 23:29:58,303][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:29:58,841][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:29:58,848][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:00,053][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:00,054][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:00,056][root][INFO] - LLM usage: prompt_tokens = 158924, completion_tokens = 53185
[2025-09-19 23:30:00,056][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:01,290][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:01,294][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:01,295][root][INFO] - LLM usage: prompt_tokens = 159275, completion_tokens = 53279
[2025-09-19 23:30:01,296][root][INFO] - Iteration 0: Running Code 274024054622720548
[2025-09-19 23:30:01,781][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:02,327][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:30:02,330][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:04,016][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:04,020][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:04,029][root][INFO] - LLM usage: prompt_tokens = 160738, completion_tokens = 53574
[2025-09-19 23:30:04,031][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:05,037][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:05,041][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:05,047][root][INFO] - LLM usage: prompt_tokens = 161225, completion_tokens = 53651
[2025-09-19 23:30:05,049][root][INFO] - Iteration 0: Running Code -3159709973718926704
[2025-09-19 23:30:05,551][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:07,591][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:30:07,592][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:09,773][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:09,775][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:09,778][root][INFO] - LLM usage: prompt_tokens = 162418, completion_tokens = 54150
[2025-09-19 23:30:09,779][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:10,915][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:10,920][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:10,926][root][INFO] - LLM usage: prompt_tokens = 163109, completion_tokens = 54255
[2025-09-19 23:30:10,929][root][INFO] - Iteration 0: Running Code 9021655115118364887
[2025-09-19 23:30:11,431][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:13,498][root][INFO] - Iteration 0, response_id 0: Objective value: 6.740945786340461
[2025-09-19 23:30:13,498][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:16,773][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:16,778][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:16,785][root][INFO] - LLM usage: prompt_tokens = 163839, completion_tokens = 54910
[2025-09-19 23:30:16,786][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:17,845][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:17,849][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:17,855][root][INFO] - LLM usage: prompt_tokens = 164686, completion_tokens = 54998
[2025-09-19 23:30:17,856][root][INFO] - Iteration 0: Running Code 7565274132421053474
[2025-09-19 23:30:18,345][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:18,384][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:30:18,384][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:21,061][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:21,065][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:21,073][root][INFO] - LLM usage: prompt_tokens = 165416, completion_tokens = 55494
[2025-09-19 23:30:21,074][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:22,211][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:22,214][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:22,217][root][INFO] - LLM usage: prompt_tokens = 166099, completion_tokens = 55598
[2025-09-19 23:30:22,218][root][INFO] - Iteration 0: Running Code 3242310619188862880
[2025-09-19 23:30:22,736][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:24,784][root][INFO] - Iteration 0, response_id 0: Objective value: 36.57570543998629
[2025-09-19 23:30:24,785][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:27,293][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:27,297][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:27,305][root][INFO] - LLM usage: prompt_tokens = 166810, completion_tokens = 56056
[2025-09-19 23:30:27,307][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:28,644][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:28,647][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:28,649][root][INFO] - LLM usage: prompt_tokens = 167460, completion_tokens = 56159
[2025-09-19 23:30:28,649][root][INFO] - Iteration 0: Running Code 7326577155839276273
[2025-09-19 23:30:29,141][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:31,188][root][INFO] - Iteration 0, response_id 0: Objective value: 7.300640500832115
[2025-09-19 23:30:31,197][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:33,165][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:33,167][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:33,170][root][INFO] - LLM usage: prompt_tokens = 168974, completion_tokens = 56611
[2025-09-19 23:30:33,170][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:34,071][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:34,075][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:34,081][root][INFO] - LLM usage: prompt_tokens = 169613, completion_tokens = 56704
[2025-09-19 23:30:34,083][root][INFO] - Iteration 0: Running Code -2591430041368756603
[2025-09-19 23:30:34,589][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:36,649][root][INFO] - Iteration 0, response_id 0: Objective value: 7.177943342427737
[2025-09-19 23:30:36,651][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:38,804][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:38,805][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:38,807][root][INFO] - LLM usage: prompt_tokens = 170501, completion_tokens = 57081
[2025-09-19 23:30:38,808][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:40,299][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:40,301][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:40,304][root][INFO] - LLM usage: prompt_tokens = 171070, completion_tokens = 57203
[2025-09-19 23:30:40,305][root][INFO] - Iteration 0: Running Code -621157600607371502
[2025-09-19 23:30:40,827][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:40,864][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:30:40,865][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:43,411][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:43,415][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:43,426][root][INFO] - LLM usage: prompt_tokens = 173527, completion_tokens = 57625
[2025-09-19 23:30:43,428][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:44,480][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:44,482][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:44,484][root][INFO] - LLM usage: prompt_tokens = 174141, completion_tokens = 57705
[2025-09-19 23:30:44,486][root][INFO] - Iteration 0: Running Code 6800843915243990801
[2025-09-19 23:30:44,976][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:47,006][root][INFO] - Iteration 0, response_id 0: Objective value: 7.08193316687947
[2025-09-19 23:30:47,007][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:48,642][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:48,643][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:48,645][root][INFO] - LLM usage: prompt_tokens = 175051, completion_tokens = 57959
[2025-09-19 23:30:48,646][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:49,798][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:49,799][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:49,801][root][INFO] - LLM usage: prompt_tokens = 175497, completion_tokens = 58071
[2025-09-19 23:30:49,801][root][INFO] - Iteration 0: Running Code 9061108736526874733
[2025-09-19 23:30:50,283][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:30:51,003][root][INFO] - Iteration 0, response_id 0: Objective value: 9.464107099326785
[2025-09-19 23:30:51,004][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:53,234][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:53,237][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:53,242][root][INFO] - LLM usage: prompt_tokens = 176641, completion_tokens = 58466
[2025-09-19 23:30:53,243][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:30:57,742][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:30:57,746][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:30:57,752][root][INFO] - LLM usage: prompt_tokens = 177228, completion_tokens = 58572
[2025-09-19 23:30:57,754][root][INFO] - Iteration 0: Running Code 5632230310732033124
[2025-09-19 23:30:58,258][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:14,873][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:31:14,873][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:17,983][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:17,987][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:17,994][root][INFO] - LLM usage: prompt_tokens = 177963, completion_tokens = 59126
[2025-09-19 23:31:17,996][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:19,584][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:19,588][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:19,595][root][INFO] - LLM usage: prompt_tokens = 178709, completion_tokens = 59251
[2025-09-19 23:31:19,598][root][INFO] - Iteration 0: Running Code 8650494013693578946
[2025-09-19 23:31:20,120][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:22,095][root][INFO] - Iteration 0, response_id 0: Objective value: 8.01222331988063
[2025-09-19 23:31:22,096][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:24,294][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:24,298][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:24,306][root][INFO] - LLM usage: prompt_tokens = 179425, completion_tokens = 59755
[2025-09-19 23:31:24,308][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:25,441][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:25,445][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:25,451][root][INFO] - LLM usage: prompt_tokens = 180121, completion_tokens = 59846
[2025-09-19 23:31:25,453][root][INFO] - Iteration 0: Running Code -7916357967561319926
[2025-09-19 23:31:25,963][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:27,930][root][INFO] - Iteration 0, response_id 0: Objective value: 9.963940640007333
[2025-09-19 23:31:27,941][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:30,526][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:30,530][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:30,540][root][INFO] - LLM usage: prompt_tokens = 181640, completion_tokens = 60372
[2025-09-19 23:31:30,542][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:31,897][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:31,901][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:31,907][root][INFO] - LLM usage: prompt_tokens = 182358, completion_tokens = 60464
[2025-09-19 23:31:31,910][root][INFO] - Iteration 0: Running Code 1051306277741474546
[2025-09-19 23:31:32,418][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:35,055][root][INFO] - Iteration 0, response_id 0: Objective value: 7.801210773104069
[2025-09-19 23:31:35,058][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:36,964][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:36,968][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:36,976][root][INFO] - LLM usage: prompt_tokens = 183365, completion_tokens = 60791
[2025-09-19 23:31:36,978][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:38,450][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:38,454][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:38,455][root][INFO] - LLM usage: prompt_tokens = 183884, completion_tokens = 60917
[2025-09-19 23:31:38,456][root][INFO] - Iteration 0: Running Code -6699441975642337716
[2025-09-19 23:31:38,937][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:40,202][root][INFO] - Iteration 0, response_id 0: Objective value: 7.4261582322526305
[2025-09-19 23:31:40,203][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:45,765][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:45,770][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:45,778][root][INFO] - LLM usage: prompt_tokens = 184546, completion_tokens = 61321
[2025-09-19 23:31:45,780][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:46,871][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:46,873][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:46,874][root][INFO] - LLM usage: prompt_tokens = 185154, completion_tokens = 61416
[2025-09-19 23:31:46,876][root][INFO] - Iteration 0: Running Code 8616966777361284774
[2025-09-19 23:31:47,392][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:31:47,430][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:31:47,431][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:50,099][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:50,103][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:50,111][root][INFO] - LLM usage: prompt_tokens = 185816, completion_tokens = 61957
[2025-09-19 23:31:50,113][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:51,285][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:51,289][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:51,295][root][INFO] - LLM usage: prompt_tokens = 186549, completion_tokens = 62049
[2025-09-19 23:31:51,298][root][INFO] - Iteration 0: Running Code 8580394223187555812
[2025-09-19 23:31:51,807][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:31:54,533][root][INFO] - Iteration 0, response_id 0: Objective value: 7.068485701317879
[2025-09-19 23:31:54,534][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:56,796][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:56,798][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:56,801][root][INFO] - LLM usage: prompt_tokens = 187192, completion_tokens = 62464
[2025-09-19 23:31:56,802][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:31:58,036][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:31:58,040][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:31:58,043][root][INFO] - LLM usage: prompt_tokens = 187799, completion_tokens = 62557
[2025-09-19 23:31:58,044][root][INFO] - Iteration 0: Running Code -4809817364117195587
[2025-09-19 23:31:58,535][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:00,569][root][INFO] - Iteration 0, response_id 0: Objective value: 6.992933557976045
[2025-09-19 23:32:00,578][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:02,406][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:02,411][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:02,418][root][INFO] - LLM usage: prompt_tokens = 188841, completion_tokens = 62870
[2025-09-19 23:32:02,421][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:03,512][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:03,516][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:03,522][root][INFO] - LLM usage: prompt_tokens = 189346, completion_tokens = 62970
[2025-09-19 23:32:03,524][root][INFO] - Iteration 0: Running Code 8647239927246707043
[2025-09-19 23:32:04,037][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:05,266][root][INFO] - Iteration 0, response_id 0: Objective value: 15.025704714053843
[2025-09-19 23:32:05,267][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:07,958][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:07,962][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:07,969][root][INFO] - LLM usage: prompt_tokens = 190021, completion_tokens = 63432
[2025-09-19 23:32:07,971][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:09,191][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:09,196][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:09,202][root][INFO] - LLM usage: prompt_tokens = 190675, completion_tokens = 63520
[2025-09-19 23:32:09,204][root][INFO] - Iteration 0: Running Code 487720016840632119
[2025-09-19 23:32:09,707][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:09,771][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:32:09,771][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:12,805][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:12,809][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:12,816][root][INFO] - LLM usage: prompt_tokens = 191350, completion_tokens = 64011
[2025-09-19 23:32:12,818][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:14,082][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:14,086][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:14,092][root][INFO] - LLM usage: prompt_tokens = 192028, completion_tokens = 64096
[2025-09-19 23:32:14,095][root][INFO] - Iteration 0: Running Code 663181092271254530
[2025-09-19 23:32:14,592][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:16,565][root][INFO] - Iteration 0, response_id 0: Objective value: 31.873224882721757
[2025-09-19 23:32:16,566][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:19,060][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:19,063][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:19,065][root][INFO] - LLM usage: prompt_tokens = 192684, completion_tokens = 64518
[2025-09-19 23:32:19,066][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:20,091][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:20,093][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:20,094][root][INFO] - LLM usage: prompt_tokens = 193293, completion_tokens = 64608
[2025-09-19 23:32:20,096][root][INFO] - Iteration 0: Running Code 6146222282832788768
[2025-09-19 23:32:20,585][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:22,602][root][INFO] - Iteration 0, response_id 0: Objective value: 7.600767627686496
[2025-09-19 23:32:22,611][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:26,193][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:26,194][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:26,198][root][INFO] - LLM usage: prompt_tokens = 194469, completion_tokens = 65044
[2025-09-19 23:32:26,198][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:27,315][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:27,319][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:27,325][root][INFO] - LLM usage: prompt_tokens = 195097, completion_tokens = 65148
[2025-09-19 23:32:27,327][root][INFO] - Iteration 0: Running Code -3478159291019473601
[2025-09-19 23:32:27,843][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:29,798][root][INFO] - Iteration 0, response_id 0: Objective value: 7.057397338357192
[2025-09-19 23:32:29,800][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:32,042][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:32,045][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:32,048][root][INFO] - LLM usage: prompt_tokens = 196251, completion_tokens = 65514
[2025-09-19 23:32:32,048][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:33,353][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:33,356][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:33,358][root][INFO] - LLM usage: prompt_tokens = 196819, completion_tokens = 65645
[2025-09-19 23:32:33,359][root][INFO] - Iteration 0: Running Code -5887060747367417526
[2025-09-19 23:32:33,848][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:32:33,885][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:32:33,886][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:36,495][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:36,499][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:36,508][root][INFO] - LLM usage: prompt_tokens = 198022, completion_tokens = 66098
[2025-09-19 23:32:36,509][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:37,584][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:37,585][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:37,587][root][INFO] - LLM usage: prompt_tokens = 198667, completion_tokens = 66203
[2025-09-19 23:32:37,588][root][INFO] - Iteration 0: Running Code 3703014741788068880
[2025-09-19 23:32:38,090][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:32:40,562][root][INFO] - Iteration 0, response_id 0: Objective value: 7.509546562181192
[2025-09-19 23:32:40,563][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:43,333][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:43,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:43,347][root][INFO] - LLM usage: prompt_tokens = 199461, completion_tokens = 66787
[2025-09-19 23:32:43,349][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:32:44,425][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:32:44,427][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:32:44,429][root][INFO] - LLM usage: prompt_tokens = 200237, completion_tokens = 66873
[2025-09-19 23:32:44,430][root][INFO] - Iteration 0: Running Code -2162794386945479491
[2025-09-19 23:32:44,924][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:33:13,378][root][INFO] - Iteration 0, response_id 0: Objective value: 7.20674099698202
[2025-09-19 23:33:13,379][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:15,769][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:15,772][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:15,774][root][INFO] - LLM usage: prompt_tokens = 201012, completion_tokens = 67446
[2025-09-19 23:33:15,774][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:16,930][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:16,931][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:16,933][root][INFO] - LLM usage: prompt_tokens = 201777, completion_tokens = 67544
[2025-09-19 23:33:16,934][root][INFO] - Iteration 0: Running Code -9100259563306335091
[2025-09-19 23:33:17,428][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:33:20,160][root][INFO] - Iteration 0, response_id 0: Objective value: 6.870311196190385
[2025-09-19 23:33:20,169][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:23,539][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:23,543][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:23,553][root][INFO] - LLM usage: prompt_tokens = 203072, completion_tokens = 68252
[2025-09-19 23:33:23,555][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:24,550][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:24,555][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:24,556][root][INFO] - LLM usage: prompt_tokens = 203967, completion_tokens = 68345
[2025-09-19 23:33:24,557][root][INFO] - Iteration 0: Running Code -2935772851972595219
[2025-09-19 23:33:25,052][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:33:29,129][root][INFO] - Iteration 0, response_id 0: Objective value: 7.169943796340142
[2025-09-19 23:33:29,131][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:30,692][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:30,697][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:30,706][root][INFO] - LLM usage: prompt_tokens = 205942, completion_tokens = 68592
[2025-09-19 23:33:30,707][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:31,760][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:31,765][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:31,770][root][INFO] - LLM usage: prompt_tokens = 206381, completion_tokens = 68695
[2025-09-19 23:33:31,772][root][INFO] - Iteration 0: Running Code -9038460624628613530
[2025-09-19 23:33:32,269][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:33:33,576][root][INFO] - Iteration 0, response_id 0: Objective value: 8.27042893754
[2025-09-19 23:33:33,577][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:35,374][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:35,379][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:35,387][root][INFO] - LLM usage: prompt_tokens = 207469, completion_tokens = 69084
[2025-09-19 23:33:35,389][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:36,886][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:36,890][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:36,895][root][INFO] - LLM usage: prompt_tokens = 208050, completion_tokens = 69194
[2025-09-19 23:33:36,898][root][INFO] - Iteration 0: Running Code -1852159866340267794
[2025-09-19 23:33:37,406][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:33:38,687][root][INFO] - Iteration 0, response_id 0: Objective value: 7.4261582322526305
[2025-09-19 23:33:38,687][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:41,138][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:41,142][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:41,149][root][INFO] - LLM usage: prompt_tokens = 208675, completion_tokens = 69716
[2025-09-19 23:33:41,150][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:42,336][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:42,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:42,341][root][INFO] - LLM usage: prompt_tokens = 208992, completion_tokens = 69833
[2025-09-19 23:33:42,341][root][INFO] - Iteration 0: Running Code -8173945685876586310
[2025-09-19 23:33:42,847][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:33:42,886][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:33:42,886][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:45,693][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:45,697][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:45,704][root][INFO] - LLM usage: prompt_tokens = 209617, completion_tokens = 70323
[2025-09-19 23:33:45,706][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:33:47,242][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:33:47,247][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:33:47,253][root][INFO] - LLM usage: prompt_tokens = 210294, completion_tokens = 70448
[2025-09-19 23:33:47,256][root][INFO] - Iteration 0: Running Code -3877819251098487390
[2025-09-19 23:33:47,765][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:13,782][root][INFO] - Iteration 0, response_id 0: Objective value: 7.240876885499016
[2025-09-19 23:34:13,783][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:15,684][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:15,685][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:15,687][root][INFO] - LLM usage: prompt_tokens = 210900, completion_tokens = 70766
[2025-09-19 23:34:15,687][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:16,717][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:16,718][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:16,720][root][INFO] - LLM usage: prompt_tokens = 211410, completion_tokens = 70841
[2025-09-19 23:34:16,721][root][INFO] - Iteration 0: Running Code 7145617007953467730
[2025-09-19 23:34:17,214][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:18,501][root][INFO] - Iteration 0, response_id 0: Objective value: 32.08584885738665
[2025-09-19 23:34:18,511][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:21,087][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:21,091][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:21,098][root][INFO] - LLM usage: prompt_tokens = 212536, completion_tokens = 71411
[2025-09-19 23:34:21,098][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:23,320][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:23,325][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:23,331][root][INFO] - LLM usage: prompt_tokens = 213298, completion_tokens = 71524
[2025-09-19 23:34:23,334][root][INFO] - Iteration 0: Running Code 3300885188571714074
[2025-09-19 23:34:23,839][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:27,015][root][INFO] - Iteration 0, response_id 0: Objective value: 6.47317621676763
[2025-09-19 23:34:27,017][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:28,975][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:28,980][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:28,987][root][INFO] - LLM usage: prompt_tokens = 214195, completion_tokens = 71866
[2025-09-19 23:34:28,989][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:30,257][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:30,261][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:30,267][root][INFO] - LLM usage: prompt_tokens = 214729, completion_tokens = 71967
[2025-09-19 23:34:30,269][root][INFO] - Iteration 0: Running Code 8563635094838104014
[2025-09-19 23:34:30,768][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:33,232][root][INFO] - Iteration 0, response_id 0: Objective value: 6.625254691116391
[2025-09-19 23:34:33,233][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:35,608][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:35,613][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:35,618][root][INFO] - LLM usage: prompt_tokens = 215243, completion_tokens = 72352
[2025-09-19 23:34:35,619][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:36,906][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:36,911][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:36,917][root][INFO] - LLM usage: prompt_tokens = 215820, completion_tokens = 72471
[2025-09-19 23:34:36,919][root][INFO] - Iteration 0: Running Code 9142603576086437655
[2025-09-19 23:34:37,436][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:39,976][root][INFO] - Iteration 0, response_id 0: Objective value: 24.83173000222994
[2025-09-19 23:34:39,976][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:41,498][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:41,502][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:41,508][root][INFO] - LLM usage: prompt_tokens = 216315, completion_tokens = 72760
[2025-09-19 23:34:41,510][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:42,653][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:42,657][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:42,663][root][INFO] - LLM usage: prompt_tokens = 216796, completion_tokens = 72883
[2025-09-19 23:34:42,665][root][INFO] - Iteration 0: Running Code -4276561356233685886
[2025-09-19 23:34:43,204][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:44,489][root][INFO] - Iteration 0, response_id 0: Objective value: 25.401215230712744
[2025-09-19 23:34:44,497][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:46,493][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:46,498][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:46,505][root][INFO] - LLM usage: prompt_tokens = 217776, completion_tokens = 73233
[2025-09-19 23:34:46,507][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:47,528][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:47,532][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:47,537][root][INFO] - LLM usage: prompt_tokens = 218318, completion_tokens = 73319
[2025-09-19 23:34:47,539][root][INFO] - Iteration 0: Running Code 8563635094838104014
[2025-09-19 23:34:48,055][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:50,420][root][INFO] - Iteration 0, response_id 0: Objective value: 6.625254691116391
[2025-09-19 23:34:50,420][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:52,401][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:52,405][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:52,411][root][INFO] - LLM usage: prompt_tokens = 218915, completion_tokens = 73678
[2025-09-19 23:34:52,412][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:34:53,682][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:34:53,686][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:34:53,692][root][INFO] - LLM usage: prompt_tokens = 219466, completion_tokens = 73779
[2025-09-19 23:34:53,694][root][INFO] - Iteration 0: Running Code 4606812809365606659
[2025-09-19 23:34:54,202][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:34:56,367][root][INFO] - Iteration 0, response_id 0: Objective value: 6.44573639182836
[2025-09-19 23:34:56,367][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:01,536][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:01,540][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:01,542][root][INFO] - LLM usage: prompt_tokens = 220044, completion_tokens = 74113
[2025-09-19 23:35:01,542][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:02,696][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:02,701][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:02,706][root][INFO] - LLM usage: prompt_tokens = 220570, completion_tokens = 74226
[2025-09-19 23:35:02,707][root][INFO] - Iteration 0: Running Code 63365755144377286
[2025-09-19 23:35:03,213][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:05,779][root][INFO] - Iteration 0, response_id 0: Objective value: 6.61284227128499
[2025-09-19 23:35:05,788][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:07,548][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:07,551][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:07,558][root][INFO] - LLM usage: prompt_tokens = 221520, completion_tokens = 74580
[2025-09-19 23:35:07,560][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:08,901][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:08,904][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:08,905][root][INFO] - LLM usage: prompt_tokens = 222066, completion_tokens = 74696
[2025-09-19 23:35:08,906][root][INFO] - Iteration 0: Running Code -1729397721792111798
[2025-09-19 23:35:09,391][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:11,793][root][INFO] - Iteration 0, response_id 0: Objective value: 6.612252312885365
[2025-09-19 23:35:11,795][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:13,815][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:13,820][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:13,828][root][INFO] - LLM usage: prompt_tokens = 223134, completion_tokens = 75091
[2025-09-19 23:35:13,829][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:15,134][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:15,138][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:15,144][root][INFO] - LLM usage: prompt_tokens = 223721, completion_tokens = 75207
[2025-09-19 23:35:15,146][root][INFO] - Iteration 0: Running Code 4967691241026015588
[2025-09-19 23:35:15,641][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:17,841][root][INFO] - Iteration 0, response_id 0: Objective value: 6.448253874391039
[2025-09-19 23:35:17,841][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:20,396][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:20,400][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:20,407][root][INFO] - LLM usage: prompt_tokens = 224326, completion_tokens = 75629
[2025-09-19 23:35:20,409][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:21,465][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:21,468][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:21,470][root][INFO] - LLM usage: prompt_tokens = 224940, completion_tokens = 75722
[2025-09-19 23:35:21,470][root][INFO] - Iteration 0: Running Code 530168141276341856
[2025-09-19 23:35:21,958][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:24,172][root][INFO] - Iteration 0, response_id 0: Objective value: 9.949037354421407
[2025-09-19 23:35:24,173][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:26,045][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:26,046][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:26,048][root][INFO] - LLM usage: prompt_tokens = 225526, completion_tokens = 76039
[2025-09-19 23:35:26,049][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:27,653][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:27,658][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:27,663][root][INFO] - LLM usage: prompt_tokens = 226035, completion_tokens = 76134
[2025-09-19 23:35:27,665][root][INFO] - Iteration 0: Running Code -7074840277275813899
[2025-09-19 23:35:28,179][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:30,355][root][INFO] - Iteration 0, response_id 0: Objective value: 7.5209389737430214
[2025-09-19 23:35:30,369][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:32,446][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:32,447][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:32,450][root][INFO] - LLM usage: prompt_tokens = 227396, completion_tokens = 76542
[2025-09-19 23:35:32,450][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:33,648][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:33,652][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:33,659][root][INFO] - LLM usage: prompt_tokens = 227996, completion_tokens = 76626
[2025-09-19 23:35:33,661][root][INFO] - Iteration 0: Running Code 2572446288503952837
[2025-09-19 23:35:34,164][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:36,953][root][INFO] - Iteration 0, response_id 0: Objective value: 6.452079160416718
[2025-09-19 23:35:36,955][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:39,371][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:39,372][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:39,375][root][INFO] - LLM usage: prompt_tokens = 229154, completion_tokens = 77051
[2025-09-19 23:35:39,376][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:40,466][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:40,467][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:40,469][root][INFO] - LLM usage: prompt_tokens = 229771, completion_tokens = 77158
[2025-09-19 23:35:40,470][root][INFO] - Iteration 0: Running Code 2576449318614660082
[2025-09-19 23:35:40,952][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:43,111][root][INFO] - Iteration 0, response_id 0: Objective value: 6.451340445232406
[2025-09-19 23:35:43,112][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:45,515][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:45,517][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:45,519][root][INFO] - LLM usage: prompt_tokens = 230388, completion_tokens = 77606
[2025-09-19 23:35:45,520][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:46,742][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:46,743][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:46,745][root][INFO] - LLM usage: prompt_tokens = 231028, completion_tokens = 77717
[2025-09-19 23:35:46,746][root][INFO] - Iteration 0: Running Code 3392990905529538850
[2025-09-19 23:35:47,234][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:49,651][root][INFO] - Iteration 0, response_id 0: Objective value: 6.933164857146246
[2025-09-19 23:35:49,652][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:51,380][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:51,383][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:51,385][root][INFO] - LLM usage: prompt_tokens = 231626, completion_tokens = 78051
[2025-09-19 23:35:51,385][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:52,532][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:52,534][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:52,536][root][INFO] - LLM usage: prompt_tokens = 232152, completion_tokens = 78186
[2025-09-19 23:35:52,536][root][INFO] - Iteration 0: Running Code -1144585971906591684
[2025-09-19 23:35:53,040][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:35:55,437][root][INFO] - Iteration 0, response_id 0: Objective value: 6.633896412256609
[2025-09-19 23:35:55,450][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:57,463][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:57,465][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:57,469][root][INFO] - LLM usage: prompt_tokens = 233525, completion_tokens = 78525
[2025-09-19 23:35:57,469][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:35:58,821][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:35:58,826][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:35:58,832][root][INFO] - LLM usage: prompt_tokens = 234056, completion_tokens = 78619
[2025-09-19 23:35:58,834][root][INFO] - Iteration 0: Running Code 8037799980134879686
[2025-09-19 23:35:59,338][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:01,781][root][INFO] - Iteration 0, response_id 0: Objective value: 6.612252312885365
[2025-09-19 23:36:01,783][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:03,658][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:03,662][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:03,670][root][INFO] - LLM usage: prompt_tokens = 235276, completion_tokens = 78921
[2025-09-19 23:36:03,671][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:05,058][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:05,062][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:05,064][root][INFO] - LLM usage: prompt_tokens = 235770, completion_tokens = 79074
[2025-09-19 23:36:05,064][root][INFO] - Iteration 0: Running Code 6871503978801713600
[2025-09-19 23:36:05,551][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:06,872][root][INFO] - Iteration 0, response_id 0: Objective value: 7.642967982770405
[2025-09-19 23:36:06,873][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:09,976][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:09,977][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:09,979][root][INFO] - LLM usage: prompt_tokens = 236848, completion_tokens = 79455
[2025-09-19 23:36:09,980][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:11,097][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:11,100][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:11,102][root][INFO] - LLM usage: prompt_tokens = 237421, completion_tokens = 79574
[2025-09-19 23:36:11,103][root][INFO] - Iteration 0: Running Code -62417961316860293
[2025-09-19 23:36:11,605][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:13,758][root][INFO] - Iteration 0, response_id 0: Objective value: 6.46442610420492
[2025-09-19 23:36:13,758][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:18,289][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:18,291][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:18,296][root][INFO] - LLM usage: prompt_tokens = 238035, completion_tokens = 80092
[2025-09-19 23:36:18,297][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:19,691][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:19,695][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:19,701][root][INFO] - LLM usage: prompt_tokens = 238745, completion_tokens = 80183
[2025-09-19 23:36:19,704][root][INFO] - Iteration 0: Running Code 7763018183846968960
[2025-09-19 23:36:20,203][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:20,242][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:36:20,242][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:22,719][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:22,724][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:22,731][root][INFO] - LLM usage: prompt_tokens = 239359, completion_tokens = 80676
[2025-09-19 23:36:22,733][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:23,839][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:23,843][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:23,849][root][INFO] - LLM usage: prompt_tokens = 240044, completion_tokens = 80768
[2025-09-19 23:36:23,852][root][INFO] - Iteration 0: Running Code -3375948980219198287
[2025-09-19 23:36:24,360][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:24,433][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:36:24,434][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:28,340][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:28,343][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:28,346][root][INFO] - LLM usage: prompt_tokens = 240658, completion_tokens = 81289
[2025-09-19 23:36:28,346][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:29,721][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:29,726][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:29,732][root][INFO] - LLM usage: prompt_tokens = 241371, completion_tokens = 81395
[2025-09-19 23:36:29,735][root][INFO] - Iteration 0: Running Code -5494824985488671203
[2025-09-19 23:36:30,229][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:30,267][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:36:30,268][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:31,902][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:31,903][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:31,905][root][INFO] - LLM usage: prompt_tokens = 241966, completion_tokens = 81709
[2025-09-19 23:36:31,905][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:33,028][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:33,031][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:33,033][root][INFO] - LLM usage: prompt_tokens = 242472, completion_tokens = 81807
[2025-09-19 23:36:33,034][root][INFO] - Iteration 0: Running Code -7388735771522254157
[2025-09-19 23:36:33,513][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:35,485][root][INFO] - Iteration 0, response_id 0: Objective value: 7.838574028801167
[2025-09-19 23:36:35,499][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:37,432][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:37,433][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:37,435][root][INFO] - LLM usage: prompt_tokens = 243842, completion_tokens = 82170
[2025-09-19 23:36:37,436][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:38,459][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:38,462][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:38,469][root][INFO] - LLM usage: prompt_tokens = 244397, completion_tokens = 82267
[2025-09-19 23:36:38,471][root][INFO] - Iteration 0: Running Code -3918314131402059703
[2025-09-19 23:36:38,969][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:41,348][root][INFO] - Iteration 0, response_id 0: Objective value: 6.636006351326177
[2025-09-19 23:36:41,350][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:43,460][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:43,464][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:43,474][root][INFO] - LLM usage: prompt_tokens = 246322, completion_tokens = 82557
[2025-09-19 23:36:43,476][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:44,567][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:44,569][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:44,571][root][INFO] - LLM usage: prompt_tokens = 246781, completion_tokens = 82658
[2025-09-19 23:36:44,571][root][INFO] - Iteration 0: Running Code 4763021381078788906
[2025-09-19 23:36:45,060][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:45,098][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:36:45,098][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:47,451][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:47,452][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:47,454][root][INFO] - LLM usage: prompt_tokens = 248270, completion_tokens = 83110
[2025-09-19 23:36:47,455][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:48,592][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:48,596][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:48,603][root][INFO] - LLM usage: prompt_tokens = 248914, completion_tokens = 83190
[2025-09-19 23:36:48,604][root][INFO] - Iteration 0: Running Code -4328935178872546699
[2025-09-19 23:36:49,097][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:50,573][root][INFO] - Iteration 0, response_id 0: Objective value: 13.293675480564406
[2025-09-19 23:36:50,574][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:52,351][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:52,355][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:52,357][root][INFO] - LLM usage: prompt_tokens = 249929, completion_tokens = 83503
[2025-09-19 23:36:52,357][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:53,574][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:53,578][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:53,584][root][INFO] - LLM usage: prompt_tokens = 250434, completion_tokens = 83618
[2025-09-19 23:36:53,586][root][INFO] - Iteration 0: Running Code 6259233369863280014
[2025-09-19 23:36:54,102][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:36:54,862][root][INFO] - Iteration 0, response_id 0: Objective value: 9.158875278165898
[2025-09-19 23:36:54,862][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:57,147][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:57,151][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:57,160][root][INFO] - LLM usage: prompt_tokens = 251641, completion_tokens = 84095
[2025-09-19 23:36:57,161][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:36:58,396][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:36:58,397][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:36:58,400][root][INFO] - LLM usage: prompt_tokens = 252310, completion_tokens = 84185
[2025-09-19 23:36:58,401][root][INFO] - Iteration 0: Running Code -7010364383417719337
[2025-09-19 23:36:58,898][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:01,330][root][INFO] - Iteration 0, response_id 0: Objective value: 7.8829865856187
[2025-09-19 23:37:01,331][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:04,363][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:04,366][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:04,369][root][INFO] - LLM usage: prompt_tokens = 253157, completion_tokens = 84807
[2025-09-19 23:37:04,369][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:05,425][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:05,429][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:05,435][root][INFO] - LLM usage: prompt_tokens = 253971, completion_tokens = 84877
[2025-09-19 23:37:05,438][root][INFO] - Iteration 0: Running Code -9005317433648237550
[2025-09-19 23:37:05,936][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:23,552][root][INFO] - Iteration 0, response_id 0: Objective value: 7.204851518145087
[2025-09-19 23:37:23,552][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:26,635][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:26,638][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:26,641][root][INFO] - LLM usage: prompt_tokens = 254799, completion_tokens = 85436
[2025-09-19 23:37:26,641][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:27,817][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:27,821][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:27,828][root][INFO] - LLM usage: prompt_tokens = 255550, completion_tokens = 85521
[2025-09-19 23:37:27,830][root][INFO] - Iteration 0: Running Code 1400096994745669936
[2025-09-19 23:37:28,333][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:31,571][root][INFO] - Iteration 0, response_id 0: Objective value: 8.267566822757987
[2025-09-19 23:37:31,585][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:34,285][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:34,290][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:34,300][root][INFO] - LLM usage: prompt_tokens = 257329, completion_tokens = 86092
[2025-09-19 23:37:34,302][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:36,397][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:36,399][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:36,401][root][INFO] - LLM usage: prompt_tokens = 258092, completion_tokens = 86209
[2025-09-19 23:37:36,401][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:39,690][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:39,694][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:39,705][root][INFO] - LLM usage: prompt_tokens = 259871, completion_tokens = 86906
[2025-09-19 23:37:39,707][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:40,800][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:40,804][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:40,809][root][INFO] - LLM usage: prompt_tokens = 260232, completion_tokens = 87002
[2025-09-19 23:37:40,811][root][INFO] - Iteration 0: Running Code -7939379468480261376
[2025-09-19 23:37:41,326][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:37:41,362][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:37:41,363][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:44,000][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:44,003][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:44,006][root][INFO] - LLM usage: prompt_tokens = 262011, completion_tokens = 87573
[2025-09-19 23:37:44,007][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:45,081][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:45,084][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:45,086][root][INFO] - LLM usage: prompt_tokens = 262769, completion_tokens = 87666
[2025-09-19 23:37:45,087][root][INFO] - Iteration 0: Running Code 4413819531667054584
[2025-09-19 23:37:45,575][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:48,775][root][INFO] - Iteration 0, response_id 0: Objective value: 6.887111190418691
[2025-09-19 23:37:48,777][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:50,668][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:50,672][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:50,678][root][INFO] - LLM usage: prompt_tokens = 263743, completion_tokens = 88017
[2025-09-19 23:37:50,679][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:52,242][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:52,245][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:52,246][root][INFO] - LLM usage: prompt_tokens = 264286, completion_tokens = 88129
[2025-09-19 23:37:52,247][root][INFO] - Iteration 0: Running Code -8407015118469375378
[2025-09-19 23:37:52,757][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:54,668][root][INFO] - Iteration 0, response_id 0: Objective value: 15.64074448104904
[2025-09-19 23:37:54,669][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:56,771][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:56,773][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:56,775][root][INFO] - LLM usage: prompt_tokens = 264907, completion_tokens = 88465
[2025-09-19 23:37:56,775][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:37:58,168][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:37:58,172][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:37:58,178][root][INFO] - LLM usage: prompt_tokens = 265435, completion_tokens = 88580
[2025-09-19 23:37:58,180][root][INFO] - Iteration 0: Running Code 3758872481670858848
[2025-09-19 23:37:58,678][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:37:59,698][root][INFO] - Iteration 0, response_id 0: Objective value: 33.73603794771719
[2025-09-19 23:37:59,698][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:01,317][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:01,321][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:01,328][root][INFO] - LLM usage: prompt_tokens = 266037, completion_tokens = 88856
[2025-09-19 23:38:01,329][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:02,667][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:02,671][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:02,672][root][INFO] - LLM usage: prompt_tokens = 266505, completion_tokens = 88978
[2025-09-19 23:38:02,673][root][INFO] - Iteration 0: Running Code 4123713828142366542
[2025-09-19 23:38:03,165][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:04,455][root][INFO] - Iteration 0, response_id 0: Objective value: 7.024083164746109
[2025-09-19 23:38:04,466][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:06,308][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:06,312][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:06,320][root][INFO] - LLM usage: prompt_tokens = 267479, completion_tokens = 89304
[2025-09-19 23:38:06,321][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:07,497][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:07,498][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:07,500][root][INFO] - LLM usage: prompt_tokens = 267997, completion_tokens = 89409
[2025-09-19 23:38:07,501][root][INFO] - Iteration 0: Running Code 4450981648407436993
[2025-09-19 23:38:07,991][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:09,940][root][INFO] - Iteration 0, response_id 0: Objective value: 7.830502670760037
[2025-09-19 23:38:09,942][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:12,143][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:12,145][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:12,148][root][INFO] - LLM usage: prompt_tokens = 269112, completion_tokens = 89828
[2025-09-19 23:38:12,149][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:13,352][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:13,353][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:13,354][root][INFO] - LLM usage: prompt_tokens = 269723, completion_tokens = 89921
[2025-09-19 23:38:13,355][root][INFO] - Iteration 0: Running Code -310373732394299914
[2025-09-19 23:38:13,864][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:16,545][root][INFO] - Iteration 0, response_id 0: Objective value: 16.641165590393115
[2025-09-19 23:38:16,546][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:19,082][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:19,083][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:19,085][root][INFO] - LLM usage: prompt_tokens = 270306, completion_tokens = 90341
[2025-09-19 23:38:19,086][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:20,170][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:20,172][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:20,175][root][INFO] - LLM usage: prompt_tokens = 270918, completion_tokens = 90435
[2025-09-19 23:38:20,175][root][INFO] - Iteration 0: Running Code -3992684847173574407
[2025-09-19 23:38:20,722][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:20,790][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:38:20,790][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:22,612][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:22,614][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:22,615][root][INFO] - LLM usage: prompt_tokens = 271501, completion_tokens = 90755
[2025-09-19 23:38:22,616][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:23,860][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:23,864][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:23,871][root][INFO] - LLM usage: prompt_tokens = 272013, completion_tokens = 90847
[2025-09-19 23:38:23,873][root][INFO] - Iteration 0: Running Code -3723779793558561090
[2025-09-19 23:38:24,389][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:25,613][root][INFO] - Iteration 0, response_id 0: Objective value: 7.040580196745701
[2025-09-19 23:38:25,614][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:30,387][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:30,389][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:30,391][root][INFO] - LLM usage: prompt_tokens = 272577, completion_tokens = 91124
[2025-09-19 23:38:30,391][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:31,761][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:31,766][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:31,772][root][INFO] - LLM usage: prompt_tokens = 273046, completion_tokens = 91220
[2025-09-19 23:38:31,775][root][INFO] - Iteration 0: Running Code 3542075180069012604
[2025-09-19 23:38:32,275][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:33,554][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0913463530466725
[2025-09-19 23:38:33,569][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:35,604][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:35,609][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:35,616][root][INFO] - LLM usage: prompt_tokens = 274409, completion_tokens = 91545
[2025-09-19 23:38:35,617][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:37,038][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:37,040][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:37,042][root][INFO] - LLM usage: prompt_tokens = 274926, completion_tokens = 91682
[2025-09-19 23:38:37,042][root][INFO] - Iteration 0: Running Code -6784028326078845809
[2025-09-19 23:38:37,556][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:38,834][root][INFO] - Iteration 0, response_id 0: Objective value: 19.887026031569466
[2025-09-19 23:38:38,835][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:40,789][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:40,793][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:40,801][root][INFO] - LLM usage: prompt_tokens = 275904, completion_tokens = 92032
[2025-09-19 23:38:40,802][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:42,174][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:42,179][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:42,184][root][INFO] - LLM usage: prompt_tokens = 276446, completion_tokens = 92162
[2025-09-19 23:38:42,186][root][INFO] - Iteration 0: Running Code -870589708137715412
[2025-09-19 23:38:42,730][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:45,452][root][INFO] - Iteration 0, response_id 0: Objective value: 6.72686170173612
[2025-09-19 23:38:45,453][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:47,348][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:47,350][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:47,353][root][INFO] - LLM usage: prompt_tokens = 277455, completion_tokens = 92489
[2025-09-19 23:38:47,353][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:48,346][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:48,350][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:48,356][root][INFO] - LLM usage: prompt_tokens = 277969, completion_tokens = 92572
[2025-09-19 23:38:48,359][root][INFO] - Iteration 0: Running Code 52833535176955821
[2025-09-19 23:38:48,875][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:50,526][root][INFO] - Iteration 0, response_id 0: Objective value: 6.452120749742063
[2025-09-19 23:38:50,527][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:52,229][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:52,233][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:52,240][root][INFO] - LLM usage: prompt_tokens = 278551, completion_tokens = 92920
[2025-09-19 23:38:52,241][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:53,696][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:53,701][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:53,706][root][INFO] - LLM usage: prompt_tokens = 279091, completion_tokens = 93034
[2025-09-19 23:38:53,709][root][INFO] - Iteration 0: Running Code -4376457944714572642
[2025-09-19 23:38:54,203][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:38:56,613][root][INFO] - Iteration 0, response_id 0: Objective value: 32.42417232254321
[2025-09-19 23:38:56,613][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:58,515][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:58,517][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:58,519][root][INFO] - LLM usage: prompt_tokens = 279654, completion_tokens = 93372
[2025-09-19 23:38:58,520][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:38:59,770][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:38:59,772][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:38:59,774][root][INFO] - LLM usage: prompt_tokens = 280179, completion_tokens = 93487
[2025-09-19 23:38:59,775][root][INFO] - Iteration 0: Running Code -2518904510869947999
[2025-09-19 23:39:00,272][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:02,704][root][INFO] - Iteration 0, response_id 0: Objective value: 8.381171989196782
[2025-09-19 23:39:02,719][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:04,939][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:04,940][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:04,942][root][INFO] - LLM usage: prompt_tokens = 281517, completion_tokens = 93855
[2025-09-19 23:39:04,943][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:06,169][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:06,173][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:06,179][root][INFO] - LLM usage: prompt_tokens = 282077, completion_tokens = 93960
[2025-09-19 23:39:06,181][root][INFO] - Iteration 0: Running Code 2392859264930005475
[2025-09-19 23:39:06,673][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:09,107][root][INFO] - Iteration 0, response_id 0: Objective value: 6.625254691116391
[2025-09-19 23:39:09,109][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:11,002][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:11,005][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:11,012][root][INFO] - LLM usage: prompt_tokens = 283047, completion_tokens = 94353
[2025-09-19 23:39:11,014][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:12,314][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:12,318][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:12,324][root][INFO] - LLM usage: prompt_tokens = 283632, completion_tokens = 94476
[2025-09-19 23:39:12,326][root][INFO] - Iteration 0: Running Code -1340252623732674943
[2025-09-19 23:39:12,855][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:15,104][root][INFO] - Iteration 0, response_id 0: Objective value: 6.941358743423704
[2025-09-19 23:39:15,105][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:17,165][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:17,169][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:17,176][root][INFO] - LLM usage: prompt_tokens = 284175, completion_tokens = 94854
[2025-09-19 23:39:17,177][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:18,412][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:18,416][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:18,418][root][INFO] - LLM usage: prompt_tokens = 284745, completion_tokens = 94965
[2025-09-19 23:39:18,418][root][INFO] - Iteration 0: Running Code 1421742937770561989
[2025-09-19 23:39:18,906][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:18,946][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:39:18,947][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:20,721][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:20,724][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:20,726][root][INFO] - LLM usage: prompt_tokens = 285288, completion_tokens = 95284
[2025-09-19 23:39:20,727][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:21,999][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:22,004][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:22,009][root][INFO] - LLM usage: prompt_tokens = 285799, completion_tokens = 95385
[2025-09-19 23:39:22,012][root][INFO] - Iteration 0: Running Code 1576752102663376734
[2025-09-19 23:39:22,530][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:24,601][root][INFO] - Iteration 0, response_id 0: Objective value: 8.061439681245977
[2025-09-19 23:39:24,602][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:26,476][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:26,478][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:26,480][root][INFO] - LLM usage: prompt_tokens = 286323, completion_tokens = 95704
[2025-09-19 23:39:26,481][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:27,940][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:27,944][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:27,950][root][INFO] - LLM usage: prompt_tokens = 286834, completion_tokens = 95805
[2025-09-19 23:39:27,952][root][INFO] - Iteration 0: Running Code 819326960121431665
[2025-09-19 23:39:28,489][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:29,886][root][INFO] - Iteration 0, response_id 0: Objective value: 7.50694664887271
[2025-09-19 23:39:29,897][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:31,776][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:31,778][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:31,780][root][INFO] - LLM usage: prompt_tokens = 287664, completion_tokens = 96106
[2025-09-19 23:39:31,781][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:32,917][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:32,921][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:32,927][root][INFO] - LLM usage: prompt_tokens = 288157, completion_tokens = 96182
[2025-09-19 23:39:32,929][root][INFO] - Iteration 0: Running Code -3267448470902005058
[2025-09-19 23:39:33,428][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:34,781][root][INFO] - Iteration 0, response_id 0: Objective value: 7.820639809099885
[2025-09-19 23:39:34,783][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:36,664][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:36,674][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:36,683][root][INFO] - LLM usage: prompt_tokens = 291032, completion_tokens = 96453
[2025-09-19 23:39:36,684][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:38,019][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:38,023][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:38,029][root][INFO] - LLM usage: prompt_tokens = 291495, completion_tokens = 96550
[2025-09-19 23:39:38,031][root][INFO] - Iteration 0: Running Code 3564906928092098522
[2025-09-19 23:39:38,532][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:39,302][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:39:39,303][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:40,847][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:40,850][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:40,852][root][INFO] - LLM usage: prompt_tokens = 292231, completion_tokens = 96805
[2025-09-19 23:39:40,852][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:41,816][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:41,820][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:41,826][root][INFO] - LLM usage: prompt_tokens = 292678, completion_tokens = 96886
[2025-09-19 23:39:41,828][root][INFO] - Iteration 0: Running Code 935255967365579098
[2025-09-19 23:39:42,337][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:43,583][root][INFO] - Iteration 0, response_id 0: Objective value: 6.890383103977944
[2025-09-19 23:39:43,584][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:45,002][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:45,007][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:45,013][root][INFO] - LLM usage: prompt_tokens = 293514, completion_tokens = 97151
[2025-09-19 23:39:45,015][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:45,968][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:45,969][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:45,970][root][INFO] - LLM usage: prompt_tokens = 293971, completion_tokens = 97244
[2025-09-19 23:39:45,970][root][INFO] - Iteration 0: Running Code 3850889914493544243
[2025-09-19 23:39:46,456][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:39:47,697][root][INFO] - Iteration 0, response_id 0: Objective value: 6.8455817332096265
[2025-09-19 23:39:47,698][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:49,291][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:49,292][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:49,294][root][INFO] - LLM usage: prompt_tokens = 294454, completion_tokens = 97510
[2025-09-19 23:39:49,294][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:50,726][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:50,728][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:50,729][root][INFO] - LLM usage: prompt_tokens = 294954, completion_tokens = 97600
[2025-09-19 23:39:50,730][root][INFO] - Iteration 0: Running Code 2610162440135807642
[2025-09-19 23:39:51,221][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:39:51,261][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:39:51,263][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:53,419][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:53,424][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:53,431][root][INFO] - LLM usage: prompt_tokens = 295437, completion_tokens = 98010
[2025-09-19 23:39:53,433][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:54,827][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:54,831][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:54,831][root][INFO] - LLM usage: prompt_tokens = 295706, completion_tokens = 98142
[2025-09-19 23:39:54,833][root][INFO] - Iteration 0: Running Code 7933494222087287344
[2025-09-19 23:39:55,328][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:39:55,365][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:39:55,366][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:57,572][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:57,573][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:57,576][root][INFO] - LLM usage: prompt_tokens = 296189, completion_tokens = 98494
[2025-09-19 23:39:57,576][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:39:58,738][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:39:58,743][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:39:58,748][root][INFO] - LLM usage: prompt_tokens = 296733, completion_tokens = 98597
[2025-09-19 23:39:58,749][root][INFO] - Iteration 0: Running Code 6849498063415419412
[2025-09-19 23:39:59,238][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:40:00,933][root][INFO] - Iteration 0, response_id 0: Objective value: 15.78818025102999
[2025-09-19 23:40:00,934][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:02,252][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:02,253][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:02,255][root][INFO] - LLM usage: prompt_tokens = 297197, completion_tokens = 98806
[2025-09-19 23:40:02,256][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:03,225][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:03,229][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:03,230][root][INFO] - LLM usage: prompt_tokens = 297598, completion_tokens = 98902
[2025-09-19 23:40:03,230][root][INFO] - Iteration 0: Running Code 1933992631158707989
[2025-09-19 23:40:03,823][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:40:05,030][root][INFO] - Iteration 0, response_id 0: Objective value: 13.758800935562473
[2025-09-19 23:40:05,046][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:06,499][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:06,503][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:06,511][root][INFO] - LLM usage: prompt_tokens = 298513, completion_tokens = 99136
[2025-09-19 23:40:06,513][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:07,575][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:07,576][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:07,577][root][INFO] - LLM usage: prompt_tokens = 298939, completion_tokens = 99231
[2025-09-19 23:40:07,577][root][INFO] - Iteration 0: Running Code 1173783774744316996
[2025-09-19 23:40:08,068][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:40:09,316][root][INFO] - Iteration 0, response_id 0: Objective value: 6.8455817332096265
[2025-09-19 23:40:09,319][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:11,210][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:11,212][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:11,215][root][INFO] - LLM usage: prompt_tokens = 300634, completion_tokens = 99484
[2025-09-19 23:40:11,217][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:12,310][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:12,314][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:12,320][root][INFO] - LLM usage: prompt_tokens = 301075, completion_tokens = 99573
[2025-09-19 23:40:12,323][root][INFO] - Iteration 0: Running Code 7629138823506980575
[2025-09-19 23:40:12,860][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:40:12,898][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:40:12,899][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:14,973][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:14,975][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:14,980][root][INFO] - LLM usage: prompt_tokens = 302058, completion_tokens = 99891
[2025-09-19 23:40:14,981][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:16,242][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:16,246][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:16,247][root][INFO] - LLM usage: prompt_tokens = 302362, completion_tokens = 100000
[2025-09-19 23:40:16,248][root][INFO] - Iteration 0: Running Code 109339677094849548
[2025-09-19 23:40:16,738][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:40:16,774][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:40:16,774][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:19,895][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:19,898][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:19,901][root][INFO] - LLM usage: prompt_tokens = 303605, completion_tokens = 100387
[2025-09-19 23:40:19,901][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:40:20,971][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:40:20,975][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:40:20,981][root][INFO] - LLM usage: prompt_tokens = 304184, completion_tokens = 100483
[2025-09-19 23:40:20,984][root][INFO] - Iteration 0: Running Code 7231036475971834554
[2025-09-19 23:40:21,499][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:01,548][root][INFO] - Iteration 0, response_id 0: Objective value: 6.682533352162719
[2025-09-19 23:41:01,549][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:03,410][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:03,414][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:03,422][root][INFO] - LLM usage: prompt_tokens = 305173, completion_tokens = 100810
[2025-09-19 23:41:03,423][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:04,457][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:04,461][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:04,467][root][INFO] - LLM usage: prompt_tokens = 305692, completion_tokens = 100909
[2025-09-19 23:41:04,470][root][INFO] - Iteration 0: Running Code 2440169152305350965
[2025-09-19 23:41:04,964][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:06,072][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0984435345981725
[2025-09-19 23:41:06,073][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:07,824][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:07,829][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:07,836][root][INFO] - LLM usage: prompt_tokens = 306620, completion_tokens = 101245
[2025-09-19 23:41:07,838][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:09,377][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:09,378][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:09,380][root][INFO] - LLM usage: prompt_tokens = 307148, completion_tokens = 101344
[2025-09-19 23:41:09,381][root][INFO] - Iteration 0: Running Code -8507143588262026728
[2025-09-19 23:41:09,877][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:11,589][root][INFO] - Iteration 0, response_id 0: Objective value: 6.480617426995455
[2025-09-19 23:41:11,590][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:13,256][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:13,261][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:13,267][root][INFO] - LLM usage: prompt_tokens = 307649, completion_tokens = 101603
[2025-09-19 23:41:13,269][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:14,376][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:14,379][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:14,380][root][INFO] - LLM usage: prompt_tokens = 308100, completion_tokens = 101677
[2025-09-19 23:41:14,381][root][INFO] - Iteration 0: Running Code 515190848283576554
[2025-09-19 23:41:14,871][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:15,914][root][INFO] - Iteration 0, response_id 0: Objective value: 32.41165361976448
[2025-09-19 23:41:15,915][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:17,324][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:17,327][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:17,331][root][INFO] - LLM usage: prompt_tokens = 308582, completion_tokens = 101900
[2025-09-19 23:41:17,332][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:18,397][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:18,401][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:18,406][root][INFO] - LLM usage: prompt_tokens = 308992, completion_tokens = 101999
[2025-09-19 23:41:18,408][root][INFO] - Iteration 0: Running Code 8486327525879731142
[2025-09-19 23:41:18,893][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:19,677][root][INFO] - Iteration 0, response_id 0: Objective value: 6.730330408741212
[2025-09-19 23:41:19,694][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:21,963][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:21,977][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:21,980][root][INFO] - LLM usage: prompt_tokens = 310059, completion_tokens = 102269
[2025-09-19 23:41:21,980][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:22,878][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:22,882][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:22,887][root][INFO] - LLM usage: prompt_tokens = 310521, completion_tokens = 102336
[2025-09-19 23:41:22,889][root][INFO] - Iteration 0: Running Code 1769131575865520353
[2025-09-19 23:41:23,395][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:24,165][root][INFO] - Iteration 0, response_id 0: Objective value: 6.722124920885673
[2025-09-19 23:41:24,167][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:25,451][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:25,452][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:25,454][root][INFO] - LLM usage: prompt_tokens = 311527, completion_tokens = 102552
[2025-09-19 23:41:25,454][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:26,475][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:26,477][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:26,479][root][INFO] - LLM usage: prompt_tokens = 311935, completion_tokens = 102615
[2025-09-19 23:41:26,480][root][INFO] - Iteration 0: Running Code 6349860100478071194
[2025-09-19 23:41:26,986][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:27,792][root][INFO] - Iteration 0, response_id 0: Objective value: 7.11107559133921
[2025-09-19 23:41:27,792][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:30,165][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:30,168][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:30,172][root][INFO] - LLM usage: prompt_tokens = 312588, completion_tokens = 103029
[2025-09-19 23:41:30,173][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:31,234][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:31,238][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:31,244][root][INFO] - LLM usage: prompt_tokens = 313194, completion_tokens = 103124
[2025-09-19 23:41:31,247][root][INFO] - Iteration 0: Running Code -4708141078956315772
[2025-09-19 23:41:31,747][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:41:31,785][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:41:31,786][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:34,493][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:34,496][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:34,498][root][INFO] - LLM usage: prompt_tokens = 313847, completion_tokens = 103672
[2025-09-19 23:41:34,499][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:41:35,474][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:41:35,478][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:41:35,480][root][INFO] - LLM usage: prompt_tokens = 314587, completion_tokens = 103764
[2025-09-19 23:41:35,481][root][INFO] - Iteration 0: Running Code 2657685098591326372
[2025-09-19 23:41:35,987][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:42:17,286][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0875411228841045
[2025-09-19 23:42:17,287][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:42:19,296][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:42:19,300][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:42:19,303][root][INFO] - LLM usage: prompt_tokens = 315221, completion_tokens = 104134
[2025-09-19 23:42:19,304][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:42:20,665][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:42:20,669][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:42:20,676][root][INFO] - LLM usage: prompt_tokens = 315783, completion_tokens = 104217
[2025-09-19 23:42:20,678][root][INFO] - Iteration 0: Running Code 1443990895568891615
[2025-09-19 23:42:21,162][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:43:01,551][root][INFO] - Iteration 0, response_id 0: Objective value: 6.733948183927218
[2025-09-19 23:43:01,561][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:03,463][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:03,468][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:03,476][root][INFO] - LLM usage: prompt_tokens = 316870, completion_tokens = 104481
[2025-09-19 23:43:03,478][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:06,138][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:06,139][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:06,141][root][INFO] - LLM usage: prompt_tokens = 317326, completion_tokens = 104575
[2025-09-19 23:43:06,141][root][INFO] - Iteration 0: Running Code -7842529348414416240
[2025-09-19 23:43:06,669][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:43:07,807][root][INFO] - Iteration 0, response_id 0: Objective value: 6.603579502235833
[2025-09-19 23:43:07,808][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:10,996][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:10,998][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:11,001][root][INFO] - LLM usage: prompt_tokens = 317966, completion_tokens = 105105
[2025-09-19 23:43:11,001][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:12,210][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:12,211][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:12,213][root][INFO] - LLM usage: prompt_tokens = 318683, completion_tokens = 105193
[2025-09-19 23:43:12,213][root][INFO] - Iteration 0: Running Code -6277103930202754972
[2025-09-19 23:43:12,756][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:43:54,349][root][INFO] - Iteration 0, response_id 0: Objective value: 6.783754347083877
[2025-09-19 23:43:54,349][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:56,026][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:56,031][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:56,038][root][INFO] - LLM usage: prompt_tokens = 319304, completion_tokens = 105446
[2025-09-19 23:43:56,040][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:43:57,065][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:43:57,069][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:43:57,070][root][INFO] - LLM usage: prompt_tokens = 319744, completion_tokens = 105532
[2025-09-19 23:43:57,071][root][INFO] - Iteration 0: Running Code 997148155596288631
[2025-09-19 23:43:57,542][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:43:58,280][root][INFO] - Iteration 0, response_id 0: Objective value: 8.046510031014297
[2025-09-19 23:43:58,294][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:44:00,056][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:44:00,057][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:44:00,059][root][INFO] - LLM usage: prompt_tokens = 320876, completion_tokens = 105959
[2025-09-19 23:44:00,060][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:44:00,976][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:44:00,980][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:44:00,981][root][INFO] - LLM usage: prompt_tokens = 321495, completion_tokens = 106045
[2025-09-19 23:44:00,982][root][INFO] - Iteration 0: Running Code -2889496219832984591
[2025-09-19 23:44:01,467][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:44:42,003][root][INFO] - Iteration 0, response_id 0: Objective value: 6.757965322525468
[2025-09-19 23:44:42,005][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:44:45,170][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:44:45,173][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:44:45,176][root][INFO] - LLM usage: prompt_tokens = 322728, completion_tokens = 106688
[2025-09-19 23:44:45,176][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:44:46,474][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:44:46,476][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:44:46,479][root][INFO] - LLM usage: prompt_tokens = 323563, completion_tokens = 106778
[2025-09-19 23:44:46,481][root][INFO] - Iteration 0: Running Code 2184097597166747531
[2025-09-19 23:44:46,983][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:45:29,452][root][INFO] - Iteration 0, response_id 0: Objective value: 6.487127555401196
[2025-09-19 23:45:29,453][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:45:33,010][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:45:33,013][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:45:33,016][root][INFO] - LLM usage: prompt_tokens = 324369, completion_tokens = 107578
[2025-09-19 23:45:33,016][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:45:34,480][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:45:34,484][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:45:34,491][root][INFO] - LLM usage: prompt_tokens = 325361, completion_tokens = 107660
[2025-09-19 23:45:34,494][root][INFO] - Iteration 0: Running Code -7897293952600887383
[2025-09-19 23:45:34,982][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:46:17,133][root][INFO] - Iteration 0, response_id 0: Objective value: 7.160194146677304
[2025-09-19 23:46:17,134][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:46:19,607][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:46:19,608][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:46:19,610][root][INFO] - LLM usage: prompt_tokens = 326148, completion_tokens = 108212
[2025-09-19 23:46:19,610][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:46:20,762][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:46:20,763][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:46:20,765][root][INFO] - LLM usage: prompt_tokens = 326887, completion_tokens = 108313
[2025-09-19 23:46:20,766][root][INFO] - Iteration 0: Running Code -4429590166533217889
[2025-09-19 23:46:21,255][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:47:03,207][root][INFO] - Iteration 0, response_id 0: Objective value: 6.848191933000908
[2025-09-19 23:47:03,220][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:06,189][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:06,194][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:06,204][root][INFO] - LLM usage: prompt_tokens = 328185, completion_tokens = 108882
[2025-09-19 23:47:06,204][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:07,315][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:07,316][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:07,318][root][INFO] - LLM usage: prompt_tokens = 328946, completion_tokens = 109004
[2025-09-19 23:47:07,318][root][INFO] - Iteration 0: Running Code 1431529013914517346
[2025-09-19 23:47:07,856][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:47:49,541][root][INFO] - Iteration 0, response_id 0: Objective value: 7.222722626530339
[2025-09-19 23:47:49,543][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:51,492][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:51,494][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:51,496][root][INFO] - LLM usage: prompt_tokens = 329900, completion_tokens = 109309
[2025-09-19 23:47:51,496][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:53,031][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:53,032][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:53,034][root][INFO] - LLM usage: prompt_tokens = 330397, completion_tokens = 109392
[2025-09-19 23:47:53,035][root][INFO] - Iteration 0: Running Code 8275671625636518
[2025-09-19 23:47:53,517][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:47:55,105][root][INFO] - Iteration 0, response_id 0: Objective value: 8.230446418925915
[2025-09-19 23:47:55,106][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:57,208][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:57,212][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:57,219][root][INFO] - LLM usage: prompt_tokens = 330847, completion_tokens = 109776
[2025-09-19 23:47:57,221][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:47:58,395][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:47:58,398][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:47:58,400][root][INFO] - LLM usage: prompt_tokens = 331423, completion_tokens = 109888
[2025-09-19 23:47:58,401][root][INFO] - Iteration 0: Running Code 8200823040537278417
[2025-09-19 23:47:58,882][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:48:24,840][root][INFO] - Iteration 0, response_id 0: Objective value: 6.6934057208365845
[2025-09-19 23:48:24,841][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:26,686][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:26,690][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:26,692][root][INFO] - LLM usage: prompt_tokens = 331854, completion_tokens = 110108
[2025-09-19 23:48:26,692][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:27,918][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:27,922][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:27,927][root][INFO] - LLM usage: prompt_tokens = 332266, completion_tokens = 110195
[2025-09-19 23:48:27,930][root][INFO] - Iteration 0: Running Code -2553330861248900353
[2025-09-19 23:48:28,415][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:48:29,216][root][INFO] - Iteration 0, response_id 0: Objective value: 7.703494300526842
[2025-09-19 23:48:29,230][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:32,253][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:32,258][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:32,265][root][INFO] - LLM usage: prompt_tokens = 333208, completion_tokens = 110646
[2025-09-19 23:48:32,266][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:33,719][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:33,723][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:33,725][root][INFO] - LLM usage: prompt_tokens = 333858, completion_tokens = 110756
[2025-09-19 23:48:33,725][root][INFO] - Iteration 0: Running Code 5346681306549109521
[2025-09-19 23:48:34,223][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:48:34,258][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:48:34,259][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:36,338][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:36,344][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:36,352][root][INFO] - LLM usage: prompt_tokens = 334800, completion_tokens = 111185
[2025-09-19 23:48:36,354][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:48:37,386][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:48:37,390][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:48:37,396][root][INFO] - LLM usage: prompt_tokens = 335421, completion_tokens = 111278
[2025-09-19 23:48:37,398][root][INFO] - Iteration 0: Running Code -4489640704369252364
[2025-09-19 23:48:37,899][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:49:19,377][root][INFO] - Iteration 0, response_id 0: Objective value: 6.8324009712140565
[2025-09-19 23:49:19,379][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:21,130][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:21,131][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:21,133][root][INFO] - LLM usage: prompt_tokens = 336574, completion_tokens = 111534
[2025-09-19 23:49:21,134][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:22,296][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:22,300][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:22,305][root][INFO] - LLM usage: prompt_tokens = 337022, completion_tokens = 111620
[2025-09-19 23:49:22,308][root][INFO] - Iteration 0: Running Code 7503950365420495867
[2025-09-19 23:49:23,047][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:49:23,860][root][INFO] - Iteration 0, response_id 0: Objective value: 7.897592540742666
[2025-09-19 23:49:23,861][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:25,640][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:25,645][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:25,653][root][INFO] - LLM usage: prompt_tokens = 338122, completion_tokens = 111951
[2025-09-19 23:49:25,654][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:27,653][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:27,656][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:27,658][root][INFO] - LLM usage: prompt_tokens = 338645, completion_tokens = 112050
[2025-09-19 23:49:27,659][root][INFO] - Iteration 0: Running Code -3806972590038450082
[2025-09-19 23:49:28,418][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:49:30,173][root][INFO] - Iteration 0, response_id 0: Objective value: 6.813448749813677
[2025-09-19 23:49:30,174][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:32,874][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:32,877][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:32,887][root][INFO] - LLM usage: prompt_tokens = 339897, completion_tokens = 112678
[2025-09-19 23:49:32,889][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:49:34,207][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:49:34,211][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:49:34,213][root][INFO] - LLM usage: prompt_tokens = 340717, completion_tokens = 112801
[2025-09-19 23:49:34,213][root][INFO] - Iteration 0: Running Code 1301600979769673931
[2025-09-19 23:49:34,696][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:50:17,041][root][INFO] - Iteration 0, response_id 0: Objective value: 7.276950968118095
[2025-09-19 23:50:17,042][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:50:20,364][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:50:20,368][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:50:20,370][root][INFO] - LLM usage: prompt_tokens = 341609, completion_tokens = 113462
[2025-09-19 23:50:20,371][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:50:21,522][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:50:21,526][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:50:21,532][root][INFO] - LLM usage: prompt_tokens = 342504, completion_tokens = 113552
[2025-09-19 23:50:21,535][root][INFO] - Iteration 0: Running Code 8055156800445096998
[2025-09-19 23:50:22,033][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:50:22,068][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:50:22,069][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:50:25,187][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:50:25,191][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:50:25,199][root][INFO] - LLM usage: prompt_tokens = 343396, completion_tokens = 114296
[2025-09-19 23:50:25,200][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:50:26,394][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:50:26,395][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:50:26,397][root][INFO] - LLM usage: prompt_tokens = 344332, completion_tokens = 114386
[2025-09-19 23:50:26,398][root][INFO] - Iteration 0: Running Code 5317307439169622084
[2025-09-19 23:50:26,879][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:51:10,256][root][INFO] - Iteration 0, response_id 0: Objective value: 8.642912268130392
[2025-09-19 23:51:10,257][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:51:13,009][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:51:13,012][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:51:13,014][root][INFO] - LLM usage: prompt_tokens = 345205, completion_tokens = 115016
[2025-09-19 23:51:13,014][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:51:14,103][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:51:14,104][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:51:14,106][root][INFO] - LLM usage: prompt_tokens = 346027, completion_tokens = 115114
[2025-09-19 23:51:14,108][root][INFO] - Iteration 0: Running Code 2086622611487974803
[2025-09-19 23:51:14,588][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:51:57,375][root][INFO] - Iteration 0, response_id 0: Objective value: 7.546902427348586
[2025-09-19 23:51:57,394][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:00,274][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:00,279][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:00,289][root][INFO] - LLM usage: prompt_tokens = 348023, completion_tokens = 115768
[2025-09-19 23:52:00,290][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:01,503][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:01,507][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:01,514][root][INFO] - LLM usage: prompt_tokens = 348864, completion_tokens = 115888
[2025-09-19 23:52:01,516][root][INFO] - Iteration 0: Running Code -2507863482260694432
[2025-09-19 23:52:02,034][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:52:45,416][root][INFO] - Iteration 0, response_id 0: Objective value: 6.528065855049659
[2025-09-19 23:52:45,418][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:48,146][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:48,151][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:48,160][root][INFO] - LLM usage: prompt_tokens = 350089, completion_tokens = 116436
[2025-09-19 23:52:48,161][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:49,224][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:49,228][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:49,234][root][INFO] - LLM usage: prompt_tokens = 350829, completion_tokens = 116513
[2025-09-19 23:52:49,236][root][INFO] - Iteration 0: Running Code 5618821602511244756
[2025-09-19 23:52:49,752][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:52:53,009][root][INFO] - Iteration 0, response_id 0: Objective value: 9.421674061928211
[2025-09-19 23:52:53,010][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:55,536][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:55,537][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:55,539][root][INFO] - LLM usage: prompt_tokens = 351348, completion_tokens = 116790
[2025-09-19 23:52:55,539][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:56,637][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:56,641][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:56,647][root][INFO] - LLM usage: prompt_tokens = 351863, completion_tokens = 116872
[2025-09-19 23:52:56,649][root][INFO] - Iteration 0: Running Code 1593325808582880809
[2025-09-19 23:52:57,156][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:52:57,195][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:52:57,196][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:52:59,446][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:52:59,448][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:52:59,452][root][INFO] - LLM usage: prompt_tokens = 352382, completion_tokens = 117289
[2025-09-19 23:52:59,453][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:00,617][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:00,621][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:00,627][root][INFO] - LLM usage: prompt_tokens = 352991, completion_tokens = 117394
[2025-09-19 23:53:00,630][root][INFO] - Iteration 0: Running Code 360153619140507359
[2025-09-19 23:53:01,127][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:02,916][root][INFO] - Iteration 0, response_id 0: Objective value: 6.619931351141558
[2025-09-19 23:53:02,917][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:07,649][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:07,650][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:07,652][root][INFO] - LLM usage: prompt_tokens = 353491, completion_tokens = 117703
[2025-09-19 23:53:07,652][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:08,790][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:08,794][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:08,800][root][INFO] - LLM usage: prompt_tokens = 353992, completion_tokens = 117789
[2025-09-19 23:53:08,802][root][INFO] - Iteration 0: Running Code -6013102332692091251
[2025-09-19 23:53:09,309][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:10,683][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9591779634395055
[2025-09-19 23:53:10,695][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:12,808][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:12,809][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:12,812][root][INFO] - LLM usage: prompt_tokens = 355190, completion_tokens = 118223
[2025-09-19 23:53:12,812][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:13,759][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:13,762][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:13,767][root][INFO] - LLM usage: prompt_tokens = 355816, completion_tokens = 118309
[2025-09-19 23:53:13,769][root][INFO] - Iteration 0: Running Code 9199138047126866382
[2025-09-19 23:53:14,260][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:16,610][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0758313887321
[2025-09-19 23:53:16,611][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:19,362][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:19,364][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:19,369][root][INFO] - LLM usage: prompt_tokens = 356473, completion_tokens = 118804
[2025-09-19 23:53:19,370][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:20,500][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:20,504][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:20,510][root][INFO] - LLM usage: prompt_tokens = 357160, completion_tokens = 118920
[2025-09-19 23:53:20,513][root][INFO] - Iteration 0: Running Code 9215864643840554937
[2025-09-19 23:53:21,009][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:21,046][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:53:21,047][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:23,473][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:23,475][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:23,477][root][INFO] - LLM usage: prompt_tokens = 357817, completion_tokens = 119372
[2025-09-19 23:53:23,477][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:24,733][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:24,738][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:24,744][root][INFO] - LLM usage: prompt_tokens = 358461, completion_tokens = 119466
[2025-09-19 23:53:24,746][root][INFO] - Iteration 0: Running Code -4739916503531098457
[2025-09-19 23:53:25,235][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:25,273][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:53:25,273][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:27,841][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:27,843][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:27,845][root][INFO] - LLM usage: prompt_tokens = 359118, completion_tokens = 119943
[2025-09-19 23:53:27,846][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:29,076][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:29,080][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:29,086][root][INFO] - LLM usage: prompt_tokens = 359787, completion_tokens = 120038
[2025-09-19 23:53:29,088][root][INFO] - Iteration 0: Running Code -1573928328130127132
[2025-09-19 23:53:29,578][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:29,614][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:53:29,615][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:31,818][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:31,822][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:31,830][root][INFO] - LLM usage: prompt_tokens = 360425, completion_tokens = 120484
[2025-09-19 23:53:31,831][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:33,201][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:33,205][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:33,210][root][INFO] - LLM usage: prompt_tokens = 360706, completion_tokens = 120594
[2025-09-19 23:53:33,212][root][INFO] - Iteration 0: Running Code -4993950073224723305
[2025-09-19 23:53:33,708][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:53:33,744][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:53:33,744][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:35,463][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:35,467][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:35,474][root][INFO] - LLM usage: prompt_tokens = 361344, completion_tokens = 120912
[2025-09-19 23:53:35,476][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:36,375][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:36,379][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:36,384][root][INFO] - LLM usage: prompt_tokens = 361854, completion_tokens = 120979
[2025-09-19 23:53:36,387][root][INFO] - Iteration 0: Running Code 7579637803922375695
[2025-09-19 23:53:36,889][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:39,266][root][INFO] - Iteration 0, response_id 0: Objective value: 6.821796033625048
[2025-09-19 23:53:39,280][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:41,495][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:41,496][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:41,498][root][INFO] - LLM usage: prompt_tokens = 362869, completion_tokens = 121325
[2025-09-19 23:53:41,499][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:42,420][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:42,421][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:42,423][root][INFO] - LLM usage: prompt_tokens = 363407, completion_tokens = 121416
[2025-09-19 23:53:42,424][root][INFO] - Iteration 0: Running Code 5276222968659749361
[2025-09-19 23:53:42,955][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:44,751][root][INFO] - Iteration 0, response_id 0: Objective value: 6.619931351141558
[2025-09-19 23:53:44,754][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:46,820][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:46,824][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:46,832][root][INFO] - LLM usage: prompt_tokens = 364416, completion_tokens = 121841
[2025-09-19 23:53:46,834][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:47,896][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:47,900][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:47,901][root][INFO] - LLM usage: prompt_tokens = 365033, completion_tokens = 121941
[2025-09-19 23:53:47,902][root][INFO] - Iteration 0: Running Code -4597684893971145362
[2025-09-19 23:53:48,374][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:50,683][root][INFO] - Iteration 0, response_id 0: Objective value: 7.706275892469741
[2025-09-19 23:53:50,683][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:52,564][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:52,565][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:52,566][root][INFO] - LLM usage: prompt_tokens = 365595, completion_tokens = 122294
[2025-09-19 23:53:52,567][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:53,778][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:53,782][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:53,787][root][INFO] - LLM usage: prompt_tokens = 366140, completion_tokens = 122400
[2025-09-19 23:53:53,789][root][INFO] - Iteration 0: Running Code -775972493674431242
[2025-09-19 23:53:54,288][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:53:56,349][root][INFO] - Iteration 0, response_id 0: Objective value: 7.104743324255441
[2025-09-19 23:53:56,350][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:57,707][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:57,711][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:57,717][root][INFO] - LLM usage: prompt_tokens = 366683, completion_tokens = 122662
[2025-09-19 23:53:57,719][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:53:58,788][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:53:58,790][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:53:58,791][root][INFO] - LLM usage: prompt_tokens = 367137, completion_tokens = 122766
[2025-09-19 23:53:58,792][root][INFO] - Iteration 0: Running Code 1068525777262204841
[2025-09-19 23:53:59,272][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:00,633][root][INFO] - Iteration 0, response_id 0: Objective value: 6.944258420955904
[2025-09-19 23:54:00,648][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:02,780][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:02,784][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:02,790][root][INFO] - LLM usage: prompt_tokens = 368057, completion_tokens = 123118
[2025-09-19 23:54:02,792][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:03,826][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:03,830][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:03,831][root][INFO] - LLM usage: prompt_tokens = 368601, completion_tokens = 123207
[2025-09-19 23:54:03,832][root][INFO] - Iteration 0: Running Code 7432879439056172104
[2025-09-19 23:54:04,291][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:04,329][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:54:04,330][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:06,059][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:06,064][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:06,071][root][INFO] - LLM usage: prompt_tokens = 369521, completion_tokens = 123526
[2025-09-19 23:54:06,073][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:07,435][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:07,437][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:07,438][root][INFO] - LLM usage: prompt_tokens = 370032, completion_tokens = 123622
[2025-09-19 23:54:07,439][root][INFO] - Iteration 0: Running Code 1317055422459659520
[2025-09-19 23:54:07,939][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:09,320][root][INFO] - Iteration 0, response_id 0: Objective value: 8.402846590559758
[2025-09-19 23:54:09,322][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:11,199][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:11,204][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:11,212][root][INFO] - LLM usage: prompt_tokens = 371075, completion_tokens = 124048
[2025-09-19 23:54:11,213][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:12,352][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:12,356][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:12,362][root][INFO] - LLM usage: prompt_tokens = 371693, completion_tokens = 124148
[2025-09-19 23:54:12,364][root][INFO] - Iteration 0: Running Code -4578945740622911975
[2025-09-19 23:54:13,002][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:15,223][root][INFO] - Iteration 0, response_id 0: Objective value: 6.511593905764407
[2025-09-19 23:54:15,224][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:17,413][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:17,417][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:17,425][root][INFO] - LLM usage: prompt_tokens = 372289, completion_tokens = 124584
[2025-09-19 23:54:17,425][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:18,561][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:18,565][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:18,571][root][INFO] - LLM usage: prompt_tokens = 372917, completion_tokens = 124688
[2025-09-19 23:54:18,574][root][INFO] - Iteration 0: Running Code -8180055773898286965
[2025-09-19 23:54:19,098][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:19,138][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:54:19,139][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:21,293][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:21,297][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:21,304][root][INFO] - LLM usage: prompt_tokens = 373513, completion_tokens = 125094
[2025-09-19 23:54:21,306][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:22,476][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:22,476][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:22,479][root][INFO] - LLM usage: prompt_tokens = 374111, completion_tokens = 125202
[2025-09-19 23:54:22,479][root][INFO] - Iteration 0: Running Code -1135117367920813797
[2025-09-19 23:54:22,967][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:47,870][root][INFO] - Iteration 0, response_id 0: Objective value: 9.463516180673846
[2025-09-19 23:54:47,871][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:50,257][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:50,263][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:50,270][root][INFO] - LLM usage: prompt_tokens = 374688, completion_tokens = 125536
[2025-09-19 23:54:50,272][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:51,378][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:51,379][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:51,381][root][INFO] - LLM usage: prompt_tokens = 375214, completion_tokens = 125617
[2025-09-19 23:54:51,381][root][INFO] - Iteration 0: Running Code -1249521798618768258
[2025-09-19 23:54:51,883][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:53,674][root][INFO] - Iteration 0, response_id 0: Objective value: 7.074386198676755
[2025-09-19 23:54:53,694][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:55,722][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:55,724][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:55,727][root][INFO] - LLM usage: prompt_tokens = 376631, completion_tokens = 126010
[2025-09-19 23:54:55,728][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:54:57,072][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:54:57,077][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:54:57,082][root][INFO] - LLM usage: prompt_tokens = 377216, completion_tokens = 126104
[2025-09-19 23:54:57,085][root][INFO] - Iteration 0: Running Code 7253619055206425555
[2025-09-19 23:54:57,592][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:54:59,946][root][INFO] - Iteration 0, response_id 0: Objective value: 6.710901106389624
[2025-09-19 23:54:59,948][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:01,746][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:01,751][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:01,758][root][INFO] - LLM usage: prompt_tokens = 378248, completion_tokens = 126445
[2025-09-19 23:55:01,761][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:02,836][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:02,840][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:02,846][root][INFO] - LLM usage: prompt_tokens = 378792, completion_tokens = 126528
[2025-09-19 23:55:02,848][root][INFO] - Iteration 0: Running Code -5897257098612467761
[2025-09-19 23:55:03,339][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:55:03,375][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:55:03,375][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:05,194][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:05,195][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:05,198][root][INFO] - LLM usage: prompt_tokens = 379769, completion_tokens = 126884
[2025-09-19 23:55:05,198][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:06,466][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:06,470][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:06,476][root][INFO] - LLM usage: prompt_tokens = 380330, completion_tokens = 127007
[2025-09-19 23:55:06,479][root][INFO] - Iteration 0: Running Code -7263613221143118633
[2025-09-19 23:55:06,990][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:55:07,026][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:55:07,027][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:08,933][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:08,938][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:08,946][root][INFO] - LLM usage: prompt_tokens = 381420, completion_tokens = 127418
[2025-09-19 23:55:08,948][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:10,244][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:10,248][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:10,254][root][INFO] - LLM usage: prompt_tokens = 382023, completion_tokens = 127520
[2025-09-19 23:55:10,257][root][INFO] - Iteration 0: Running Code -8247250435830624580
[2025-09-19 23:55:10,755][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:55:12,956][root][INFO] - Iteration 0, response_id 0: Objective value: 7.51223744187319
[2025-09-19 23:55:12,956][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:15,052][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:15,056][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:15,063][root][INFO] - LLM usage: prompt_tokens = 382573, completion_tokens = 127939
[2025-09-19 23:55:15,065][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:16,146][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:16,150][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:16,155][root][INFO] - LLM usage: prompt_tokens = 383184, completion_tokens = 128024
[2025-09-19 23:55:16,158][root][INFO] - Iteration 0: Running Code 931602390556285569
[2025-09-19 23:55:16,640][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:55:16,678][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:55:16,678][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:19,110][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:19,115][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:19,122][root][INFO] - LLM usage: prompt_tokens = 383734, completion_tokens = 128462
[2025-09-19 23:55:19,123][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:20,432][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:20,437][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:20,443][root][INFO] - LLM usage: prompt_tokens = 384391, completion_tokens = 128548
[2025-09-19 23:55:20,445][root][INFO] - Iteration 0: Running Code -6419408642216534356
[2025-09-19 23:55:20,940][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-19 23:55:20,977][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:55:20,977][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:23,112][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:23,117][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:23,123][root][INFO] - LLM usage: prompt_tokens = 384941, completion_tokens = 128957
[2025-09-19 23:55:23,126][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:55:24,310][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:55:24,314][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:55:24,316][root][INFO] - LLM usage: prompt_tokens = 385542, completion_tokens = 129040
[2025-09-19 23:55:24,316][root][INFO] - Iteration 0: Running Code 8688066395618858164
[2025-09-19 23:55:24,793][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:24,809][root][INFO] - Error for response_id 0: Command '['python', '-u', 'D:\\MCTS-AHD-master/problems/tsp_constructive/eval.py', '50', 'D:\\MCTS-AHD-master', 'train']' timed out after 60.0 seconds
[2025-09-19 23:56:24,809][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:26,835][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:26,838][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:26,840][root][INFO] - LLM usage: prompt_tokens = 386073, completion_tokens = 129368
[2025-09-19 23:56:26,840][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:27,806][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:27,810][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:27,816][root][INFO] - LLM usage: prompt_tokens = 386593, completion_tokens = 129440
[2025-09-19 23:56:27,818][root][INFO] - Iteration 0: Running Code 3384762233625095855
[2025-09-19 23:56:28,328][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:30,766][root][INFO] - Iteration 0, response_id 0: Objective value: 6.894733153768868
[2025-09-19 23:56:30,786][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:35,475][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:35,476][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:35,479][root][INFO] - LLM usage: prompt_tokens = 387964, completion_tokens = 129901
[2025-09-19 23:56:35,479][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:36,432][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:36,436][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:36,442][root][INFO] - LLM usage: prompt_tokens = 388617, completion_tokens = 129977
[2025-09-19 23:56:36,444][root][INFO] - Iteration 0: Running Code 2457514694749114231
[2025-09-19 23:56:36,948][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:40,109][root][INFO] - Iteration 0, response_id 0: Objective value: 12.025892080276112
[2025-09-19 23:56:40,112][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:41,886][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:41,888][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:41,890][root][INFO] - LLM usage: prompt_tokens = 389583, completion_tokens = 130317
[2025-09-19 23:56:41,890][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:43,044][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:43,046][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:43,048][root][INFO] - LLM usage: prompt_tokens = 390115, completion_tokens = 130409
[2025-09-19 23:56:43,048][root][INFO] - Iteration 0: Running Code 7411713424279773565
[2025-09-19 23:56:43,575][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:44,846][root][INFO] - Iteration 0, response_id 0: Objective value: 7.482370213744591
[2025-09-19 23:56:44,846][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:46,792][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:46,796][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:46,804][root][INFO] - LLM usage: prompt_tokens = 391205, completion_tokens = 130763
[2025-09-19 23:56:46,806][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:47,930][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:47,932][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:47,933][root][INFO] - LLM usage: prompt_tokens = 391751, completion_tokens = 130872
[2025-09-19 23:56:47,934][root][INFO] - Iteration 0: Running Code 4997019996589702680
[2025-09-19 23:56:48,459][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:50,424][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0921216399081395
[2025-09-19 23:56:50,424][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:52,576][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:52,580][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:52,582][root][INFO] - LLM usage: prompt_tokens = 392300, completion_tokens = 131306
[2025-09-19 23:56:52,582][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:53,639][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:53,642][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:53,649][root][INFO] - LLM usage: prompt_tokens = 392926, completion_tokens = 131395
[2025-09-19 23:56:53,652][root][INFO] - Iteration 0: Running Code -8347631879378928545
[2025-09-19 23:56:54,158][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:54,197][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:56:54,197][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:56,241][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:56,245][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:56,252][root][INFO] - LLM usage: prompt_tokens = 393475, completion_tokens = 131781
[2025-09-19 23:56:56,254][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:56:57,404][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:56:57,406][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:56:57,410][root][INFO] - LLM usage: prompt_tokens = 394053, completion_tokens = 131875
[2025-09-19 23:56:57,411][root][INFO] - Iteration 0: Running Code 4828741008319526806
[2025-09-19 23:56:57,945][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:56:57,983][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:56:57,984][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:00,176][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:00,181][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:00,187][root][INFO] - LLM usage: prompt_tokens = 394602, completion_tokens = 132223
[2025-09-19 23:57:00,189][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:01,345][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:01,347][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:01,349][root][INFO] - LLM usage: prompt_tokens = 395142, completion_tokens = 132324
[2025-09-19 23:57:01,349][root][INFO] - Iteration 0: Running Code 522257879290813458
[2025-09-19 23:57:01,864][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:01,910][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:57:01,911][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:03,712][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:03,714][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:03,715][root][INFO] - LLM usage: prompt_tokens = 395672, completion_tokens = 132618
[2025-09-19 23:57:03,715][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:04,682][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:04,683][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:04,685][root][INFO] - LLM usage: prompt_tokens = 396158, completion_tokens = 132688
[2025-09-19 23:57:04,686][root][INFO] - Iteration 0: Running Code -6682968611814967403
[2025-09-19 23:57:05,163][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:06,572][root][INFO] - Iteration 0, response_id 0: Objective value: 6.944258420955904
[2025-09-19 23:57:06,594][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:08,364][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:08,365][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:08,367][root][INFO] - LLM usage: prompt_tokens = 397433, completion_tokens = 133021
[2025-09-19 23:57:08,367][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:09,587][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:09,591][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:09,592][root][INFO] - LLM usage: prompt_tokens = 397958, completion_tokens = 133137
[2025-09-19 23:57:09,593][root][INFO] - Iteration 0: Running Code 1317055422459659520
[2025-09-19 23:57:10,084][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:11,469][root][INFO] - Iteration 0, response_id 0: Objective value: 8.402846590559758
[2025-09-19 23:57:11,471][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:13,842][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:13,844][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:13,849][root][INFO] - LLM usage: prompt_tokens = 399249, completion_tokens = 133709
[2025-09-19 23:57:13,851][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:14,978][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:14,982][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:14,989][root][INFO] - LLM usage: prompt_tokens = 400013, completion_tokens = 133815
[2025-09-19 23:57:14,991][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:16,762][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:16,766][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:16,773][root][INFO] - LLM usage: prompt_tokens = 401045, completion_tokens = 134141
[2025-09-19 23:57:16,775][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:17,780][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:17,783][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:17,788][root][INFO] - LLM usage: prompt_tokens = 401563, completion_tokens = 134212
[2025-09-19 23:57:17,790][root][INFO] - Iteration 0: Running Code 6361259768656158397
[2025-09-19 23:57:18,282][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:19,988][root][INFO] - Iteration 0, response_id 0: Objective value: 6.813448749813677
[2025-09-19 23:57:19,989][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:23,138][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:23,142][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:23,144][root][INFO] - LLM usage: prompt_tokens = 402148, completion_tokens = 134664
[2025-09-19 23:57:23,144][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:24,127][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:24,129][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:24,131][root][INFO] - LLM usage: prompt_tokens = 402792, completion_tokens = 134752
[2025-09-19 23:57:24,133][root][INFO] - Iteration 0: Running Code 4031497432748315292
[2025-09-19 23:57:24,621][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:24,659][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:57:24,660][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:27,570][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:27,574][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:27,581][root][INFO] - LLM usage: prompt_tokens = 403377, completion_tokens = 135295
[2025-09-19 23:57:27,582][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:28,986][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:28,990][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:28,996][root][INFO] - LLM usage: prompt_tokens = 404107, completion_tokens = 135396
[2025-09-19 23:57:28,999][root][INFO] - Iteration 0: Running Code 2271004957372660309
[2025-09-19 23:57:29,489][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:47,304][root][INFO] - Iteration 0, response_id 0: Objective value: 25.907518470794308
[2025-09-19 23:57:47,305][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:49,001][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:49,003][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:49,005][root][INFO] - LLM usage: prompt_tokens = 404673, completion_tokens = 135655
[2025-09-19 23:57:49,005][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:50,337][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:50,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:50,339][root][INFO] - LLM usage: prompt_tokens = 405124, completion_tokens = 135786
[2025-09-19 23:57:50,340][root][INFO] - Iteration 0: Running Code 4857984826127720918
[2025-09-19 23:57:50,865][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:57:51,817][root][INFO] - Iteration 0, response_id 0: Objective value: 9.612832295546376
[2025-09-19 23:57:51,835][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:54,092][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:54,093][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:54,095][root][INFO] - LLM usage: prompt_tokens = 406201, completion_tokens = 136324
[2025-09-19 23:57:54,095][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:57:55,084][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:57:55,085][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:57:55,088][root][INFO] - LLM usage: prompt_tokens = 406931, completion_tokens = 136405
[2025-09-19 23:57:55,089][root][INFO] - Iteration 0: Running Code -7140554831062146443
[2025-09-19 23:57:55,642][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:58:39,508][root][INFO] - Iteration 0, response_id 0: Objective value: 6.896407022716396
[2025-09-19 23:58:39,511][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:41,585][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:41,587][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:41,589][root][INFO] - LLM usage: prompt_tokens = 408673, completion_tokens = 136710
[2025-09-19 23:58:41,590][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:42,646][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:42,649][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:42,652][root][INFO] - LLM usage: prompt_tokens = 409156, completion_tokens = 136790
[2025-09-19 23:58:42,654][root][INFO] - Iteration 0: Running Code 2270001883156060625
[2025-09-19 23:58:45,274][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:58:45,311][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:58:45,312][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:47,319][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:47,323][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:47,330][root][INFO] - LLM usage: prompt_tokens = 410147, completion_tokens = 136998
[2025-09-19 23:58:47,331][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:48,334][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:48,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:48,344][root][INFO] - LLM usage: prompt_tokens = 410547, completion_tokens = 137077
[2025-09-19 23:58:48,346][root][INFO] - Iteration 0: Running Code 6583163439690280155
[2025-09-19 23:58:48,846][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:58:48,883][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:58:48,884][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:50,813][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:50,817][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:50,828][root][INFO] - LLM usage: prompt_tokens = 412639, completion_tokens = 137416
[2025-09-19 23:58:50,830][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:51,761][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:51,765][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:51,767][root][INFO] - LLM usage: prompt_tokens = 413170, completion_tokens = 137494
[2025-09-19 23:58:51,768][root][INFO] - Iteration 0: Running Code 7857991768180738978
[2025-09-19 23:58:52,274][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:58:52,311][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-19 23:58:52,312][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:55,557][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:55,560][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:55,567][root][INFO] - LLM usage: prompt_tokens = 414185, completion_tokens = 137857
[2025-09-19 23:58:55,568][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:58:56,928][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:58:56,932][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:58:56,938][root][INFO] - LLM usage: prompt_tokens = 414740, completion_tokens = 137930
[2025-09-19 23:58:56,940][root][INFO] - Iteration 0: Running Code -4566813467773258907
[2025-09-19 23:58:57,448][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:58:59,170][root][INFO] - Iteration 0, response_id 0: Objective value: 6.677045124222435
[2025-09-19 23:58:59,171][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:02,130][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:02,135][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:02,142][root][INFO] - LLM usage: prompt_tokens = 415328, completion_tokens = 138326
[2025-09-19 23:59:02,144][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:03,332][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:03,336][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:03,342][root][INFO] - LLM usage: prompt_tokens = 415911, completion_tokens = 138426
[2025-09-19 23:59:03,345][root][INFO] - Iteration 0: Running Code 5882614117435577402
[2025-09-19 23:59:03,841][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:59:04,693][root][INFO] - Iteration 0, response_id 0: Objective value: 8.45543389967116
[2025-09-19 23:59:04,694][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:07,190][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:07,195][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:07,201][root][INFO] - LLM usage: prompt_tokens = 416480, completion_tokens = 138753
[2025-09-19 23:59:07,203][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:08,434][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:08,435][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:08,437][root][INFO] - LLM usage: prompt_tokens = 416999, completion_tokens = 138837
[2025-09-19 23:59:08,437][root][INFO] - Iteration 0: Running Code 8476223333109486241
[2025-09-19 23:59:08,924][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:59:10,087][root][INFO] - Iteration 0, response_id 0: Objective value: 8.847389161566195
[2025-09-19 23:59:10,104][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:11,790][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:11,792][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:11,793][root][INFO] - LLM usage: prompt_tokens = 417945, completion_tokens = 139191
[2025-09-19 23:59:11,794][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:12,834][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:12,835][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:12,837][root][INFO] - LLM usage: prompt_tokens = 418491, completion_tokens = 139270
[2025-09-19 23:59:12,837][root][INFO] - Iteration 0: Running Code -6675091167641763142
[2025-09-19 23:59:13,349][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:59:14,639][root][INFO] - Iteration 0, response_id 0: Objective value: 7.482370213744591
[2025-09-19 23:59:14,643][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:16,225][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:16,230][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:16,238][root][INFO] - LLM usage: prompt_tokens = 419801, completion_tokens = 139478
[2025-09-19 23:59:16,239][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:17,452][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:17,453][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:17,455][root][INFO] - LLM usage: prompt_tokens = 420201, completion_tokens = 139576
[2025-09-19 23:59:17,455][root][INFO] - Iteration 0: Running Code -7344916599026806060
[2025-09-19 23:59:17,959][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-19 23:59:19,969][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0043697989867315
[2025-09-19 23:59:19,970][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:22,089][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:22,093][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:22,095][root][INFO] - LLM usage: prompt_tokens = 421336, completion_tokens = 140026
[2025-09-19 23:59:22,096][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-19 23:59:23,263][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-19 23:59:23,265][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-19 23:59:23,267][root][INFO] - LLM usage: prompt_tokens = 421978, completion_tokens = 140140
[2025-09-19 23:59:23,268][root][INFO] - Iteration 0: Running Code -3507850937251136731
[2025-09-19 23:59:23,762][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:00:04,621][root][INFO] - Iteration 0, response_id 0: Objective value: 7.298106172315706
[2025-09-20 00:00:04,622][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:07,110][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:07,115][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:07,123][root][INFO] - LLM usage: prompt_tokens = 423201, completion_tokens = 140712
[2025-09-20 00:00:07,125][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:08,369][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:08,373][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:08,379][root][INFO] - LLM usage: prompt_tokens = 423965, completion_tokens = 140842
[2025-09-20 00:00:08,382][root][INFO] - Iteration 0: Running Code -383664050734325675
[2025-09-20 00:00:08,895][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:00:12,150][root][INFO] - Iteration 0, response_id 0: Objective value: 33.243188464363016
[2025-09-20 00:00:12,151][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:14,248][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:14,253][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:14,259][root][INFO] - LLM usage: prompt_tokens = 424482, completion_tokens = 141244
[2025-09-20 00:00:14,261][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:15,445][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:15,446][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:15,447][root][INFO] - LLM usage: prompt_tokens = 425076, completion_tokens = 141326
[2025-09-20 00:00:15,448][root][INFO] - Iteration 0: Running Code 5858345769263954431
[2025-09-20 00:00:15,974][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:00:18,788][root][INFO] - Iteration 0, response_id 0: Objective value: 6.93522211534823
[2025-09-20 00:00:18,789][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:20,982][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:20,987][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:20,992][root][INFO] - LLM usage: prompt_tokens = 425574, completion_tokens = 141578
[2025-09-20 00:00:20,994][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:22,588][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:22,592][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:22,597][root][INFO] - LLM usage: prompt_tokens = 426018, completion_tokens = 141680
[2025-09-20 00:00:22,599][root][INFO] - Iteration 0: Running Code 3805160171463304684
[2025-09-20 00:00:23,108][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:00:23,908][root][INFO] - Iteration 0, response_id 0: Objective value: 7.187933714053726
[2025-09-20 00:00:23,929][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:26,169][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:26,171][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:26,174][root][INFO] - LLM usage: prompt_tokens = 427473, completion_tokens = 142168
[2025-09-20 00:00:26,174][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:00:27,159][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:00:27,163][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:00:27,169][root][INFO] - LLM usage: prompt_tokens = 428153, completion_tokens = 142257
[2025-09-20 00:00:27,172][root][INFO] - Iteration 0: Running Code -3453056443645720437
[2025-09-20 00:00:27,696][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:09,343][root][INFO] - Iteration 0, response_id 0: Objective value: 6.681682222179487
[2025-09-20 00:01:09,345][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:11,357][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:11,359][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:11,361][root][INFO] - LLM usage: prompt_tokens = 429258, completion_tokens = 142559
[2025-09-20 00:01:11,362][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:12,351][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:12,352][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:12,354][root][INFO] - LLM usage: prompt_tokens = 429752, completion_tokens = 142628
[2025-09-20 00:01:12,355][root][INFO] - Iteration 0: Running Code 767603554993349488
[2025-09-20 00:01:12,909][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:14,998][root][INFO] - Iteration 0, response_id 0: Objective value: 8.840098411912962
[2025-09-20 00:01:14,999][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:17,005][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:17,007][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:17,010][root][INFO] - LLM usage: prompt_tokens = 430753, completion_tokens = 142966
[2025-09-20 00:01:17,011][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:18,272][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:18,276][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:18,282][root][INFO] - LLM usage: prompt_tokens = 431283, completion_tokens = 143088
[2025-09-20 00:01:18,284][root][INFO] - Iteration 0: Running Code 4803831647139243496
[2025-09-20 00:01:18,776][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:19,904][root][INFO] - Iteration 0, response_id 0: Objective value: 30.75122811522182
[2025-09-20 00:01:19,905][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:22,156][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:22,158][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:22,160][root][INFO] - LLM usage: prompt_tokens = 432350, completion_tokens = 143490
[2025-09-20 00:01:22,160][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:23,251][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:23,252][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:23,254][root][INFO] - LLM usage: prompt_tokens = 432944, completion_tokens = 143584
[2025-09-20 00:01:23,255][root][INFO] - Iteration 0: Running Code 3998032527866547214
[2025-09-20 00:01:23,751][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:26,042][root][INFO] - Iteration 0, response_id 0: Objective value: 14.806877148717886
[2025-09-20 00:01:26,043][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:29,038][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:29,044][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:29,050][root][INFO] - LLM usage: prompt_tokens = 433547, completion_tokens = 143963
[2025-09-20 00:01:29,052][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:30,184][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:30,188][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:30,194][root][INFO] - LLM usage: prompt_tokens = 434118, completion_tokens = 144053
[2025-09-20 00:01:30,197][root][INFO] - Iteration 0: Running Code -3244606513557236044
[2025-09-20 00:01:30,693][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:30,729][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:01:30,730][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:32,991][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:32,994][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:32,995][root][INFO] - LLM usage: prompt_tokens = 434721, completion_tokens = 144466
[2025-09-20 00:01:32,996][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:34,222][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:34,226][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:34,232][root][INFO] - LLM usage: prompt_tokens = 435326, completion_tokens = 144571
[2025-09-20 00:01:34,235][root][INFO] - Iteration 0: Running Code 5490389971335141783
[2025-09-20 00:01:34,725][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:36,009][root][INFO] - Iteration 0, response_id 0: Objective value: 29.93692523688327
[2025-09-20 00:01:36,010][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:38,614][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:38,618][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:38,625][root][INFO] - LLM usage: prompt_tokens = 435910, completion_tokens = 144922
[2025-09-20 00:01:38,626][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:39,817][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:39,822][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:39,827][root][INFO] - LLM usage: prompt_tokens = 436448, completion_tokens = 145018
[2025-09-20 00:01:39,830][root][INFO] - Iteration 0: Running Code -4437025134220252446
[2025-09-20 00:01:40,334][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:41,611][root][INFO] - Iteration 0, response_id 0: Objective value: 32.92779961528652
[2025-09-20 00:01:41,634][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:43,532][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:43,536][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:43,544][root][INFO] - LLM usage: prompt_tokens = 437803, completion_tokens = 145380
[2025-09-20 00:01:43,545][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:44,883][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:44,887][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:44,893][root][INFO] - LLM usage: prompt_tokens = 438357, completion_tokens = 145463
[2025-09-20 00:01:44,895][root][INFO] - Iteration 0: Running Code 3044730951404531469
[2025-09-20 00:01:45,402][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:47,102][root][INFO] - Iteration 0, response_id 0: Objective value: 6.677045124222435
[2025-09-20 00:01:47,104][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:49,218][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:49,222][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:49,231][root][INFO] - LLM usage: prompt_tokens = 439648, completion_tokens = 145815
[2025-09-20 00:01:49,232][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:50,516][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:50,520][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:50,527][root][INFO] - LLM usage: prompt_tokens = 440192, completion_tokens = 145920
[2025-09-20 00:01:50,529][root][INFO] - Iteration 0: Running Code 191095578778784456
[2025-09-20 00:01:51,030][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:53,041][root][INFO] - Iteration 0, response_id 0: Objective value: 8.04829650785042
[2025-09-20 00:01:53,041][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:55,083][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:55,087][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:55,094][root][INFO] - LLM usage: prompt_tokens = 440732, completion_tokens = 146282
[2025-09-20 00:01:55,095][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:01:56,380][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:01:56,384][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:01:56,386][root][INFO] - LLM usage: prompt_tokens = 441286, completion_tokens = 146375
[2025-09-20 00:01:56,387][root][INFO] - Iteration 0: Running Code 4087162221084863637
[2025-09-20 00:01:56,883][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:01:59,795][root][INFO] - Iteration 0, response_id 0: Objective value: 8.559050443175877
[2025-09-20 00:01:59,795][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:01,573][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:01,577][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:01,584][root][INFO] - LLM usage: prompt_tokens = 441807, completion_tokens = 146660
[2025-09-20 00:02:01,586][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:02,864][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:02,867][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:02,871][root][INFO] - LLM usage: prompt_tokens = 442284, completion_tokens = 146759
[2025-09-20 00:02:02,873][root][INFO] - Iteration 0: Running Code 7220640441291437795
[2025-09-20 00:02:03,367][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:04,735][root][INFO] - Iteration 0, response_id 0: Objective value: 7.873339107628562
[2025-09-20 00:02:04,749][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:06,533][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:06,537][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:06,545][root][INFO] - LLM usage: prompt_tokens = 443327, completion_tokens = 147124
[2025-09-20 00:02:06,546][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:08,461][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:08,462][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:08,465][root][INFO] - LLM usage: prompt_tokens = 443884, completion_tokens = 147241
[2025-09-20 00:02:08,466][root][INFO] - Iteration 0: Running Code -2962936922216796573
[2025-09-20 00:02:08,953][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:10,694][root][INFO] - Iteration 0, response_id 0: Objective value: 6.954334085522643
[2025-09-20 00:02:10,695][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:12,695][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:12,696][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:12,698][root][INFO] - LLM usage: prompt_tokens = 444445, completion_tokens = 147534
[2025-09-20 00:02:12,699][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:13,730][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:13,733][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:13,737][root][INFO] - LLM usage: prompt_tokens = 444930, completion_tokens = 147615
[2025-09-20 00:02:13,739][root][INFO] - Iteration 0: Running Code 7752358736176507159
[2025-09-20 00:02:14,225][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:15,559][root][INFO] - Iteration 0, response_id 0: Objective value: 7.47763504951749
[2025-09-20 00:02:15,559][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:17,557][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:17,562][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:17,568][root][INFO] - LLM usage: prompt_tokens = 445472, completion_tokens = 147909
[2025-09-20 00:02:17,570][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:18,848][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:18,851][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:18,857][root][INFO] - LLM usage: prompt_tokens = 445953, completion_tokens = 148026
[2025-09-20 00:02:18,859][root][INFO] - Iteration 0: Running Code 5182041641351009840
[2025-09-20 00:02:19,370][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:20,718][root][INFO] - Iteration 0, response_id 0: Objective value: 7.487728343701118
[2025-09-20 00:02:20,735][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:22,470][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:22,471][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:22,473][root][INFO] - LLM usage: prompt_tokens = 446893, completion_tokens = 148369
[2025-09-20 00:02:22,473][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:23,411][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:23,412][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:23,412][root][INFO] - LLM usage: prompt_tokens = 447428, completion_tokens = 148434
[2025-09-20 00:02:23,413][root][INFO] - Iteration 0: Running Code -5970075670078340678
[2025-09-20 00:02:23,956][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:25,901][root][INFO] - Iteration 0, response_id 0: Objective value: 8.555405643411703
[2025-09-20 00:02:25,903][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:28,189][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:28,191][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:28,193][root][INFO] - LLM usage: prompt_tokens = 448562, completion_tokens = 148939
[2025-09-20 00:02:28,193][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:32,350][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:32,352][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:32,355][root][INFO] - LLM usage: prompt_tokens = 449259, completion_tokens = 149023
[2025-09-20 00:02:32,356][root][INFO] - Iteration 0: Running Code 4679737724698235206
[2025-09-20 00:02:32,881][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:35,691][root][INFO] - Iteration 0, response_id 0: Objective value: 16.569763959414963
[2025-09-20 00:02:35,692][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:42,215][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:42,218][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:42,221][root][INFO] - LLM usage: prompt_tokens = 449889, completion_tokens = 149459
[2025-09-20 00:02:42,221][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:43,588][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:43,589][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:43,591][root][INFO] - LLM usage: prompt_tokens = 450517, completion_tokens = 149589
[2025-09-20 00:02:43,592][root][INFO] - Iteration 0: Running Code -5797027581276144737
[2025-09-20 00:02:44,091][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:46,734][root][INFO] - Iteration 0, response_id 0: Objective value: 8.027331053742234
[2025-09-20 00:02:46,734][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:48,581][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:48,582][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:48,584][root][INFO] - LLM usage: prompt_tokens = 451128, completion_tokens = 149966
[2025-09-20 00:02:48,585][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:49,846][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:49,850][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:49,856][root][INFO] - LLM usage: prompt_tokens = 451692, completion_tokens = 150076
[2025-09-20 00:02:49,858][root][INFO] - Iteration 0: Running Code 4064906170319855095
[2025-09-20 00:02:50,356][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:52,267][root][INFO] - Iteration 0, response_id 0: Objective value: 7.916518914055605
[2025-09-20 00:02:52,367][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:54,291][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:54,294][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:54,297][root][INFO] - LLM usage: prompt_tokens = 452701, completion_tokens = 150432
[2025-09-20 00:02:54,298][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:02:55,569][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:02:55,572][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:02:55,574][root][INFO] - LLM usage: prompt_tokens = 453249, completion_tokens = 150522
[2025-09-20 00:02:55,574][root][INFO] - Iteration 0: Running Code 8450994181844247641
[2025-09-20 00:02:56,065][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:02:58,064][root][INFO] - Iteration 0, response_id 0: Objective value: 8.813539519444838
[2025-09-20 00:02:58,067][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:00,261][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:00,265][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:00,273][root][INFO] - LLM usage: prompt_tokens = 454398, completion_tokens = 150925
[2025-09-20 00:03:00,275][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:01,667][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:01,671][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:01,677][root][INFO] - LLM usage: prompt_tokens = 454993, completion_tokens = 151048
[2025-09-20 00:03:01,680][root][INFO] - Iteration 0: Running Code 6965235973954998079
[2025-09-20 00:03:02,179][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:03,918][root][INFO] - Iteration 0, response_id 0: Objective value: 8.300282975939346
[2025-09-20 00:03:03,919][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:06,128][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:06,130][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:06,134][root][INFO] - LLM usage: prompt_tokens = 455601, completion_tokens = 151455
[2025-09-20 00:03:06,135][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:07,244][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:07,248][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:07,250][root][INFO] - LLM usage: prompt_tokens = 456200, completion_tokens = 151564
[2025-09-20 00:03:07,251][root][INFO] - Iteration 0: Running Code 2131639922275619867
[2025-09-20 00:03:07,766][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:10,708][root][INFO] - Iteration 0, response_id 0: Objective value: 9.17299815737187
[2025-09-20 00:03:10,709][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:12,398][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:12,402][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:12,404][root][INFO] - LLM usage: prompt_tokens = 456789, completion_tokens = 151839
[2025-09-20 00:03:12,404][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:13,611][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:13,615][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:13,621][root][INFO] - LLM usage: prompt_tokens = 457256, completion_tokens = 151937
[2025-09-20 00:03:13,623][root][INFO] - Iteration 0: Running Code -3150847649624635425
[2025-09-20 00:03:14,109][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:15,821][root][INFO] - Iteration 0, response_id 0: Objective value: 13.018277134353863
[2025-09-20 00:03:15,838][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:18,052][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:18,054][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:18,056][root][INFO] - LLM usage: prompt_tokens = 458243, completion_tokens = 152327
[2025-09-20 00:03:18,056][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:19,127][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:19,131][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:19,133][root][INFO] - LLM usage: prompt_tokens = 458825, completion_tokens = 152435
[2025-09-20 00:03:19,134][root][INFO] - Iteration 0: Running Code 3627165176849937972
[2025-09-20 00:03:19,626][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:22,554][root][INFO] - Iteration 0, response_id 0: Objective value: 8.60260707321315
[2025-09-20 00:03:22,557][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:25,664][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:25,665][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:25,668][root][INFO] - LLM usage: prompt_tokens = 460572, completion_tokens = 152819
[2025-09-20 00:03:25,669][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:26,802][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:26,806][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:26,812][root][INFO] - LLM usage: prompt_tokens = 461127, completion_tokens = 152934
[2025-09-20 00:03:26,814][root][INFO] - Iteration 0: Running Code 2976297771306103312
[2025-09-20 00:03:27,305][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:27,341][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:03:27,342][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:28,897][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:28,906][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:28,916][root][INFO] - LLM usage: prompt_tokens = 463009, completion_tokens = 153140
[2025-09-20 00:03:28,918][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:29,874][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:29,878][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:29,884][root][INFO] - LLM usage: prompt_tokens = 463407, completion_tokens = 153221
[2025-09-20 00:03:29,886][root][INFO] - Iteration 0: Running Code -8165215432001225097
[2025-09-20 00:03:30,382][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:31,137][root][INFO] - Iteration 0, response_id 0: Objective value: 7.855928235404853
[2025-09-20 00:03:31,138][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:32,880][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:32,882][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:32,884][root][INFO] - LLM usage: prompt_tokens = 464522, completion_tokens = 153614
[2025-09-20 00:03:32,884][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:33,950][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:33,951][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:33,952][root][INFO] - LLM usage: prompt_tokens = 465107, completion_tokens = 153717
[2025-09-20 00:03:33,953][root][INFO] - Iteration 0: Running Code 1317085854157254912
[2025-09-20 00:03:34,449][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:36,252][root][INFO] - Iteration 0, response_id 0: Objective value: 7.785622411992589
[2025-09-20 00:03:36,252][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:38,228][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:38,233][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:38,240][root][INFO] - LLM usage: prompt_tokens = 465681, completion_tokens = 154101
[2025-09-20 00:03:38,242][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:39,445][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:39,446][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:39,448][root][INFO] - LLM usage: prompt_tokens = 466257, completion_tokens = 154223
[2025-09-20 00:03:39,448][root][INFO] - Iteration 0: Running Code 901665975719779994
[2025-09-20 00:03:39,930][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:41,874][root][INFO] - Iteration 0, response_id 0: Objective value: 6.97693989926144
[2025-09-20 00:03:41,874][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:43,784][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:43,788][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:43,795][root][INFO] - LLM usage: prompt_tokens = 466812, completion_tokens = 154488
[2025-09-20 00:03:43,796][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:45,078][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:45,079][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:45,080][root][INFO] - LLM usage: prompt_tokens = 467264, completion_tokens = 154608
[2025-09-20 00:03:45,081][root][INFO] - Iteration 0: Running Code -2824792042299709130
[2025-09-20 00:03:45,566][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:46,373][root][INFO] - Iteration 0, response_id 0: Objective value: 6.768051166618523
[2025-09-20 00:03:46,391][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:48,282][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:48,286][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:48,293][root][INFO] - LLM usage: prompt_tokens = 468134, completion_tokens = 154953
[2025-09-20 00:03:48,295][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:49,304][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:49,308][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:49,314][root][INFO] - LLM usage: prompt_tokens = 468671, completion_tokens = 155027
[2025-09-20 00:03:49,317][root][INFO] - Iteration 0: Running Code 390697289063757217
[2025-09-20 00:03:49,814][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:50,909][root][INFO] - Iteration 0, response_id 0: Objective value: 10.973580147068713
[2025-09-20 00:03:50,911][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:52,544][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:52,545][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:52,547][root][INFO] - LLM usage: prompt_tokens = 469680, completion_tokens = 155359
[2025-09-20 00:03:52,547][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:53,670][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:53,674][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:53,677][root][INFO] - LLM usage: prompt_tokens = 470204, completion_tokens = 155471
[2025-09-20 00:03:53,679][root][INFO] - Iteration 0: Running Code -2504321295931570927
[2025-09-20 00:03:54,169][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:03:55,883][root][INFO] - Iteration 0, response_id 0: Objective value: 7.950690397233468
[2025-09-20 00:03:55,884][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:57,578][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:57,579][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:57,581][root][INFO] - LLM usage: prompt_tokens = 470673, completion_tokens = 155762
[2025-09-20 00:03:57,581][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:03:58,967][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:03:58,971][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:03:58,976][root][INFO] - LLM usage: prompt_tokens = 471156, completion_tokens = 155866
[2025-09-20 00:03:58,978][root][INFO] - Iteration 0: Running Code -861273919998015333
[2025-09-20 00:03:59,449][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:00,224][root][INFO] - Iteration 0, response_id 0: Objective value: 8.01825359781303
[2025-09-20 00:04:00,225][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:01,872][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:01,876][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:01,882][root][INFO] - LLM usage: prompt_tokens = 471606, completion_tokens = 156081
[2025-09-20 00:04:01,884][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:03,115][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:03,119][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:03,121][root][INFO] - LLM usage: prompt_tokens = 472013, completion_tokens = 156190
[2025-09-20 00:04:03,121][root][INFO] - Iteration 0: Running Code 4413520774732623255
[2025-09-20 00:04:03,606][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:04,346][root][INFO] - Iteration 0, response_id 0: Objective value: 7.765514250711173
[2025-09-20 00:04:04,360][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:06,211][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:06,215][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:06,223][root][INFO] - LLM usage: prompt_tokens = 472963, completion_tokens = 156547
[2025-09-20 00:04:06,224][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:07,270][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:07,275][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:07,280][root][INFO] - LLM usage: prompt_tokens = 473512, completion_tokens = 156633
[2025-09-20 00:04:07,283][root][INFO] - Iteration 0: Running Code 964070769192136773
[2025-09-20 00:04:07,801][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:10,120][root][INFO] - Iteration 0, response_id 0: Objective value: 6.704196080546644
[2025-09-20 00:04:10,121][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:11,887][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:11,891][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:11,898][root][INFO] - LLM usage: prompt_tokens = 474015, completion_tokens = 156937
[2025-09-20 00:04:11,899][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:13,438][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:13,442][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:13,447][root][INFO] - LLM usage: prompt_tokens = 474511, completion_tokens = 157031
[2025-09-20 00:04:13,450][root][INFO] - Iteration 0: Running Code -7266602276332937653
[2025-09-20 00:04:13,954][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:14,718][root][INFO] - Iteration 0, response_id 0: Objective value: 7.348640332332998
[2025-09-20 00:04:14,719][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:15,930][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:15,934][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:15,940][root][INFO] - LLM usage: prompt_tokens = 474995, completion_tokens = 157238
[2025-09-20 00:04:15,942][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:17,633][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:17,634][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:17,636][root][INFO] - LLM usage: prompt_tokens = 475394, completion_tokens = 157329
[2025-09-20 00:04:17,636][root][INFO] - Iteration 0: Running Code 4535900893941361324
[2025-09-20 00:04:18,118][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:18,852][root][INFO] - Iteration 0, response_id 0: Objective value: 8.182237384847257
[2025-09-20 00:04:18,870][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:20,437][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:20,441][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:20,448][root][INFO] - LLM usage: prompt_tokens = 476205, completion_tokens = 157605
[2025-09-20 00:04:20,449][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:21,601][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:21,605][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:21,611][root][INFO] - LLM usage: prompt_tokens = 476668, completion_tokens = 157696
[2025-09-20 00:04:21,613][root][INFO] - Iteration 0: Running Code 434688483548753199
[2025-09-20 00:04:22,115][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:23,515][root][INFO] - Iteration 0, response_id 0: Objective value: 8.351136916830644
[2025-09-20 00:04:23,517][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:25,306][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:25,310][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:25,312][root][INFO] - LLM usage: prompt_tokens = 477708, completion_tokens = 158086
[2025-09-20 00:04:25,313][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:26,358][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:26,363][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:26,369][root][INFO] - LLM usage: prompt_tokens = 478290, completion_tokens = 158177
[2025-09-20 00:04:26,371][root][INFO] - Iteration 0: Running Code 4704250687223794931
[2025-09-20 00:04:26,885][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:28,553][root][INFO] - Iteration 0, response_id 0: Objective value: 8.034010111213412
[2025-09-20 00:04:28,554][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:31,253][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:31,256][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:31,258][root][INFO] - LLM usage: prompt_tokens = 478903, completion_tokens = 158687
[2025-09-20 00:04:31,259][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:32,298][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:32,299][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:32,301][root][INFO] - LLM usage: prompt_tokens = 479663, completion_tokens = 158793
[2025-09-20 00:04:32,302][root][INFO] - Iteration 0: Running Code -9128509461329858748
[2025-09-20 00:04:32,816][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-20 00:04:32,854][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:04:32,855][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:34,832][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:34,837][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:34,844][root][INFO] - LLM usage: prompt_tokens = 480276, completion_tokens = 159193
[2025-09-20 00:04:34,845][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:35,874][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:35,878][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:35,879][root][INFO] - LLM usage: prompt_tokens = 480863, completion_tokens = 159277
[2025-09-20 00:04:35,879][root][INFO] - Iteration 0: Running Code -6275917351296465612
[2025-09-20 00:04:36,381][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:38,590][root][INFO] - Iteration 0, response_id 0: Objective value: 22.59957365745705
[2025-09-20 00:04:38,591][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:40,460][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:40,461][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:40,462][root][INFO] - LLM usage: prompt_tokens = 481457, completion_tokens = 159598
[2025-09-20 00:04:40,463][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:41,806][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:41,810][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:41,815][root][INFO] - LLM usage: prompt_tokens = 481970, completion_tokens = 159721
[2025-09-20 00:04:41,818][root][INFO] - Iteration 0: Running Code 6695086112727008047
[2025-09-20 00:04:42,341][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:44,143][root][INFO] - Iteration 0, response_id 0: Objective value: 25.885399919036352
[2025-09-20 00:04:44,167][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:47,858][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:47,863][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:47,870][root][INFO] - LLM usage: prompt_tokens = 482891, completion_tokens = 160119
[2025-09-20 00:04:47,872][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:50,142][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:50,147][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:50,152][root][INFO] - LLM usage: prompt_tokens = 483481, completion_tokens = 160209
[2025-09-20 00:04:50,155][root][INFO] - Iteration 0: Running Code 5919982396224087054
[2025-09-20 00:04:50,665][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:52,396][root][INFO] - Iteration 0, response_id 0: Objective value: 7.864553167241152
[2025-09-20 00:04:52,398][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:54,686][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:54,688][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:54,690][root][INFO] - LLM usage: prompt_tokens = 484581, completion_tokens = 160609
[2025-09-20 00:04:54,691][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:04:56,920][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:04:56,923][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:04:56,924][root][INFO] - LLM usage: prompt_tokens = 485173, completion_tokens = 160721
[2025-09-20 00:04:56,925][root][INFO] - Iteration 0: Running Code -5223765995386515683
[2025-09-20 00:04:57,414][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:04:59,572][root][INFO] - Iteration 0, response_id 0: Objective value: 7.748081567976685
[2025-09-20 00:04:59,573][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:01,862][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:01,866][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:01,872][root][INFO] - LLM usage: prompt_tokens = 485733, completion_tokens = 161138
[2025-09-20 00:05:01,874][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:03,413][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:03,418][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:03,423][root][INFO] - LLM usage: prompt_tokens = 486342, completion_tokens = 161247
[2025-09-20 00:05:03,425][root][INFO] - Iteration 0: Running Code 4836659470310993222
[2025-09-20 00:05:03,925][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:04,712][root][INFO] - Iteration 0, response_id 0: Objective value: 20.01129144418949
[2025-09-20 00:05:04,712][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:06,669][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:06,673][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:06,679][root][INFO] - LLM usage: prompt_tokens = 486883, completion_tokens = 161524
[2025-09-20 00:05:06,681][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:08,114][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:08,118][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:08,124][root][INFO] - LLM usage: prompt_tokens = 487352, completion_tokens = 161630
[2025-09-20 00:05:08,126][root][INFO] - Iteration 0: Running Code -6260870796066733744
[2025-09-20 00:05:08,622][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:09,376][root][INFO] - Iteration 0, response_id 0: Objective value: 9.204451857497256
[2025-09-20 00:05:09,395][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:10,995][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:10,996][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:10,998][root][INFO] - LLM usage: prompt_tokens = 488220, completion_tokens = 161916
[2025-09-20 00:05:10,999][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:12,171][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:12,172][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:12,175][root][INFO] - LLM usage: prompt_tokens = 488698, completion_tokens = 161996
[2025-09-20 00:05:12,176][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:14,658][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:14,663][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:14,670][root][INFO] - LLM usage: prompt_tokens = 489566, completion_tokens = 162279
[2025-09-20 00:05:14,671][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:15,927][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:15,931][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:15,937][root][INFO] - LLM usage: prompt_tokens = 490073, completion_tokens = 162375
[2025-09-20 00:05:15,940][root][INFO] - Iteration 0: Running Code 5368472160912560576
[2025-09-20 00:05:16,443][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-20 00:05:16,481][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:05:16,482][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:18,165][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:18,169][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:18,176][root][INFO] - LLM usage: prompt_tokens = 490941, completion_tokens = 162667
[2025-09-20 00:05:18,177][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:19,468][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:19,472][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:19,478][root][INFO] - LLM usage: prompt_tokens = 491425, completion_tokens = 162751
[2025-09-20 00:05:19,480][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:21,624][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:21,628][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:21,635][root][INFO] - LLM usage: prompt_tokens = 492293, completion_tokens = 163045
[2025-09-20 00:05:21,637][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:22,954][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:22,958][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:22,964][root][INFO] - LLM usage: prompt_tokens = 492774, completion_tokens = 163135
[2025-09-20 00:05:22,966][root][INFO] - Iteration 0: Running Code -772678998683912912
[2025-09-20 00:05:23,457][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:24,203][root][INFO] - Iteration 0, response_id 0: Objective value: 7.992545482447724
[2025-09-20 00:05:24,205][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:25,689][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:25,693][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:25,701][root][INFO] - LLM usage: prompt_tokens = 493707, completion_tokens = 163387
[2025-09-20 00:05:25,702][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:27,074][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:27,078][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:27,083][root][INFO] - LLM usage: prompt_tokens = 494151, completion_tokens = 163482
[2025-09-20 00:05:27,086][root][INFO] - Iteration 0: Running Code -8083280299728607528
[2025-09-20 00:05:27,619][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:28,802][root][INFO] - Iteration 0, response_id 0: Objective value: 7.855928235404853
[2025-09-20 00:05:28,803][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:30,787][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:30,791][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:30,799][root][INFO] - LLM usage: prompt_tokens = 495186, completion_tokens = 163835
[2025-09-20 00:05:30,800][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:31,902][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:31,906][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:31,911][root][INFO] - LLM usage: prompt_tokens = 495731, completion_tokens = 163923
[2025-09-20 00:05:31,914][root][INFO] - Iteration 0: Running Code -3607643868176627797
[2025-09-20 00:05:32,410][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:34,730][root][INFO] - Iteration 0, response_id 0: Objective value: 6.6773460381078795
[2025-09-20 00:05:34,730][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:36,662][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:36,668][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:36,674][root][INFO] - LLM usage: prompt_tokens = 496339, completion_tokens = 164300
[2025-09-20 00:05:36,676][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:37,738][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:37,742][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:37,748][root][INFO] - LLM usage: prompt_tokens = 496908, completion_tokens = 164403
[2025-09-20 00:05:37,750][root][INFO] - Iteration 0: Running Code -2049213967382807929
[2025-09-20 00:05:38,244][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:40,115][root][INFO] - Iteration 0, response_id 0: Objective value: 17.753286598656697
[2025-09-20 00:05:40,116][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:42,413][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:42,418][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:42,426][root][INFO] - LLM usage: prompt_tokens = 497497, completion_tokens = 164780
[2025-09-20 00:05:42,426][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:43,473][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:43,477][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:43,483][root][INFO] - LLM usage: prompt_tokens = 498066, completion_tokens = 164881
[2025-09-20 00:05:43,485][root][INFO] - Iteration 0: Running Code -2688994910010855167
[2025-09-20 00:05:43,997][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:46,407][root][INFO] - Iteration 0, response_id 0: Objective value: 7.243195985161311
[2025-09-20 00:05:46,439][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:48,644][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:48,645][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:48,647][root][INFO] - LLM usage: prompt_tokens = 499291, completion_tokens = 165239
[2025-09-20 00:05:48,648][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:49,662][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:49,666][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:49,667][root][INFO] - LLM usage: prompt_tokens = 499841, completion_tokens = 165330
[2025-09-20 00:05:49,668][root][INFO] - Iteration 0: Running Code -4749666526593294318
[2025-09-20 00:05:50,163][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:52,422][root][INFO] - Iteration 0, response_id 0: Objective value: 6.628746453838379
[2025-09-20 00:05:52,424][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:54,375][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:54,377][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:54,379][root][INFO] - LLM usage: prompt_tokens = 500887, completion_tokens = 165670
[2025-09-20 00:05:54,379][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:55,540][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:55,544][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:55,550][root][INFO] - LLM usage: prompt_tokens = 501419, completion_tokens = 165779
[2025-09-20 00:05:55,552][root][INFO] - Iteration 0: Running Code 4162667425576008651
[2025-09-20 00:05:56,065][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:05:57,934][root][INFO] - Iteration 0, response_id 0: Objective value: 7.914195856921745
[2025-09-20 00:05:57,935][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:05:59,976][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:05:59,981][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:05:59,983][root][INFO] - LLM usage: prompt_tokens = 501933, completion_tokens = 166117
[2025-09-20 00:05:59,983][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:01,099][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:01,103][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:01,109][root][INFO] - LLM usage: prompt_tokens = 502463, completion_tokens = 166205
[2025-09-20 00:06:01,111][root][INFO] - Iteration 0: Running Code -4421651430308780939
[2025-09-20 00:06:01,625][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:01,662][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:06:01,662][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:04,136][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:04,140][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:04,147][root][INFO] - LLM usage: prompt_tokens = 502977, completion_tokens = 166567
[2025-09-20 00:06:04,148][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:05,456][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:05,457][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:05,459][root][INFO] - LLM usage: prompt_tokens = 503531, completion_tokens = 166676
[2025-09-20 00:06:05,460][root][INFO] - Iteration 0: Running Code -2667833114335737102
[2025-09-20 00:06:05,950][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:07,169][root][INFO] - Iteration 0, response_id 0: Objective value: 7.545147775359477
[2025-09-20 00:06:07,169][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:08,699][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:08,703][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:08,709][root][INFO] - LLM usage: prompt_tokens = 504026, completion_tokens = 166941
[2025-09-20 00:06:08,711][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:09,697][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:09,701][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:09,706][root][INFO] - LLM usage: prompt_tokens = 504483, completion_tokens = 167023
[2025-09-20 00:06:09,709][root][INFO] - Iteration 0: Running Code 1401500206221069910
[2025-09-20 00:06:10,223][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:11,425][root][INFO] - Iteration 0, response_id 0: Objective value: 7.526042649699715
[2025-09-20 00:06:11,444][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:13,276][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:13,277][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:13,280][root][INFO] - LLM usage: prompt_tokens = 505305, completion_tokens = 167312
[2025-09-20 00:06:13,281][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:14,334][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:14,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:14,344][root][INFO] - LLM usage: prompt_tokens = 505786, completion_tokens = 167406
[2025-09-20 00:06:14,346][root][INFO] - Iteration 0: Running Code 5926378856590427434
[2025-09-20 00:06:14,837][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:16,064][root][INFO] - Iteration 0, response_id 0: Objective value: 7.855928235404853
[2025-09-20 00:06:16,066][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:17,937][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:17,947][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:17,953][root][INFO] - LLM usage: prompt_tokens = 506897, completion_tokens = 167790
[2025-09-20 00:06:17,955][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:19,019][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:19,022][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:19,025][root][INFO] - LLM usage: prompt_tokens = 507473, completion_tokens = 167905
[2025-09-20 00:06:19,026][root][INFO] - Iteration 0: Running Code -4473102802507379492
[2025-09-20 00:06:19,518][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:22,233][root][INFO] - Iteration 0, response_id 0: Objective value: 6.712472049210957
[2025-09-20 00:06:22,234][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:24,184][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:24,186][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:24,187][root][INFO] - LLM usage: prompt_tokens = 508120, completion_tokens = 168305
[2025-09-20 00:06:24,188][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:25,760][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:25,764][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:25,770][root][INFO] - LLM usage: prompt_tokens = 508712, completion_tokens = 168440
[2025-09-20 00:06:25,773][root][INFO] - Iteration 0: Running Code 2392206453895037429
[2025-09-20 00:06:26,272][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:28,959][root][INFO] - Iteration 0, response_id 0: Objective value: 6.85041126148559
[2025-09-20 00:06:28,960][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:31,034][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:31,038][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:31,045][root][INFO] - LLM usage: prompt_tokens = 509340, completion_tokens = 168775
[2025-09-20 00:06:31,047][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:32,147][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:32,149][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:32,152][root][INFO] - LLM usage: prompt_tokens = 509862, completion_tokens = 168868
[2025-09-20 00:06:32,154][root][INFO] - Iteration 0: Running Code -5879946925052891659
[2025-09-20 00:06:32,681][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:35,043][root][INFO] - Iteration 0, response_id 0: Objective value: 7.9561361319529285
[2025-09-20 00:06:35,063][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:37,320][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:37,323][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:37,325][root][INFO] - LLM usage: prompt_tokens = 510862, completion_tokens = 169251
[2025-09-20 00:06:37,326][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:38,558][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:38,562][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:38,564][root][INFO] - LLM usage: prompt_tokens = 511437, completion_tokens = 169360
[2025-09-20 00:06:38,564][root][INFO] - Iteration 0: Running Code 5114494459923642989
[2025-09-20 00:06:39,063][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:39,101][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:06:39,101][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:40,987][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:40,991][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:40,998][root][INFO] - LLM usage: prompt_tokens = 512437, completion_tokens = 169726
[2025-09-20 00:06:41,000][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:42,067][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:42,071][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:42,076][root][INFO] - LLM usage: prompt_tokens = 512995, completion_tokens = 169804
[2025-09-20 00:06:42,079][root][INFO] - Iteration 0: Running Code 6730268617713587895
[2025-09-20 00:06:42,620][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:44,827][root][INFO] - Iteration 0, response_id 0: Objective value: 6.721014153023326
[2025-09-20 00:06:44,830][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:46,945][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:46,946][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:46,948][root][INFO] - LLM usage: prompt_tokens = 513964, completion_tokens = 170169
[2025-09-20 00:06:46,948][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:48,031][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:48,032][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:48,033][root][INFO] - LLM usage: prompt_tokens = 514521, completion_tokens = 170257
[2025-09-20 00:06:48,034][root][INFO] - Iteration 0: Running Code -3877411606833750352
[2025-09-20 00:06:48,600][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:51,385][root][INFO] - Iteration 0, response_id 0: Objective value: 12.643215651931495
[2025-09-20 00:06:51,386][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:53,355][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:53,358][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:53,364][root][INFO] - LLM usage: prompt_tokens = 515754, completion_tokens = 170703
[2025-09-20 00:06:53,366][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:06:54,457][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:06:54,459][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:06:54,460][root][INFO] - LLM usage: prompt_tokens = 516392, completion_tokens = 170800
[2025-09-20 00:06:54,461][root][INFO] - Iteration 0: Running Code 4005717905841543293
[2025-09-20 00:06:54,952][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:06:57,170][root][INFO] - Iteration 0, response_id 0: Objective value: 6.709559524290721
[2025-09-20 00:06:57,171][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:00,277][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:00,281][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:00,288][root][INFO] - LLM usage: prompt_tokens = 517085, completion_tokens = 171418
[2025-09-20 00:07:00,290][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:01,765][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:01,769][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:01,776][root][INFO] - LLM usage: prompt_tokens = 517895, completion_tokens = 171485
[2025-09-20 00:07:01,778][root][INFO] - Iteration 0: Running Code -5151021736175812348
[2025-09-20 00:07:02,289][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:07:02,328][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:07:02,329][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:04,859][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:04,863][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:04,871][root][INFO] - LLM usage: prompt_tokens = 518588, completion_tokens = 172032
[2025-09-20 00:07:04,873][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:06,547][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:06,551][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:06,558][root][INFO] - LLM usage: prompt_tokens = 519327, completion_tokens = 172144
[2025-09-20 00:07:06,560][root][INFO] - Iteration 0: Running Code -2216987983815059319
[2025-09-20 00:07:07,040][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:07:09,407][root][INFO] - Iteration 0, response_id 0: Objective value: 7.001413526438798
[2025-09-20 00:07:09,407][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:11,089][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:11,092][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:11,094][root][INFO] - LLM usage: prompt_tokens = 520001, completion_tokens = 172466
[2025-09-20 00:07:11,094][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:12,204][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:12,208][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:12,214][root][INFO] - LLM usage: prompt_tokens = 520515, completion_tokens = 172560
[2025-09-20 00:07:12,216][root][INFO] - Iteration 0: Running Code 8049473903517160583
[2025-09-20 00:07:12,687][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:07:14,989][root][INFO] - Iteration 0, response_id 0: Objective value: 7.021206854025191
[2025-09-20 00:07:15,016][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:17,597][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:17,598][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:17,601][root][INFO] - LLM usage: prompt_tokens = 522029, completion_tokens = 173045
[2025-09-20 00:07:17,602][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:18,780][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:18,784][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:18,790][root][INFO] - LLM usage: prompt_tokens = 522706, completion_tokens = 173159
[2025-09-20 00:07:18,792][root][INFO] - Iteration 0: Running Code -6417226812805519631
[2025-09-20 00:07:19,289][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:07:21,608][root][INFO] - Iteration 0, response_id 0: Objective value: 7.0758313887321
[2025-09-20 00:07:21,610][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:23,895][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:23,899][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:23,908][root][INFO] - LLM usage: prompt_tokens = 523850, completion_tokens = 173716
[2025-09-20 00:07:23,910][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:07:24,922][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:07:24,926][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:07:24,933][root][INFO] - LLM usage: prompt_tokens = 524599, completion_tokens = 173803
[2025-09-20 00:07:24,936][root][INFO] - Iteration 0: Running Code -1044299800320839672
[2025-09-20 00:07:25,426][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:08:07,556][root][INFO] - Iteration 0, response_id 0: Objective value: 8.187257663311748
[2025-09-20 00:08:07,557][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:08:10,351][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:08:10,355][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:08:10,363][root][INFO] - LLM usage: prompt_tokens = 525316, completion_tokens = 174401
[2025-09-20 00:08:10,364][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:08:11,485][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:08:11,490][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:08:11,497][root][INFO] - LLM usage: prompt_tokens = 526106, completion_tokens = 174489
[2025-09-20 00:08:11,499][root][INFO] - Iteration 0: Running Code 393943778205729008
[2025-09-20 00:08:12,016][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:09:12,030][root][INFO] - Error for response_id 0: Command '['python', '-u', 'D:\\MCTS-AHD-master/problems/tsp_constructive/eval.py', '50', 'D:\\MCTS-AHD-master', 'train']' timed out after 60.0 seconds
[2025-09-20 00:09:12,031][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:09:17,733][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:09:17,734][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:09:17,735][root][INFO] - LLM usage: prompt_tokens = 526804, completion_tokens = 174932
[2025-09-20 00:09:17,736][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:09:18,820][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:09:18,822][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:09:18,823][root][INFO] - LLM usage: prompt_tokens = 527434, completion_tokens = 175019
[2025-09-20 00:09:18,824][root][INFO] - Iteration 0: Running Code 2073024666204919825
[2025-09-20 00:09:19,319][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:10:00,277][root][INFO] - Iteration 0, response_id 0: Objective value: 6.55486604242239
[2025-09-20 00:10:00,299][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:02,566][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:02,567][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:02,570][root][INFO] - LLM usage: prompt_tokens = 528643, completion_tokens = 175470
[2025-09-20 00:10:02,570][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:03,700][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:03,701][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:03,703][root][INFO] - LLM usage: prompt_tokens = 529281, completion_tokens = 175581
[2025-09-20 00:10:03,703][root][INFO] - Iteration 0: Running Code -8255155424719691832
[2025-09-20 00:10:04,191][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:10:45,520][root][INFO] - Iteration 0, response_id 0: Objective value: 7.024329662539763
[2025-09-20 00:10:45,522][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:47,376][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:47,378][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:47,382][root][INFO] - LLM usage: prompt_tokens = 530299, completion_tokens = 175962
[2025-09-20 00:10:47,382][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:49,481][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:49,485][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:49,491][root][INFO] - LLM usage: prompt_tokens = 530872, completion_tokens = 176071
[2025-09-20 00:10:49,493][root][INFO] - Iteration 0: Running Code -5733955683696955716
[2025-09-20 00:10:49,998][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:10:52,862][root][INFO] - Iteration 0, response_id 0: Objective value: 6.454636877993263
[2025-09-20 00:10:52,863][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:54,673][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:54,675][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:54,681][root][INFO] - LLM usage: prompt_tokens = 532033, completion_tokens = 176471
[2025-09-20 00:10:54,683][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:10:55,959][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:10:55,963][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:10:55,969][root][INFO] - LLM usage: prompt_tokens = 532625, completion_tokens = 176603
[2025-09-20 00:10:55,972][root][INFO] - Iteration 0: Running Code -8166699349878116813
[2025-09-20 00:10:56,481][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:10:59,319][root][INFO] - Iteration 0, response_id 0: Objective value: 6.452079160416718
[2025-09-20 00:10:59,320][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:01,511][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:01,514][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:01,516][root][INFO] - LLM usage: prompt_tokens = 533282, completion_tokens = 177059
[2025-09-20 00:11:01,517][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:02,757][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:02,761][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:02,765][root][INFO] - LLM usage: prompt_tokens = 533930, completion_tokens = 177168
[2025-09-20 00:11:02,766][root][INFO] - Iteration 0: Running Code -8632361327578945207
[2025-09-20 00:11:03,266][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:05,955][root][INFO] - Iteration 0, response_id 0: Objective value: 7.000687658605691
[2025-09-20 00:11:05,956][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:07,683][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:07,687][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:07,693][root][INFO] - LLM usage: prompt_tokens = 534568, completion_tokens = 177508
[2025-09-20 00:11:07,695][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:08,919][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:08,920][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:08,922][root][INFO] - LLM usage: prompt_tokens = 535095, completion_tokens = 177619
[2025-09-20 00:11:08,923][root][INFO] - Iteration 0: Running Code -5504605769712381966
[2025-09-20 00:11:09,406][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:11,881][root][INFO] - Iteration 0, response_id 0: Objective value: 6.845512446880964
[2025-09-20 00:11:11,908][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:14,240][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:14,241][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:14,244][root][INFO] - LLM usage: prompt_tokens = 536558, completion_tokens = 178047
[2025-09-20 00:11:14,244][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:15,366][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:15,369][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:15,371][root][INFO] - LLM usage: prompt_tokens = 537173, completion_tokens = 178136
[2025-09-20 00:11:15,372][root][INFO] - Iteration 0: Running Code -2209004866523010443
[2025-09-20 00:11:15,889][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:18,779][root][INFO] - Iteration 0, response_id 0: Objective value: 6.696895069414049
[2025-09-20 00:11:18,781][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:20,574][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:20,578][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:20,580][root][INFO] - LLM usage: prompt_tokens = 538287, completion_tokens = 178504
[2025-09-20 00:11:20,581][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:21,545][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:21,549][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:21,555][root][INFO] - LLM usage: prompt_tokens = 538842, completion_tokens = 178594
[2025-09-20 00:11:21,557][root][INFO] - Iteration 0: Running Code -4554098729691911699
[2025-09-20 00:11:22,052][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:23,391][root][INFO] - Iteration 0, response_id 0: Objective value: 6.864319339118359
[2025-09-20 00:11:23,392][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:25,493][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:25,496][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:25,498][root][INFO] - LLM usage: prompt_tokens = 539415, completion_tokens = 178997
[2025-09-20 00:11:25,499][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:27,392][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:27,396][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:27,402][root][INFO] - LLM usage: prompt_tokens = 540010, completion_tokens = 179091
[2025-09-20 00:11:27,405][root][INFO] - Iteration 0: Running Code -4969143843938602794
[2025-09-20 00:11:28,178][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:29,474][root][INFO] - Iteration 0, response_id 0: Objective value: 34.385363747720184
[2025-09-20 00:11:29,475][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:31,306][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:31,310][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:31,316][root][INFO] - LLM usage: prompt_tokens = 540564, completion_tokens = 179423
[2025-09-20 00:11:31,318][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:32,477][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:32,478][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:32,480][root][INFO] - LLM usage: prompt_tokens = 541088, completion_tokens = 179540
[2025-09-20 00:11:32,480][root][INFO] - Iteration 0: Running Code -4765579251203435213
[2025-09-20 00:11:32,971][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:33,007][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:11:33,007][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:34,364][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:34,368][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:34,375][root][INFO] - LLM usage: prompt_tokens = 541642, completion_tokens = 179807
[2025-09-20 00:11:34,376][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:35,308][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:35,311][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:35,313][root][INFO] - LLM usage: prompt_tokens = 542101, completion_tokens = 179877
[2025-09-20 00:11:35,313][root][INFO] - Iteration 0: Running Code 4600927036772216103
[2025-09-20 00:11:35,785][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:37,033][root][INFO] - Iteration 0, response_id 0: Objective value: 25.828176590994936
[2025-09-20 00:11:37,061][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:38,859][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:38,860][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:38,862][root][INFO] - LLM usage: prompt_tokens = 543308, completion_tokens = 180211
[2025-09-20 00:11:38,863][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:39,893][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:39,896][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:39,898][root][INFO] - LLM usage: prompt_tokens = 543834, completion_tokens = 180319
[2025-09-20 00:11:39,898][root][INFO] - Iteration 0: Running Code 1636198799650020713
[2025-09-20 00:11:40,387][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:41,669][root][INFO] - Iteration 0, response_id 0: Objective value: 6.643530465948105
[2025-09-20 00:11:41,671][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:43,380][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:43,381][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:43,383][root][INFO] - LLM usage: prompt_tokens = 544746, completion_tokens = 180619
[2025-09-20 00:11:43,383][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:44,548][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:44,552][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:44,553][root][INFO] - LLM usage: prompt_tokens = 545238, completion_tokens = 180739
[2025-09-20 00:11:44,553][root][INFO] - Iteration 0: Running Code 1339819953708283573
[2025-09-20 00:11:45,065][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:46,938][root][INFO] - Iteration 0, response_id 0: Objective value: 12.711574866723364
[2025-09-20 00:11:46,939][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:48,790][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:48,793][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:48,801][root][INFO] - LLM usage: prompt_tokens = 546346, completion_tokens = 181082
[2025-09-20 00:11:48,803][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:49,871][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:49,876][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:49,882][root][INFO] - LLM usage: prompt_tokens = 546881, completion_tokens = 181184
[2025-09-20 00:11:49,884][root][INFO] - Iteration 0: Running Code 1598586048205637422
[2025-09-20 00:11:50,389][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:52,605][root][INFO] - Iteration 0, response_id 0: Objective value: 6.656038202478211
[2025-09-20 00:11:52,606][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:54,565][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:54,569][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:54,576][root][INFO] - LLM usage: prompt_tokens = 547507, completion_tokens = 181610
[2025-09-20 00:11:54,578][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:55,811][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:55,812][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:55,814][root][INFO] - LLM usage: prompt_tokens = 548125, completion_tokens = 181723
[2025-09-20 00:11:55,814][root][INFO] - Iteration 0: Running Code -3467032477113279990
[2025-09-20 00:11:56,325][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:11:58,157][root][INFO] - Iteration 0, response_id 0: Objective value: 6.567923322555508
[2025-09-20 00:11:58,158][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:11:59,833][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:11:59,838][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:11:59,845][root][INFO] - LLM usage: prompt_tokens = 548732, completion_tokens = 182067
[2025-09-20 00:11:59,846][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:00,917][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:00,920][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:00,923][root][INFO] - LLM usage: prompt_tokens = 549263, completion_tokens = 182181
[2025-09-20 00:12:00,924][root][INFO] - Iteration 0: Running Code 8835314730374816013
[2025-09-20 00:12:01,412][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:03,274][root][INFO] - Iteration 0, response_id 0: Objective value: 7.156274463383891
[2025-09-20 00:12:03,303][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:05,426][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:05,431][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:05,439][root][INFO] - LLM usage: prompt_tokens = 550544, completion_tokens = 182542
[2025-09-20 00:12:05,441][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:06,581][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:06,585][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:06,591][root][INFO] - LLM usage: prompt_tokens = 551097, completion_tokens = 182656
[2025-09-20 00:12:06,593][root][INFO] - Iteration 0: Running Code -3405151747627840940
[2025-09-20 00:12:07,124][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:08,982][root][INFO] - Iteration 0, response_id 0: Objective value: 6.481316824912309
[2025-09-20 00:12:08,984][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:10,745][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:10,750][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:10,756][root][INFO] - LLM usage: prompt_tokens = 552149, completion_tokens = 183065
[2025-09-20 00:12:10,758][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:11,833][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:11,837][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:11,842][root][INFO] - LLM usage: prompt_tokens = 552750, completion_tokens = 183191
[2025-09-20 00:12:11,845][root][INFO] - Iteration 0: Running Code 3533889510154199280
[2025-09-20 00:12:12,360][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:14,546][root][INFO] - Iteration 0, response_id 0: Objective value: 6.463484853997896
[2025-09-20 00:12:14,547][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:16,605][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:16,609][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:16,615][root][INFO] - LLM usage: prompt_tokens = 553298, completion_tokens = 183586
[2025-09-20 00:12:16,617][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:17,770][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:17,774][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:17,775][root][INFO] - LLM usage: prompt_tokens = 553885, completion_tokens = 183682
[2025-09-20 00:12:17,776][root][INFO] - Iteration 0: Running Code 7632841168201230612
[2025-09-20 00:12:18,436][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:20,557][root][INFO] - Iteration 0, response_id 0: Objective value: 9.18321661169919
[2025-09-20 00:12:20,558][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:21,778][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:21,783][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:21,789][root][INFO] - LLM usage: prompt_tokens = 554414, completion_tokens = 183909
[2025-09-20 00:12:21,791][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:22,922][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:22,926][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:22,931][root][INFO] - LLM usage: prompt_tokens = 554833, completion_tokens = 184019
[2025-09-20 00:12:22,933][root][INFO] - Iteration 0: Running Code 430744194746703543
[2025-09-20 00:12:23,474][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:24,263][root][INFO] - Iteration 0, response_id 0: Objective value: 7.59713168325583
[2025-09-20 00:12:24,292][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:26,080][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:26,084][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:26,093][root][INFO] - LLM usage: prompt_tokens = 556036, completion_tokens = 184341
[2025-09-20 00:12:26,095][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:27,455][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:27,456][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:27,457][root][INFO] - LLM usage: prompt_tokens = 556550, completion_tokens = 184439
[2025-09-20 00:12:27,458][root][INFO] - Iteration 0: Running Code 8955643624005726403
[2025-09-20 00:12:27,953][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:30,303][root][INFO] - Iteration 0, response_id 0: Objective value: 8.613121554372182
[2025-09-20 00:12:30,306][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:32,279][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:32,280][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:32,283][root][INFO] - LLM usage: prompt_tokens = 557743, completion_tokens = 184878
[2025-09-20 00:12:32,283][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:33,375][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:33,379][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:33,385][root][INFO] - LLM usage: prompt_tokens = 558374, completion_tokens = 184992
[2025-09-20 00:12:33,387][root][INFO] - Iteration 0: Running Code -7701110945024212551
[2025-09-20 00:12:33,877][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:36,614][root][INFO] - Iteration 0, response_id 0: Objective value: 6.697517360491094
[2025-09-20 00:12:36,615][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:39,120][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:39,125][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:39,133][root][INFO] - LLM usage: prompt_tokens = 559046, completion_tokens = 185467
[2025-09-20 00:12:39,134][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:40,196][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:40,201][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:40,207][root][INFO] - LLM usage: prompt_tokens = 559713, completion_tokens = 185542
[2025-09-20 00:12:40,209][root][INFO] - Iteration 0: Running Code 121149484699738444
[2025-09-20 00:12:40,713][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:42,642][root][INFO] - Iteration 0, response_id 0: Objective value: 7.2713007904343705
[2025-09-20 00:12:42,643][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:44,178][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:44,182][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:44,190][root][INFO] - LLM usage: prompt_tokens = 560366, completion_tokens = 185841
[2025-09-20 00:12:44,191][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:45,275][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:45,279][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:45,286][root][INFO] - LLM usage: prompt_tokens = 560857, completion_tokens = 185947
[2025-09-20 00:12:45,288][root][INFO] - Iteration 0: Running Code -5602738398241445687
[2025-09-20 00:12:45,799][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:47,160][root][INFO] - Iteration 0, response_id 0: Objective value: 10.3306519520781
[2025-09-20 00:12:47,188][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:49,060][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:49,063][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:49,067][root][INFO] - LLM usage: prompt_tokens = 562165, completion_tokens = 186337
[2025-09-20 00:12:49,067][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:50,200][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:50,204][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:50,210][root][INFO] - LLM usage: prompt_tokens = 562742, completion_tokens = 186459
[2025-09-20 00:12:50,212][root][INFO] - Iteration 0: Running Code 7296801726079845666
[2025-09-20 00:12:50,695][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:52,950][root][INFO] - Iteration 0, response_id 0: Objective value: 7.051235113888976
[2025-09-20 00:12:52,952][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:54,466][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:54,469][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:54,475][root][INFO] - LLM usage: prompt_tokens = 563617, completion_tokens = 186746
[2025-09-20 00:12:54,476][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:55,519][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:55,523][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:55,528][root][INFO] - LLM usage: prompt_tokens = 564096, completion_tokens = 186837
[2025-09-20 00:12:55,530][root][INFO] - Iteration 0: Running Code -8679387810342842970
[2025-09-20 00:12:56,023][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:12:57,817][root][INFO] - Iteration 0, response_id 0: Objective value: 6.716073373950344
[2025-09-20 00:12:57,818][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:12:59,471][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:12:59,475][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:12:59,483][root][INFO] - LLM usage: prompt_tokens = 565091, completion_tokens = 187202
[2025-09-20 00:12:59,484][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:00,754][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:00,758][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:00,762][root][INFO] - LLM usage: prompt_tokens = 565648, completion_tokens = 187317
[2025-09-20 00:13:00,763][root][INFO] - Iteration 0: Running Code 6698035385656644058
[2025-09-20 00:13:01,259][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:03,450][root][INFO] - Iteration 0, response_id 0: Objective value: 7.618131524748699
[2025-09-20 00:13:03,451][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:05,493][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:05,495][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:05,500][root][INFO] - LLM usage: prompt_tokens = 566179, completion_tokens = 187714
[2025-09-20 00:13:05,501][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:06,403][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:06,407][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:06,413][root][INFO] - LLM usage: prompt_tokens = 566776, completion_tokens = 187806
[2025-09-20 00:13:06,415][root][INFO] - Iteration 0: Running Code 6367551943797499398
[2025-09-20 00:13:06,921][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-20 00:13:06,959][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:13:06,959][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:09,017][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:09,022][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:09,024][root][INFO] - LLM usage: prompt_tokens = 567307, completion_tokens = 188199
[2025-09-20 00:13:09,024][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:10,164][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:10,168][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:10,174][root][INFO] - LLM usage: prompt_tokens = 567892, completion_tokens = 188323
[2025-09-20 00:13:10,176][root][INFO] - Iteration 0: Running Code -1433643211190493989
[2025-09-20 00:13:10,673][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:11,932][root][INFO] - Iteration 0, response_id 0: Objective value: 6.839541208769473
[2025-09-20 00:13:11,933][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:13,334][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:13,338][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:13,344][root][INFO] - LLM usage: prompt_tokens = 568404, completion_tokens = 188594
[2025-09-20 00:13:13,346][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:14,727][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:14,731][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:14,736][root][INFO] - LLM usage: prompt_tokens = 568867, completion_tokens = 188690
[2025-09-20 00:13:14,738][root][INFO] - Iteration 0: Running Code 3898987039131943924
[2025-09-20 00:13:15,249][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:16,487][root][INFO] - Iteration 0, response_id 0: Objective value: 8.827442341771173
[2025-09-20 00:13:16,517][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:18,250][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:18,254][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:18,263][root][INFO] - LLM usage: prompt_tokens = 569973, completion_tokens = 188978
[2025-09-20 00:13:18,265][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:19,172][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:19,175][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:19,179][root][INFO] - LLM usage: prompt_tokens = 570453, completion_tokens = 189075
[2025-09-20 00:13:19,180][root][INFO] - Iteration 0: Running Code -2242241269613606887
[2025-09-20 00:13:19,696][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:21,051][root][INFO] - Iteration 0, response_id 0: Objective value: 6.956084426842899
[2025-09-20 00:13:21,053][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:24,036][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:24,040][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:24,049][root][INFO] - LLM usage: prompt_tokens = 572306, completion_tokens = 189465
[2025-09-20 00:13:24,051][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:25,154][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:25,155][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:25,157][root][INFO] - LLM usage: prompt_tokens = 572892, completion_tokens = 189547
[2025-09-20 00:13:25,158][root][INFO] - Iteration 0: Running Code -4834733275977322663
[2025-09-20 00:13:25,690][root][INFO] - Iteration -1: Code Run -1 execution error!
[2025-09-20 00:13:25,733][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:13:25,734][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:27,267][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:27,268][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:27,271][root][INFO] - LLM usage: prompt_tokens = 575049, completion_tokens = 189767
[2025-09-20 00:13:27,271][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:28,280][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:28,282][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:28,283][root][INFO] - LLM usage: prompt_tokens = 575461, completion_tokens = 189867
[2025-09-20 00:13:28,284][root][INFO] - Iteration 0: Running Code 2795543591707311007
[2025-09-20 00:13:28,792][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:51,976][root][INFO] - Iteration 0, response_id 0: Objective value: 7.240666997298963
[2025-09-20 00:13:51,977][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:53,871][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:53,875][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:53,883][root][INFO] - LLM usage: prompt_tokens = 576462, completion_tokens = 190152
[2025-09-20 00:13:53,885][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:55,062][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:55,065][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:55,067][root][INFO] - LLM usage: prompt_tokens = 576939, completion_tokens = 190250
[2025-09-20 00:13:55,067][root][INFO] - Iteration 0: Running Code 3993862436588725018
[2025-09-20 00:13:55,554][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:13:56,959][root][INFO] - Iteration 0, response_id 0: Objective value: 7.907996551068635
[2025-09-20 00:13:56,960][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:13:59,220][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:13:59,225][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:13:59,232][root][INFO] - LLM usage: prompt_tokens = 577953, completion_tokens = 190648
[2025-09-20 00:13:59,234][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:00,704][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:00,733][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:00,740][root][INFO] - LLM usage: prompt_tokens = 578543, completion_tokens = 190724
[2025-09-20 00:14:00,742][root][INFO] - Iteration 0: Running Code 2092186387436093664
[2025-09-20 00:14:01,254][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:03,592][root][INFO] - Iteration 0, response_id 0: Objective value: 6.601187643661699
[2025-09-20 00:14:03,593][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:05,908][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:05,913][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:05,920][root][INFO] - LLM usage: prompt_tokens = 579110, completion_tokens = 191065
[2025-09-20 00:14:05,921][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:07,124][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:07,128][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:07,134][root][INFO] - LLM usage: prompt_tokens = 579643, completion_tokens = 191160
[2025-09-20 00:14:07,136][root][INFO] - Iteration 0: Running Code -7652543497050170191
[2025-09-20 00:14:07,665][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:09,070][root][INFO] - Iteration 0, response_id 0: Objective value: 8.565126992541366
[2025-09-20 00:14:09,071][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:10,689][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:10,693][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:10,700][root][INFO] - LLM usage: prompt_tokens = 580191, completion_tokens = 191473
[2025-09-20 00:14:10,701][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:11,689][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:11,693][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:11,699][root][INFO] - LLM usage: prompt_tokens = 580696, completion_tokens = 191563
[2025-09-20 00:14:11,701][root][INFO] - Iteration 0: Running Code 7648794658277453234
[2025-09-20 00:14:12,199][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:12,985][root][INFO] - Iteration 0, response_id 0: Objective value: 10.055214979339718
[2025-09-20 00:14:13,015][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:15,115][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:15,119][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:15,127][root][INFO] - LLM usage: prompt_tokens = 581880, completion_tokens = 191898
[2025-09-20 00:14:15,129][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:16,139][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:16,143][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:16,148][root][INFO] - LLM usage: prompt_tokens = 582402, completion_tokens = 191973
[2025-09-20 00:14:16,151][root][INFO] - Iteration 0: Running Code 6851489967757839937
[2025-09-20 00:14:16,647][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:18,061][root][INFO] - Iteration 0, response_id 0: Objective value: 12.086410147206825
[2025-09-20 00:14:18,063][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:19,759][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:19,764][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:19,771][root][INFO] - LLM usage: prompt_tokens = 583430, completion_tokens = 192299
[2025-09-20 00:14:19,773][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:20,893][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:20,897][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:20,903][root][INFO] - LLM usage: prompt_tokens = 583948, completion_tokens = 192397
[2025-09-20 00:14:20,905][root][INFO] - Iteration 0: Running Code 1199877888079428471
[2025-09-20 00:14:21,405][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:45,430][root][INFO] - Iteration 0, response_id 0: Objective value: 7.165618245159941
[2025-09-20 00:14:45,431][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:48,269][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:48,271][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:48,273][root][INFO] - LLM usage: prompt_tokens = 584435, completion_tokens = 192709
[2025-09-20 00:14:48,273][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:49,850][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:49,854][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:49,860][root][INFO] - LLM usage: prompt_tokens = 584939, completion_tokens = 192809
[2025-09-20 00:14:49,862][root][INFO] - Iteration 0: Running Code 8179580517403850400
[2025-09-20 00:14:50,376][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:50,412][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:14:50,413][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:52,119][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:52,123][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:52,129][root][INFO] - LLM usage: prompt_tokens = 585426, completion_tokens = 193121
[2025-09-20 00:14:52,131][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:53,143][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:53,147][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:53,152][root][INFO] - LLM usage: prompt_tokens = 585930, completion_tokens = 193199
[2025-09-20 00:14:53,155][root][INFO] - Iteration 0: Running Code 4103896859772855988
[2025-09-20 00:14:53,657][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:14:53,772][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:14:53,772][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:55,621][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:55,622][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:55,624][root][INFO] - LLM usage: prompt_tokens = 586417, completion_tokens = 193540
[2025-09-20 00:14:55,625][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:14:57,053][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:14:57,057][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:14:57,063][root][INFO] - LLM usage: prompt_tokens = 586950, completion_tokens = 193661
[2025-09-20 00:14:57,064][root][INFO] - Iteration 0: Running Code 6666111197186966642
[2025-09-20 00:14:57,570][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:15:19,940][root][INFO] - Iteration 0, response_id 0: Objective value: 8.729653177945096
[2025-09-20 00:15:19,941][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:21,752][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:21,755][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:21,763][root][INFO] - LLM usage: prompt_tokens = 587418, completion_tokens = 193930
[2025-09-20 00:15:21,764][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:22,811][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:22,815][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:22,821][root][INFO] - LLM usage: prompt_tokens = 587874, completion_tokens = 194013
[2025-09-20 00:15:22,823][root][INFO] - Iteration 0: Running Code -9151210844363704109
[2025-09-20 00:15:23,304][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:15:24,247][root][INFO] - Iteration 0, response_id 0: Objective value: 8.055761301607806
[2025-09-20 00:15:24,266][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:26,178][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:26,181][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:26,183][root][INFO] - LLM usage: prompt_tokens = 588894, completion_tokens = 194422
[2025-09-20 00:15:26,184][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:27,290][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:27,295][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:27,300][root][INFO] - LLM usage: prompt_tokens = 589495, completion_tokens = 194510
[2025-09-20 00:15:27,303][root][INFO] - Iteration 0: Running Code -9134455719578266883
[2025-09-20 00:15:27,944][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:15:52,621][root][INFO] - Iteration 0, response_id 0: Objective value: 7.247805442575243
[2025-09-20 00:15:52,622][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:54,852][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:54,857][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:54,863][root][INFO] - LLM usage: prompt_tokens = 590088, completion_tokens = 194907
[2025-09-20 00:15:54,865][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:15:55,943][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:15:55,947][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:15:55,953][root][INFO] - LLM usage: prompt_tokens = 590677, completion_tokens = 195038
[2025-09-20 00:15:55,955][root][INFO] - Iteration 0: Running Code 8837272403226823082
[2025-09-20 00:15:56,466][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:16:20,301][root][INFO] - Iteration 0, response_id 0: Objective value: 7.065601539250629
[2025-09-20 00:16:20,302][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:16:22,472][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:16:22,473][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:16:22,475][root][INFO] - LLM usage: prompt_tokens = 591251, completion_tokens = 195355
[2025-09-20 00:16:22,475][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:16:23,595][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:16:23,599][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:16:23,605][root][INFO] - LLM usage: prompt_tokens = 591760, completion_tokens = 195445
[2025-09-20 00:16:23,607][root][INFO] - Iteration 0: Running Code 3722155570789314681
[2025-09-20 00:16:24,112][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:16:50,696][root][INFO] - Iteration 0, response_id 0: Objective value: 7.656654412873803
[2025-09-20 00:16:50,719][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:01,183][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:01,187][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:01,195][root][INFO] - LLM usage: prompt_tokens = 592679, completion_tokens = 195812
[2025-09-20 00:17:01,197][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:02,265][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:02,269][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:02,275][root][INFO] - LLM usage: prompt_tokens = 593238, completion_tokens = 195907
[2025-09-20 00:17:02,277][root][INFO] - Iteration 0: Running Code 4145075373212982049
[2025-09-20 00:17:02,804][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:28,200][root][INFO] - Iteration 0, response_id 0: Objective value: 7.2973791097418665
[2025-09-20 00:17:28,203][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:30,202][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:30,206][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:30,214][root][INFO] - LLM usage: prompt_tokens = 594231, completion_tokens = 196329
[2025-09-20 00:17:30,215][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:31,370][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:31,371][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:31,373][root][INFO] - LLM usage: prompt_tokens = 594845, completion_tokens = 196432
[2025-09-20 00:17:31,373][root][INFO] - Iteration 0: Running Code -2796902542431832217
[2025-09-20 00:17:31,954][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:35,218][root][INFO] - Iteration 0, response_id 0: Objective value: 16.82589178421038
[2025-09-20 00:17:35,219][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:37,160][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:37,164][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:37,171][root][INFO] - LLM usage: prompt_tokens = 595356, completion_tokens = 196806
[2025-09-20 00:17:37,172][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:38,142][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:38,144][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:38,146][root][INFO] - LLM usage: prompt_tokens = 595922, completion_tokens = 196897
[2025-09-20 00:17:38,146][root][INFO] - Iteration 0: Running Code -3624769095222156495
[2025-09-20 00:17:38,678][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:38,724][root][INFO] - Iteration 0, response_id 0: Objective value: inf
[2025-09-20 00:17:38,724][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:40,820][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:40,822][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:40,824][root][INFO] - LLM usage: prompt_tokens = 596433, completion_tokens = 197204
[2025-09-20 00:17:40,824][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:42,045][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:42,049][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:42,057][root][INFO] - LLM usage: prompt_tokens = 596932, completion_tokens = 197301
[2025-09-20 00:17:42,059][root][INFO] - Iteration 0: Running Code -4969846231200504122
[2025-09-20 00:17:42,625][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:43,625][root][INFO] - Iteration 0, response_id 0: Objective value: 7.724377162975495
[2025-09-20 00:17:43,626][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:44,983][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:44,985][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:44,986][root][INFO] - LLM usage: prompt_tokens = 597424, completion_tokens = 197550
[2025-09-20 00:17:44,987][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:45,961][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:45,965][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:45,969][root][INFO] - LLM usage: prompt_tokens = 597865, completion_tokens = 197634
[2025-09-20 00:17:45,971][root][INFO] - Iteration 0: Running Code 3030538467708326744
[2025-09-20 00:17:46,518][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:47,535][root][INFO] - Iteration 0, response_id 0: Objective value: 7.653289685129993
[2025-09-20 00:17:47,580][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:49,050][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:49,054][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:49,060][root][INFO] - LLM usage: prompt_tokens = 598702, completion_tokens = 197904
[2025-09-20 00:17:49,061][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:50,067][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:50,072][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:50,078][root][INFO] - LLM usage: prompt_tokens = 599164, completion_tokens = 197995
[2025-09-20 00:17:50,080][root][INFO] - Iteration 0: Running Code -3121578132524536687
[2025-09-20 00:17:50,649][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:17:51,673][root][INFO] - Iteration 0, response_id 0: Objective value: 8.790924795061937
[2025-09-20 00:17:51,675][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:53,907][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:53,912][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:53,922][root][INFO] - LLM usage: prompt_tokens = 600395, completion_tokens = 198504
[2025-09-20 00:17:53,924][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:17:55,078][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:17:55,080][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:17:55,082][root][INFO] - LLM usage: prompt_tokens = 601096, completion_tokens = 198592
[2025-09-20 00:17:55,082][root][INFO] - Iteration 0: Running Code 6579974812295163482
[2025-09-20 00:17:55,647][root][INFO] - Iteration -1: Code Run -1 successful!
[2025-09-20 00:18:40,000][root][INFO] - Iteration 0, response_id 0: Objective value: 6.665252224219903
[2025-09-20 00:18:40,001][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:18:43,371][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:18:43,375][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:18:43,383][root][INFO] - LLM usage: prompt_tokens = 601786, completion_tokens = 199236
[2025-09-20 00:18:43,385][LiteLLM][INFO] - 
LiteLLM completion() model= codestral-latest; provider = mistral
[2025-09-20 00:18:44,581][httpx][INFO] - HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
[2025-09-20 00:18:44,582][LiteLLM][INFO] - Wrapper: Completed Call, calling success_handler
[2025-09-20 00:18:44,584][root][INFO] - LLM usage: prompt_tokens = 602622, completion_tokens = 199354
[2025-09-20 00:18:44,585][root][INFO] - Iteration 0: Running Code -9173603818654003492
[2025-09-20 00:18:45,236][root][INFO] - Iteration -1: Code Run -1 successful!
