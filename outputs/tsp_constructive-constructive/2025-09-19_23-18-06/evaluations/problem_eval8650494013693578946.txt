def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    def node_degree(node):
        return sum(1 for d in distance_matrix[node] if d > 0)

    def locality(node, unvisited):
        if len(unvisited) == 1:
            return 1.0
        remaining_nodes = unvisited - {node}
        return 1.0 / (sum(distance_matrix[node][n] for n in remaining_nodes) / len(remaining_nodes) + 1e-6)

    def novelty_bonus(node, unvisited, current):
        if len(unvisited) <= 2:
            return 0.0
        avg_dist = sum(distance_matrix[current][n] for n in unvisited) / len(unvisited)
        return (distance_matrix[current][node] - avg_dist) / avg_dist if avg_dist > 0 else 0.0

    def reinforcement_weight(node, unvisited, current, history):
        if not history:
            return 1.0
        freq = history.get(node, 0)
        return 1.0 / (1.0 + 0.1 * freq)

    history = {}
    candidates = []
    for node in unvisited_nodes:
        distance = distance_matrix[current_node][node]
        degree = node_degree(node)
        local = locality(node, unvisited_nodes)
        bonus = novelty_bonus(node, unvisited_nodes, current_node)
        r_weight = reinforcement_weight(node, unvisited_nodes, current_node, history)

        weight_dist = 0.4 if len(unvisited_nodes) > 4 else 0.2
        weight_degree = 0.3 if len(unvisited_nodes) > 4 else 0.4
        weight_local = 0.3 if len(unvisited_nodes) > 4 else 0.4

        score = (weight_dist * distance + weight_degree * (1.0 / (degree + 1e-6)) + weight_local * (1.0 / (local + 1e-6))) * (1.0 + 0.3 * bonus) * r_weight
        candidates.append((node, score))

    next_node, _ = min(candidates, key=lambda x: x[1])
    history[next_node] = history.get(next_node, 0) + 1
    return next_node
