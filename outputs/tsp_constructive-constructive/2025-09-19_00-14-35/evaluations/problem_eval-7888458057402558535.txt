import random
import math

def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = remaining_nodes / total_nodes

    # Dynamic neighborhood size with probabilistic adjustment
    base_neighborhood = max(1, int(2 + 3 * (1 - exploration_factor)))
    neighborhood_size = min(base_neighborhood + random.randint(-1, 1), len(unvisited_nodes))
    candidates = sorted(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])[:neighborhood_size]

    # Evaluate candidates using hybrid metric
    def evaluate_node(node):
        current_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]

        # Connectivity score (normalized variance of distances to remaining nodes)
        if remaining_nodes > 1:
            remaining_dists = [distance_matrix[node][n] for n in unvisited_nodes if n != node]
            mean_dist = sum(remaining_dists) / (remaining_nodes - 1)
            variance = sum((d - mean_dist) ** 2 for d in remaining_dists) / (remaining_nodes - 1)
            normalized_variance = variance / (mean_dist + 1e-6)  # Avoid division by zero
        else:
            normalized_variance = 0

        # Dynamic weights with non-linear scaling
        weight_dist = 0.5 - 0.3 * exploration_factor**1.5
        weight_connectivity = 0.3 + 0.4 * exploration_factor**1.5
        weight_penalty = 0.2 + 0.2 * (1 - exploration_factor**1.5)

        # Hybrid metric with probabilistic component
        base_score = (weight_dist * current_dist +
                     weight_connectivity * normalized_variance -
                     weight_penalty * (dest_dist ** (1 + 0.3 * exploration_factor)))

        # Add probabilistic perturbation based on exploration factor
        perturbation = random.uniform(-0.1, 0.1) * exploration_factor
        return base_score + perturbation

    # Select with probabilistic softmax
    scores = [evaluate_node(node) for node in candidates]
    min_score = min(scores)
    max_score = max(scores)
    normalized_scores = [(max_score - s) / (max_score - min_score + 1e-6) for s in scores]  # Invert for minimization

    # Softmax selection with temperature based on exploration
    temperature = 1.0 - 0.5 * exploration_factor
    exp_scores = [math.exp(s / temperature) for s in normalized_scores]
    sum_exp = sum(exp_scores)
    probabilities = [e / sum_exp for e in exp_scores]
    next_node = random.choices(candidates, weights=probabilities, k=1)[0]

    return next_node
