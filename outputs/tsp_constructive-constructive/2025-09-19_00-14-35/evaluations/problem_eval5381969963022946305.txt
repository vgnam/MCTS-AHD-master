def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = remaining_nodes / total_nodes

    # Dynamic neighborhood size based on both distance and connectivity
    base_size = max(1, int(3 + 2 * (1 - exploration_factor)))
    connectivity_bias = 0.3 + 0.6 * exploration_factor
    neighborhood_size = max(1, int(base_size * (1 + connectivity_bias)))

    # Candidate selection with distance and connectivity filtering
    candidates = sorted(unvisited_nodes,
                       key=lambda node: (1 - connectivity_bias) * distance_matrix[current_node][node] +
                                       connectivity_bias * sum(distance_matrix[node][n] for n in unvisited_nodes if n != node))[:neighborhood_size]

    # Evaluate candidates with novel metrics
    def evaluate_node(node):
        current_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]

        # Connectivity score (normalized variance of distances to remaining nodes)
        if remaining_nodes > 1:
            remaining_dists = [distance_matrix[node][n] for n in unvisited_nodes if n != node]
            mean_dist = sum(remaining_dists) / (remaining_nodes - 1)
            variance = sum((d - mean_dist) ** 2 for d in remaining_dists) / (remaining_nodes - 1)
            normalized_variance = variance / (mean_dist + 1e-6)
        else:
            normalized_variance = 0

        # Path diversity term (inverse of average distance to already visited nodes)
        visited_nodes = [n for n in range(total_nodes) if n not in unvisited_nodes and n != current_node]
        if visited_nodes:
            diversity = 1 / (sum(distance_matrix[node][n] for n in visited_nodes) / len(visited_nodes) + 1e-6)
        else:
            diversity = 1

        # Dynamic weights with novel scaling
        weight_dist = 0.3 - 0.2 * exploration_factor
        weight_connectivity = 0.4 + 0.4 * exploration_factor
        weight_penalty = 0.2 + 0.2 * (1 - exploration_factor)
        weight_diversity = 0.1 + 0.2 * exploration_factor

        return (weight_dist * current_dist +
                weight_connectivity * normalized_variance -
                weight_penalty * (dest_dist ** (1 + 0.3 * exploration_factor)) +
                weight_diversity * diversity)

    next_node = min(candidates, key=lambda node: evaluate_node(node))
    return next_node
