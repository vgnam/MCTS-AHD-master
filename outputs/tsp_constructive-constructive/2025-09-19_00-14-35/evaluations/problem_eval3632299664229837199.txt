def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = remaining_nodes / total_nodes

    # Dynamic neighborhood with probabilistic selection
    neighborhood_size = max(1, int(2 + 3 * (1 - exploration_factor)))
    candidates = sorted(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])[:neighborhood_size]

    # Adaptive weights with novelty factor
    alpha = 0.5 + 0.3 * (1 - exploration_factor)  # Immediate distance weight
    beta = 0.3 - 0.1 * (1 - exploration_factor)   # Destination bias weight
    gamma = 0.2  # Penalty for recent visits
    delta = 0.1 * (1 - exploration_factor)        # Novelty factor

    # Track recent visits (simplified memory)
    recent_visits = set()
    if hasattr(select_next_node, 'last_visited'):
        recent_visits.add(select_next_node.last_visited)

    def evaluate_node(node):
        immediate_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]
        novelty = 1 / (1 + len(recent_visits)) if node not in recent_visits else 0
        return (alpha * immediate_dist) + (beta * dest_dist) - (gamma * (1 if node in recent_visits else 0)) + (delta * novelty)

    # Probabilistic selection
    scores = [evaluate_node(node) for node in candidates]
    min_score = min(scores)
    max_score = max(scores)
    normalized_scores = [(max_score - score) / (max_score - min_score + 1e-10) for score in scores]
    probabilities = [score / sum(normalized_scores) for score in normalized_scores]
    next_node = np.random.choice(candidates, p=probabilities)

    # Update memory
    select_next_node.last_visited = next_node
    return next_node
