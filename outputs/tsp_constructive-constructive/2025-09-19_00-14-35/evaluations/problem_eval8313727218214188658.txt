def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = remaining_nodes / total_nodes

    # Calculate distance entropy for more nuanced neighborhood scaling
    distances = [distance_matrix[current_node][node] for node in unvisited_nodes]
    entropy = sum(d * (1 - d/sum(distances)) for d in distances) if distances else 0

    # Dynamic neighborhood size with entropy consideration
    base_size = max(1, int(2 + 3 * (1 - exploration_factor)))
    neighborhood_size = min(base_size + int(entropy * 2), len(unvisited_nodes))
    candidates = sorted(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])[:neighborhood_size]

    # Adaptive weights with entropy influence
    alpha = 0.6 + 0.2 * (1 - exploration_factor) + 0.1 * entropy
    beta = 0.4 - 0.2 * (1 - exploration_factor) - 0.1 * entropy
    gamma = 0.2 + 0.1 * (1 - exploration_factor)

    # Temperature for probabilistic selection
    temperature = 1 - exploration_factor

    def evaluate_node(node):
        immediate_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]
        revisit_penalty = gamma * (1 if node in unvisited_nodes else 0)
        alignment_score = (immediate_dist + dest_dist) / (distance_matrix[current_node][destination_node] + 1e-6)
        return (alpha * immediate_dist + beta * dest_dist - revisit_penalty) * (1 - alignment_score)

    # Probabilistic selection with temperature
    scores = [evaluate_node(node) for node in candidates]
    exp_scores = [math.exp(-score / temperature) for score in scores]
    probs = [exp_score / sum(exp_scores) for exp_score in exp_scores]
    next_node = random.choices(candidates, weights=probs, k=1)[0]

    return next_node
