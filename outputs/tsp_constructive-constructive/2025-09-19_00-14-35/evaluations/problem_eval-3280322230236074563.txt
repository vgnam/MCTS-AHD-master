def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix):
    if not unvisited_nodes:
        return destination_node

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = remaining_nodes / total_nodes

    # Logarithmic neighborhood scaling
    neighborhood_size = max(1, int(1 + 2 * np.log(total_nodes - remaining_nodes + 1)))
    candidates = sorted(unvisited_nodes, key=lambda node: distance_matrix[current_node][node])[:neighborhood_size]

    # Adaptive weights with reinforcement learning-inspired decay
    alpha = 0.7 - 0.1 * np.exp(-exploration_factor)  # Immediate distance weight
    beta = 0.3 + 0.1 * np.exp(-exploration_factor)   # Destination bias weight
    gamma = 0.3 * (1 - exploration_factor)  # Dynamic revisit penalty

    def evaluate_node(node):
        immediate_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]
        return (alpha * immediate_dist) + (beta * dest_dist) - (gamma * (1 if node in unvisited_nodes else 0))

    next_node = min(candidates, key=lambda node: evaluate_node(node))
    return next_node
