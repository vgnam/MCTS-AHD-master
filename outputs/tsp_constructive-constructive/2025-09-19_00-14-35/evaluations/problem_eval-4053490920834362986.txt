def select_next_node(current_node, destination_node, unvisited_nodes, distance_matrix, node_selection_history=None):
    if not unvisited_nodes:
        return destination_node

    if node_selection_history is None:
        node_selection_history = {}

    remaining_nodes = len(unvisited_nodes)
    total_nodes = len(distance_matrix)
    exploration_factor = 1 / (1 + math.exp(-5 * (remaining_nodes / total_nodes - 0.5)))

    # Calculate node centrality as average distance to all other nodes
    centrality_scores = []
    for node in unvisited_nodes:
        centrality = sum(distance_matrix[node][n] for n in range(total_nodes)) / total_nodes
        centrality_scores.append((node, centrality))
    centrality_scores = dict(centrality_scores)

    scores = []
    for node in unvisited_nodes:
        immediate_dist = distance_matrix[current_node][node]
        dest_dist = distance_matrix[node][destination_node]

        if remaining_nodes > 1:
            remaining_nodes_list = [n for n in unvisited_nodes if n != node]
            avg_remaining_dist = sum(distance_matrix[node][n] for n in remaining_nodes_list) / len(remaining_nodes_list)
            connectivity_score = 1.0 / (1.0 + avg_remaining_dist)
            potential_gain = (distance_matrix[current_node][destination_node] - immediate_dist - dest_dist) / (1 + immediate_dist)
        else:
            connectivity_score = 0
            potential_gain = 0

        # Dynamic weight adjustment
        weight_local = 0.3 + 0.2 * exploration_factor
        weight_connectivity = 0.4 - 0.1 * exploration_factor
        weight_dest = -0.1 * (1 - exploration_factor)
        weight_gain = 0.3 * (1 - exploration_factor)
        weight_centrality = 0.2 * exploration_factor

        # Normalize centrality (inverse since we want to minimize distance)
        normalized_centrality = centrality_scores[node] / max(centrality_scores.values()) if max(centrality_scores.values()) > 0 else 0

        # Reinforcement learning-inspired adjustment
        selection_prob = node_selection_history.get(node, 0) + 1
        rl_adjustment = 1 / math.sqrt(selection_prob)

        score = (weight_local * immediate_dist) + (weight_connectivity * connectivity_score) + \
                (weight_dest * dest_dist) + (weight_gain * potential_gain) + \
                (weight_centrality * normalized_centrality) * rl_adjustment

        scores.append((node, score))

    next_node = min(scores, key=lambda x: x[1])[0]

    # Update selection history
    if next_node in node_selection_history:
        node_selection_history[next_node] += 1
    else:
        node_selection_history[next_node] = 1

    return next_node
